[{"path":"https://arutools.github.io/ARUtools/dev/CODE_DESIGN.html","id":null,"dir":"","previous_headings":"","what":"Code Design","title":"Code Design","text":"file contains notes code design conventions aim making collaboration future modifications easier.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/CODE_DESIGN.html","id":"naming","dir":"","previous_headings":"","what":"Naming","title":"Code Design","text":"Snake case used wherever possible Test files named test-XX_DESCRIPTION.R, XX order run (try test lower order functions first).","code":""},{"path":"https://arutools.github.io/ARUtools/dev/CODE_DESIGN.html","id":"column-names","dir":"","previous_headings":"","what":"Column names","title":"Code Design","text":"initial cleaning functions (clean_metadata(), clean_site_index()) users can specify existing column names, formatted standard names file_name, path date, date_start, date_end, date_time, date_time_start, date_time_end aru_id, aru_type, site_id longitude, latitude tz, t2sr, t2ss add_sites() allow adding keeping extra columns (name_extra = ...) Functions legitimately use different standardized column names (ie. selection functions clip wave functions) use NSE name arguments defined col_COLNAME Non-NSE col arguments defined name_COLNAME, including converted character within function use ways. NSE col names can referenced {{ }} tidyverse functions, occasionally must enquo()d use functions (like nse_names(), quo_is_null() example). Therefore cases enquo()d right start function (e.g., sample_recordings()) NSE col names default values must declared .onLoad function ARUtools-package.R avoid NOTES","code":""},{"path":"https://arutools.github.io/ARUtools/dev/CODE_DESIGN.html","id":"regular-expression-patterns","dir":"","previous_headings":"","what":"Regular Expression patterns","title":"Code Design","text":"create_pattern_XXX() e.g., patterns extracting data GPS files","code":""},{"path":"https://arutools.github.io/ARUtools/dev/CODE_DESIGN.html","id":"nitty-gritty-of-patterns-esp-for-datetimes","dir":"","previous_headings":"","what":"Nitty gritty of patterns (esp for date/times)","title":"Code Design","text":"Multiple patterns can created supplying multiple arguments create_pattern_XXX() functions, supplying vector patterns clean_metadata() (example). Date/time patterns order need specified pattern creation, also clean_metadata() (order_date) two steps, extracting pattern parsing pattern. Currently, although seconds can enforced, omitted optional create_pattern_time() function, always optional parsing function (.e. lubridate::parse_date_time(... truncated = 1)). necessary, made optional parsing adding another argument optional_sec similar, may overkill now Right now, users supply date, sep, time patterns, possibly, might worth option supply single date/time pattern take precedence. ’s unclear often necessary, however. possibility matching different numbers numbers (.e. can match 2 year digits 4 year digits), always use rev(sort(digits)), (sort(digits, decreasing = TRUE)) ensure longer patterns can matched comparing shorter patterns","code":""},{"path":"https://arutools.github.io/ARUtools/dev/CODE_DESIGN.html","id":"verbosity","dir":"","previous_headings":"","what":"Verbosity","title":"Code Design","text":"ARUtools pretty chatty result clear weird data handled quiet argument FALSE default. TRUE, non-essential, FYI messages suppressed (warnings, informative problem messages) verbose argument (currently clean_gps()) default FALSE. TRUE, shows even information (generally unnecessary unless troubleshooting specific problem)","code":""},{"path":"https://arutools.github.io/ARUtools/dev/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 ARUtools authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/articles/ARUtools.html","id":"read-file-metadata","dir":"Articles","previous_headings":"","what":"Read file metadata","title":"Getting started with ARUtools","text":"Let’s use example data get started. list hypothetical ARU files different sites, using different ARUs. fairly messily organized data clear structure folders appear unneeded characters files. However give standard structure site names, ARU ID codes, datetime stamps, can extract information file structure alone. First things first, ’ll clean meta data associated files. example files follow standard formats Site ID, ARU Id, date/time, can extract information without change default arguments. reading directly files assign base directory clean_metadata read files folder sub-folders.","code":"library(ARUtools) head(example_files) #> [1] \"a_BARLT10962_P01_1/P01_1_20200502T050000-0400_ARU.wav\" #> [2] \"a_BARLT10962_P01_1/P01_1_20200503T052000-0400_ARU.wav\" #> [3] \"a_S4A01234_P02_1/P02_1_20200504T052500_ARU.wav\"        #> [4] \"a_S4A01234_P02_1/P02_1_20200505T073000_ARU.wav\"        #> [5] \"a_BARLT10962_P03_1/P03_1_20200506T100000-0400_ARU.wav\" #> [6] \"a_BARLT11111_P04_1/P04_1_20200506T050000-0400_ARU.wav\" m <- clean_metadata(project_files = example_files) #> Extracting ARU info... #> Extracting Dates and Times... m #> # A tibble: 42 × 11 #>   file_name     type  path  aru_id manufacturer model aru_type site_id tz_offset #>   <chr>         <chr> <chr> <chr>  <chr>        <chr> <chr>    <chr>   <chr>     #> 1 P01_1_202005… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P01_1   -0400     #> 2 P01_1_202005… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P01_1   -0400     #> 3 P02_1_202005… wav   a_S4… S4A01… Wildlife Ac… Song… SongMet… P02_1   NA        #> 4 P02_1_202005… wav   a_S4… S4A01… Wildlife Ac… Song… SongMet… P02_1   NA        #> # ℹ 38 more rows #> # ℹ 2 more variables: date_time <dttm>, date <date> base_directory <- \"/path/to/project/files/\" m <- clean_metadata(project_dir = base_directory)"},{"path":"https://arutools.github.io/ARUtools/dev/articles/ARUtools.html","id":"add-coordinates","dir":"Articles","previous_headings":"","what":"Add coordinates","title":"Getting started with ARUtools","text":"Next, want add coordinates data. data GPS logs included, detected step now use g <- clean_gps(m) create list GPS coordinates. However, many models ARUs internal GPS , may accurately record location ARU deployed . Therefore recommend create site index file manually record deployment locations, like one. can simply specify single date, recommended use start date end date best matching. critical moving ARUs season. Now let’s clean list can add sites metadata. Ooops! can see right away clean_site_index() expects data particular format. Luckily can let know ’ve used different format. Hmm, ’s interesting message! means deployment dates overlap. ARUtools assumes set ARU specific day, probably didn’t set midnight (.e. start day). Since assume likely using ARUs recording early morning late night, shift dates start/end times noon estimate ARU likely deployed. ARU deployed midnight, use resolve_ovelaps = FALSE. , know exact time ARU deployed, use date/time rather just date site index. Note ’ve lost couple non-standard columns: Plots Subplot. can retain specifying cols_extra. can even fancy rename consistency using named vectors. Now let’s add site-related information metadata.","code":"example_sites #>    Sites Date_set_out Date_removed        ARU    lon    lat Plots Subplot #> 1  P01_1   2020-05-01   2020-05-03 BARLT10962 -85.03 50.010 Plot1       a #> 2  P02_1   2020-05-03   2020-05-05   S4A01234 -87.45 52.680 Plot1       a #> 3  P03_1   2020-05-05   2020-05-06 BARLT10962 -90.38 48.990 Plot2       a #> 4  P04_1   2020-05-05   2020-05-07 BARLT11111 -85.53 45.000 Plot2       a #> 5  P05_1   2020-05-06   2020-05-07 BARLT10962 -88.45 51.050 Plot3       b #> 6  P06_1   2020-05-08   2020-05-09 BARLT10962 -90.08 52.000 Plot1       a #> 7  P07_1   2020-05-08   2020-05-10   S4A01234 -86.03 50.450 Plot1       a #> 8  P08_1   2020-05-10   2020-05-11 BARLT10962 -84.45 48.999 Plot2       a #> 9  P09_1   2020-05-10   2020-05-11   S4A02222 -91.38 45.000 Plot2       a #> 10 P10_1   2020-05-10   2020-05-11   S4A03333 -90.00 50.010 Plot3       b sites <- clean_site_index(example_sites) #> Error in `clean_site_index()`: #> ! Problems with data `site_index`: #> • Column 'site_id' does not exist #> • Column 'date' does not exist #> • Column 'aru_id' does not exist #> • Column 'longitude' does not exist #> • Column 'latitude' does not exist #> • See ?clean_site_index sites <- clean_site_index(example_sites,   name_aru_id = \"ARU\",   name_site_id = \"Sites\",   name_date_time = c(\"Date_set_out\", \"Date_removed\"),   name_coords = c(\"lon\", \"lat\") ) #> There are overlapping date ranges #> • Shifting start/end times to 'noon' #> • Skip this with `resolve_overlaps = FALSE` sites #> # A tibble: 10 × 8 #>   site_id aru_id   date_time_start     date_time_end       date_start date_end   #>   <chr>   <chr>    <dttm>              <dttm>              <date>     <date>     #> 1 P01_1   BARLT10… 2020-05-01 12:00:00 2020-05-03 12:00:00 2020-05-01 2020-05-03 #> 2 P02_1   S4A01234 2020-05-03 12:00:00 2020-05-05 12:00:00 2020-05-03 2020-05-05 #> 3 P03_1   BARLT10… 2020-05-05 12:00:00 2020-05-06 12:00:00 2020-05-05 2020-05-06 #> 4 P04_1   BARLT11… 2020-05-05 12:00:00 2020-05-07 12:00:00 2020-05-05 2020-05-07 #> # ℹ 6 more rows #> # ℹ 2 more variables: longitude <dbl>, latitude <dbl> sites <- clean_site_index(example_sites,   name_aru_id = \"ARU\",   name_site_id = \"Sites\",   name_date_time = c(\"Date_set_out\", \"Date_removed\"),   name_coords = c(\"lon\", \"lat\"),   name_extra = c(\"Plots\", \"Subplot\") ) #> There are overlapping date ranges #> • Shifting start/end times to 'noon' #> • Skip this with `resolve_overlaps = FALSE` sites #> # A tibble: 10 × 10 #>   site_id aru_id   date_time_start     date_time_end       date_start date_end   #>   <chr>   <chr>    <dttm>              <dttm>              <date>     <date>     #> 1 P01_1   BARLT10… 2020-05-01 12:00:00 2020-05-03 12:00:00 2020-05-01 2020-05-03 #> 2 P02_1   S4A01234 2020-05-03 12:00:00 2020-05-05 12:00:00 2020-05-03 2020-05-05 #> 3 P03_1   BARLT10… 2020-05-05 12:00:00 2020-05-06 12:00:00 2020-05-05 2020-05-06 #> 4 P04_1   BARLT11… 2020-05-05 12:00:00 2020-05-07 12:00:00 2020-05-05 2020-05-07 #> # ℹ 6 more rows #> # ℹ 4 more variables: longitude <dbl>, latitude <dbl>, Plots <chr>, #> #   Subplot <chr> sites <- clean_site_index(example_sites,   name_aru_id = \"ARU\",   name_site_id = \"Sites\",   name_date_time = c(\"Date_set_out\", \"Date_removed\"),   name_coords = c(\"lon\", \"lat\"),   name_extra = c(\"plot\" = \"Plots\", \"subplot\" = \"Subplot\") ) #> There are overlapping date ranges #> • Shifting start/end times to 'noon' #> • Skip this with `resolve_overlaps = FALSE` sites #> # A tibble: 10 × 10 #>   site_id aru_id   date_time_start     date_time_end       date_start date_end   #>   <chr>   <chr>    <dttm>              <dttm>              <date>     <date>     #> 1 P01_1   BARLT10… 2020-05-01 12:00:00 2020-05-03 12:00:00 2020-05-01 2020-05-03 #> 2 P02_1   S4A01234 2020-05-03 12:00:00 2020-05-05 12:00:00 2020-05-03 2020-05-05 #> 3 P03_1   BARLT10… 2020-05-05 12:00:00 2020-05-06 12:00:00 2020-05-05 2020-05-06 #> 4 P04_1   BARLT11… 2020-05-05 12:00:00 2020-05-07 12:00:00 2020-05-05 2020-05-07 #> # ℹ 6 more rows #> # ℹ 4 more variables: longitude <dbl>, latitude <dbl>, plot <chr>, #> #   subplot <chr> m <- add_sites(m, sites) #> Joining by columns `date_time_start` and `date_time_end` m #> # A tibble: 42 × 15 #>   file_name     type  path  aru_id manufacturer model aru_type site_id tz_offset #>   <chr>         <chr> <chr> <chr>  <chr>        <chr> <chr>    <chr>   <chr>     #> 1 P01_1_202005… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P01_1   -0400     #> 2 P01_1_202005… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P01_1   -0400     #> 3 P02_1_202005… wav   a_S4… S4A01… Wildlife Ac… Song… SongMet… P02_1   NA        #> 4 P02_1_202005… wav   a_S4… S4A01… Wildlife Ac… Song… SongMet… P02_1   NA        #> # ℹ 38 more rows #> # ℹ 6 more variables: date_time <dttm>, date <date>, longitude <dbl>, #> #   latitude <dbl>, plot <chr>, subplot <chr>"},{"path":"https://arutools.github.io/ARUtools/dev/articles/ARUtools.html","id":"calculate-times-to-sunrise-and-sunset","dir":"Articles","previous_headings":"","what":"Calculate times to sunrise and sunset","title":"Getting started with ARUtools","text":"Great! site-related information describe recording. Now prepare selection procedure, last thing need calculate time sunrise sunset. need clear timezone ARU unit recording times . two options. first option ARUs set home base deployment. case ’s possible deployed location different timezone recording . doesn’t matter, long specify programmed timezone . case, use tz = \"America/Toronto\", whichever time zone used. Note timezones must one OlsonNames(). second option ARU unit set record local timezone placed. case, specify tz = \"local\" calc_sun() function use coordinates determine local timezones. (See Dealing Timezones vignette details). example, let’s assume ARUs set location deployed. ’ll use tz = \"local\", default setting. Tada! Now complete set cleaned metadata associated recording. simple example much pain large projects comes complications, sure check vignette(\"customizing\") vignette(\"spatial\") dig issues.","code":"m <- calc_sun(m) dplyr::glimpse(m) #> Rows: 42 #> Columns: 18 #> $ file_name    <chr> \"P01_1_20200502T050000-0400_ARU.wav\", \"P01_1_20200503T052… #> $ type         <chr> \"wav\", \"wav\", \"wav\", \"wav\", \"wav\", \"wav\", \"wav\", \"wav\", \"… #> $ path         <chr> \"a_BARLT10962_P01_1/P01_1_20200502T050000-0400_ARU.wav\", … #> $ aru_id       <chr> \"BARLT10962\", \"BARLT10962\", \"S4A01234\", \"S4A01234\", \"BARL… #> $ manufacturer <chr> \"Frontier Labs\", \"Frontier Labs\", \"Wildlife Acoustics\", \"… #> $ model        <chr> \"BAR-LT\", \"BAR-LT\", \"Song Meter 4\", \"Song Meter 4\", \"BAR-… #> $ aru_type     <chr> \"BARLT\", \"BARLT\", \"SongMeter\", \"SongMeter\", \"BARLT\", \"BAR… #> $ site_id      <chr> \"P01_1\", \"P01_1\", \"P02_1\", \"P02_1\", \"P03_1\", \"P04_1\", \"P0… #> $ tz_offset    <chr> \"-0400\", \"-0400\", NA, NA, \"-0400\", \"-0400\", \"-0400\", \"-04… #> $ date_time    <dttm> 2020-05-02 05:00:00, 2020-05-03 05:20:00, 2020-05-04 05:… #> $ date         <date> 2020-05-02, 2020-05-03, 2020-05-04, 2020-05-05, 2020-05-… #> $ longitude    <dbl> -85.03, -85.03, -87.45, -87.45, -90.38, -85.53, -85.53, -… #> $ latitude     <dbl> 50.010, 50.010, 52.680, 52.680, 48.990, 45.000, 45.000, 5… #> $ plot         <chr> \"Plot1\", \"Plot1\", \"Plot1\", \"Plot1\", \"Plot2\", \"Plot2\", \"Pl… #> $ subplot      <chr> \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"b\", \"a\", \"a\", \"a\", \"a… #> $ tz           <chr> \"America/Toronto\", \"America/Toronto\", \"America/Toronto\", … #> $ t2sr         <dbl> -74.933333, -53.216667, -47.250000, 79.616667, 207.133333… #> $ t2ss         <dbl> 479.9500, 498.4167, 483.4167, 606.6833, -685.8833, 486.18…"},{"path":"https://arutools.github.io/ARUtools/dev/articles/ARUtools.html","id":"next-steps","dir":"Articles","previous_headings":"","what":"Next steps","title":"Getting started with ARUtools","text":"Now set cleaned metadata next step select recordings. using random sampling approach check subsampling article vignette(\"SubSample\").","code":""},{"path":"https://arutools.github.io/ARUtools/dev/articles/Misc.html","id":"setting-up-your-folder-structure","dir":"Articles","previous_headings":"","what":"Setting up your folder structure","title":"Other useful functions","text":"ARUtools focuses processing recordings transferred ARUs, setting folder structure can greatly increase efficiency transferring files. set folder structure need hierarchical structure wish use list sites/arus processing. create series folders plot main level site subdirectory . Note work project structures think carefully want set file names, folder structure spatial information deploy ARUs.","code":"site_list <-   example_sites |>   tidyr::separate(Sites, into = c(\"plot\", \"site\"), sep = \"_\", remove = F) |>   dplyr::select(site_id = Sites, plot, site)   tmp_dir <- tempdir(check = T) |> paste0(\"/ARUtools/\") dir.create(tmp_dir)  create_directory_structure(   hexagons = site_list$plot,   units = site_list$site_id,   base_dir = tmp_dir ) list.dirs(tmp_dir, full.names = F)"},{"path":"https://arutools.github.io/ARUtools/dev/articles/Misc.html","id":"wind-processing","dir":"Articles","previous_headings":"","what":"Wind processing","title":"Other useful functions","text":"One issue can cause difficulty interpretation acoustic recordings wind. Wind can mask bird songs even potential danger interpreters’ ears. University Salford Acoustics Research Centre developed softare program WindNoiseDetection detects wind wave files. developed fork software added ability run multiple files using parallel processing provide list files process. Running program requires fairly complex setup Windows uses C C++ requires Cygwin run. However get running, ARUtools includes couple helper functions process metadata set running WindNoiseDetection. output list vectors include path wave files (filePaths), input wave filenames (filenames), list sites append output results (sites). run WindNoiseDetection can read results using wind_detection_summarize_json().","code":"wind_files <-   wind_detection_pre_processing(     wav_files = example_clean$path,     output_directory = \"./wind_files/\",     site_pattern = create_pattern_site_id(       p_digits = c(2, 3), sep = \"_\",       s_digits = c(1, 2)     ),     write_to_file = F, chunk_size = NULL   ) example_json <- system.file(\"extdata\", \"P71-1__20210606T232500-0400_SS.json\", package = \"ARUtools\")  wind_summary <- wind_detection_summarize_json(example_json) dplyr::glimpse(wind_summary) #> Rows: 1 #> Columns: 7 #> $ totalwindless <dbl> 268.58 #> $ pwindless     <dbl> 0.8966715 #> $ n             <int> 5 #> $ length        <dbl> 299.53 #> $ mean_windless <dbl> 53.716 #> $ path          <chr> \"/cygdrive/P/Path/To/WaveFile/NL/P71/P71-1/20210606_Napk… #> $ jsonF         <chr> \"P71-1__20210606T232500-0400_SS.json\""},{"path":"https://arutools.github.io/ARUtools/dev/articles/Misc.html","id":"assign-tasks","dir":"Articles","previous_headings":"","what":"Assign tasks","title":"Other useful functions","text":"assign tasks need either download task template ‘WildTrax’ alternatively can use new wildRtrax::wt_make_aru_tasks() function. also need template observers number hours interpreting. doesn’t match exactly time project relative amounts used. files need, can run wt_assign_tasks() randomly assign tasks interpreters based amount effort can put . can alternatively use Shiny app Shiny_select running following:","code":"in_tasks <- fs::file_temp(\"Input_task_file\", ext = \".csv\") task_template <- wildRtrax::wt_make_aru_tasks(   example_clean |>     dplyr::mutate(       recording_date_time = date_time,       file_path = path, location = site_id,       length_seconds = 300     ),   output = in_tasks,   task_method = \"1SPT\", task_length = 300 ) template_observers #> # A tibble: 4 × 2 #>   transcriber                     hrs #>   <chr>                         <dbl> #> 1 Charles Dickens                 5   #> 2 John Von Jovie                  1   #> 3 John Yossarian                  6.5 #> 4 Rodion Romanovich Raskolnikov   2.3 task_output <- wt_assign_tasks(   wt_task_template_in = task_template,   wt_task_output_file = NULL,   interp_hours = template_observers,   interp_hours_column = hrs,   random_seed = 65416 )  task_output$task_summary #> # A tibble: 4 × 5 #>   transcriber                   hrs_assigned   hrs   phrs updated_hrs_remain #>   <chr>                                <dbl> <dbl>  <dbl>              <dbl> #> 1 John Yossarian                       1.08    6.5 0.439               5.42  #> 2 Rodion Romanovich Raskolnikov        1.08    2.3 0.155               1.22  #> 3 Charles Dickens                      1.17    5   0.338               3.83  #> 4 John Von Jovie                       0.167   1   0.0676              0.833 shiny::runGitHub(\"dhope/Shiny_select\")"},{"path":"https://arutools.github.io/ARUtools/dev/articles/SubSample.html","id":"create-data","dir":"Articles","previous_headings":"","what":"Create data","title":"Subsampling recordings","text":"generate data sites example_sites. Click triangle see details method. simulate file names generate series recordings site. schedule every 30 minutes 5:30 8:00 every second day 1 May 10 July. Normally want schedule based around local sunrise targeting dawn chorus, work purposes. site info used example_sites.","code":"library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(stringr) library(lubridate) #>  #> Attaching package: 'lubridate' #> The following objects are masked from 'package:base': #>  #>     date, intersect, setdiff, union  simple_deploy <-   tidyr::expand_grid(     site_id = unique(example_sites$Sites),     doy = seq(121, 191, by = 2),     times = seq(-30, 120, by = 30)   ) |>   tidyr::separate(site_id, into = c(\"plot\", \"site\"), sep = \"_\", remove = F) |>   left_join(example_sites, join_by(site_id == Sites)) |>   mutate(     # aru_id = glue::glue(\"BARLT-000{as.numeric(as.factor(site_id))}\"),     date = ymd(\"2028-01-01\") + doy,     date_time = ymd_hm(glue::glue(\"{date} 06:00\")) + minutes(times),     date_time_chr = str_replace(as.character(date_time), \"\\\\s\", \"T\"),     file_name = glue::glue(\"{plot}/{site_id}/{ARU}_{date_time_chr}.wav\")   )  simple_deploy #> # A tibble: 2,160 × 16 #>   site_id plot  site    doy times Date_set_out Date_removed ARU        lon   lat #>   <chr>   <chr> <chr> <dbl> <dbl> <chr>        <chr>        <chr>    <dbl> <dbl> #> 1 P01_1   P01   1       121   -30 2020-05-01   2020-05-03   BARLT10… -85.0  50.0 #> 2 P01_1   P01   1       121     0 2020-05-01   2020-05-03   BARLT10… -85.0  50.0 #> 3 P01_1   P01   1       121    30 2020-05-01   2020-05-03   BARLT10… -85.0  50.0 #> 4 P01_1   P01   1       121    60 2020-05-01   2020-05-03   BARLT10… -85.0  50.0 #> # ℹ 2,156 more rows #> # ℹ 6 more variables: Plots <chr>, Subplot <chr>, date <date>, #> #   date_time <dttm>, date_time_chr <chr>, file_name <glue> site_info <- simple_deploy |>   slice_min(order_by = date_time, n = 1, by = site_id) |>   dplyr::select(site_id, ARU, lon, lat, date_time)"},{"path":"https://arutools.github.io/ARUtools/dev/articles/SubSample.html","id":"clean-metadata","dir":"Articles","previous_headings":"","what":"Clean metadata","title":"Subsampling recordings","text":"clean metadata can use code found Getting Started vignette. used pipe save space , can see details linked article (vignette(\"ARUtools\")).","code":"sites <- clean_site_index(site_info,   name_aru_id = \"ARU\",   name_site_id = \"site_id\",   name_date_time = c(\"date_time\"),   name_coords = c(\"lon\", \"lat\") ) metadata <- clean_metadata(project_files = simple_deploy$file_name) |>   add_sites(sites) |>   calc_sun() |>   dplyr::mutate(doy = lubridate::yday(date)) #> Extracting ARU info... #> Extracting Dates and Times... #> Joining by column `date_time` using buffers dplyr::glimpse(metadata) #> Rows: 2,160 #> Columns: 17 #> $ file_name    <chr> \"BARLT10962_2028-05-01T05:30:00.wav\", \"BARLT10962_2028-05… #> $ type         <chr> \"wav\", \"wav\", \"wav\", \"wav\", \"wav\", \"wav\", \"wav\", \"wav\", \"… #> $ path         <chr> \"P01/P01_1/BARLT10962_2028-05-01T05:30:00.wav\", \"P01/P01_… #> $ aru_id       <chr> \"BARLT10962\", \"BARLT10962\", \"BARLT10962\", \"BARLT10962\", \"… #> $ manufacturer <chr> \"Frontier Labs\", \"Frontier Labs\", \"Frontier Labs\", \"Front… #> $ model        <chr> \"BAR-LT\", \"BAR-LT\", \"BAR-LT\", \"BAR-LT\", \"BAR-LT\", \"BAR-LT… #> $ aru_type     <chr> \"BARLT\", \"BARLT\", \"BARLT\", \"BARLT\", \"BARLT\", \"BARLT\", \"BA… #> $ site_id      <chr> \"P01_1\", \"P01_1\", \"P01_1\", \"P01_1\", \"P01_1\", \"P01_1\", \"P0… #> $ tz_offset    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N… #> $ date_time    <dttm> 2028-05-01 05:30:00, 2028-05-01 06:00:00, 2028-05-01 06:… #> $ date         <date> 2028-05-01, 2028-05-01, 2028-05-01, 2028-05-01, 2028-05-… #> $ longitude    <dbl> -85.03, -85.03, -85.03, -85.03, -85.03, -85.03, -85.03, -… #> $ latitude     <dbl> 50.01, 50.01, 50.01, 50.01, 50.01, 50.01, 50.01, 50.01, 5… #> $ tz           <chr> \"America/Toronto\", \"America/Toronto\", \"America/Toronto\", … #> $ t2sr         <dbl> -46.80, -16.80, 13.20, 43.20, 73.20, 103.20, -43.35, -13.… #> $ t2ss         <dbl> 511.6167, 541.6167, 571.6167, 601.6167, 631.6167, 661.616… #> $ doy          <dbl> 122, 122, 122, 122, 122, 122, 124, 124, 124, 124, 124, 12…"},{"path":"https://arutools.github.io/ARUtools/dev/articles/SubSample.html","id":"parameters","dir":"Articles","previous_headings":"","what":"Parameters","title":"Subsampling recordings","text":"Generally random sampling may want recordings selected equal weight across time dates. example sampling songbirds breeding season, species active couple hours around sunrise. also want limit dates ensure picking breeding birds migrants. deal issue allow user specify selection weights based time sunrise (sunset) well day year. visualize selection parameters use gen_dens_sel_simulation. show sample weights change time time sunrise/sunset.","code":"p <- sim_selection_weights(   min_range = c(-70, 240),   day_range = c(120, lubridate::yday(lubridate::ymd(\"2021-07-20\"))),   min_mean = 30, min_sd = 60,   day_mean = lubridate::yday(lubridate::ymd(\"2021-06-10\")),   day_sd = 20, offset = 0,   return_log = TRUE, selection_fun = \"norm\" )"},{"path":"https://arutools.github.io/ARUtools/dev/articles/SubSample.html","id":"calculate-selection-weights","dir":"Articles","previous_headings":"","what":"Calculate selection weights","title":"Subsampling recordings","text":"parameters set , can use calculate sampling weights metadata. can see selection weights psel_normalized. highest selection weights match output gen_dens_sel_simulation(). schedule set start based time, time sunrise recordings occur differ sites.","code":"full_selection_probs <-   metadata |>   calc_selection_weights(     col_site_id = site_id,     col_min = t2sr,     col_day = doy,     params = p   )"},{"path":"https://arutools.github.io/ARUtools/dev/articles/SubSample.html","id":"assign-sample-size","dir":"Articles","previous_headings":"","what":"Assign sample size","title":"Subsampling recordings","text":"next step assign sample sizes. can done per site basis across board. use 2% sampling rate, subsampling intensity depend project goals. can also set oversample draw extra samples case samples unusable (e.g. due wind). figure can provide coarse rule thumb many minutes recordings might need number samples. course many assumptions including knowledge probability observing per minute, probability change date, time day, conspecific behaviour, weather, etc.","code":"sample_size <- count(full_selection_probs, site_id) |>   transmute(site_id,     n = floor(n * .02),     n_os = ceiling(n * .3)   )"},{"path":[]},{"path":"https://arutools.github.io/ARUtools/dev/articles/SubSample.html","id":"grts","dir":"Articles","previous_headings":"Draw subsample","what":"GRTS","title":"Subsampling recordings","text":"ways subsample recordings. ARUtools imported grts() (Generalized Random Tessellation Stratified algorithm) function spsurvey package. developed wrapper around function simplify ’s usage particular use case. GRTS allows us sample using dispersed samples, maintaining stochastic element sampling. case selecting samples dispersed across dates time dates.","code":"grts_res <- sample_recordings(full_selection_probs,   n = sample_size,   col_site_id = site_id,   seed = 2024,   col_sel_weights = psel_normalized )  dplyr::glimpse(grts_res$sites_base) #> Rows: 40 #> Columns: 33 #> $ siteID          <chr> \"sample-01\", \"sample-02\", \"sample-03\", \"sample-04\", \"s… #> $ siteuse         <chr> \"Base\", \"Base\", \"Base\", \"Base\", \"Base\", \"Base\", \"Base\"… #> $ replsite        <chr> \"None\", \"None\", \"None\", \"None\", \"None\", \"None\", \"None\"… #> $ lon_WGS84       <dbl> 0.001365439, 0.001545102, 0.001203742, 0.001563069, 0.… #> $ lat_WGS84       <dbl> 4.723823e-04, 5.254387e-04, -2.502089e-04, -2.125268e-… #> $ stratum         <chr> \"P01_1\", \"P01_1\", \"P01_1\", \"P01_1\", \"P02_1\", \"P02_1\", … #> $ wgt             <dbl> 35.29300, 36.72486, 72.07435, 38.37921, 33.54426, 76.4… #> $ ip              <dbl> 0.028334233, 0.027229512, 0.013874562, 0.026055777, 0.… #> $ caty            <chr> \"None\", \"None\", \"None\", \"None\", \"None\", \"None\", \"None\"… #> $ aux             <dbl> 0.9307375, 0.8944490, 0.4557587, 0.8558936, 0.9678483,… #> $ file_name       <chr> \"BARLT10962_2028-05-31T06:30:00.wav\", \"BARLT10962_2028… #> $ type            <chr> \"wav\", \"wav\", \"wav\", \"wav\", \"wav\", \"wav\", \"wav\", \"wav\"… #> $ path            <chr> \"P01/P01_1/BARLT10962_2028-05-31T06:30:00.wav\", \"P01/P… #> $ aru_id          <chr> \"BARLT10962\", \"BARLT10962\", \"BARLT10962\", \"BARLT10962\"… #> $ manufacturer    <chr> \"Frontier Labs\", \"Frontier Labs\", \"Frontier Labs\", \"Fr… #> $ model           <chr> \"BAR-LT\", \"BAR-LT\", \"BAR-LT\", \"BAR-LT\", \"Song Meter 4\"… #> $ aru_type        <chr> \"BARLT\", \"BARLT\", \"BARLT\", \"BARLT\", \"SongMeter\", \"Song… #> $ site_id         <chr> \"P01_1\", \"P01_1\", \"P01_1\", \"P01_1\", \"P02_1\", \"P02_1\", … #> $ tz_offset       <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… #> $ date_time       <dttm> 2028-05-31 06:30:00, 2028-06-20 06:30:00, 2028-05-13 … #> $ date            <date> 2028-05-31, 2028-06-20, 2028-05-13, 2028-06-22, 2028-… #> $ longitude       <dbl> -85.03, -85.03, -85.03, -85.03, -87.45, -87.45, -87.45… #> $ latitude        <dbl> 50.01, 50.01, 50.01, 50.01, 52.68, 52.68, 52.68, 52.68… #> $ tz              <chr> \"America/Toronto\", \"America/Toronto\", \"America/Toronto… #> $ t2ss            <dbl> 530.1500, 516.0667, 493.4667, 455.6000, 438.7000, 551.… #> $ psel_by         <chr> \"t2sr\", \"t2sr\", \"t2sr\", \"t2sr\", \"t2sr\", \"t2sr\", \"t2sr\"… #> $ psel_min        <dbl> -0.4561300, -0.4598709, -0.4920422, -0.4628636, -0.460… #> $ psel_doy        <dbl> -0.6675488, -0.6758601, -0.8021915, -0.6858336, -0.650… #> $ psel            <dbl> 0.3250817, 0.3211873, 0.2741078, 0.3170496, 0.3290624,… #> $ psel_scaled     <dbl> 0.9775970, 0.9658855, 0.8243066, 0.9534425, 0.9895679,… #> $ psel_std        <dbl> 0.9776457, 0.9659337, 0.8243477, 0.9534901, 0.9895803,… #> $ psel_normalized <dbl> 0.9307375, 0.8944490, 0.4557587, 0.8558936, 0.9678483,… #> $ geometry        <POINT [m]> POINT (152 52.23333), POINT (172 58.1), POINT (1…"},{"path":"https://arutools.github.io/ARUtools/dev/articles/SubSample.html","id":"slice_sample","dir":"Articles","previous_headings":"Draw subsample","what":"slice_sample","title":"Subsampling recordings","text":"don’t want sample using grts() can just use dplyr::slice_sample(). Oversamples random sampling, just involves dropping recordings ’ve selected drawing .","code":"withr::with_seed(2024, {   random_sample <-     full_selection_probs |>     dplyr::slice_sample(       n = 4, by = site_id,       weight_by = psel_normalized,       replace = F     ) }) withr::with_seed(2024, {   random_sample_stratified <-     full_selection_probs |>     left_join(sample_size, by = join_by(site_id)) |>     nest_by(site_id, n) |>     rowwise() |>     mutate(sample = list(dplyr::slice_sample(       .data = data,       n = .data$n,       weight_by = psel_normalized,       replace = F     ))) |>     dplyr::select(site_id, sample) |>     tidyr::unnest(sample) }) oversample <- filter(   full_selection_probs,   !path %in% random_sample$path ) |>   dplyr::slice_sample(     n = 2, by = site_id,     weight_by = psel_normalized,     replace = F   )"},{"path":"https://arutools.github.io/ARUtools/dev/articles/SubSample.html","id":"compare-methods","dir":"Articles","previous_headings":"Draw subsample","what":"Compare methods","title":"Subsampling recordings","text":"Looking draws, may notice grts results spaced , random sample, contains clumping, characteristic random sampling.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/articles/SubSample.html","id":"assigning-recording-lengths","dir":"Articles","previous_headings":"","what":"Assigning recording lengths","title":"Subsampling recordings","text":"surveys may include full recordings, others may interpret portion recordings, allowing recordings least partially interpreted. assign lengths, can repeat process sequentially assigning lengths simply just assign . however creates issue sites less length. Sampling site length creates equal sample length site.","code":"withr::with_seed(6546, {   random_sample$length <- sample(     x = c(\"5min\", \"3min\", \"1min\"),     size = nrow(random_sample), replace = T   ) }) #> # A tibble: 3 × 11 #>   length P02_1 P03_1 P04_1 P05_1 P07_1 P08_1 P09_1 P10_1 P01_1 P06_1 #>   <chr>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1 1min       1     3     1     1     3     2     1     1     0     0 #> 2 3min       1     1     1     2     0     1     3     2     3     3 #> 3 5min       2     0     2     1     1     1     0     1     1     1 withr::with_seed(569, {   sample5min <- slice_sample(random_sample,     n = 1, by = site_id, weight_by = psel_normalized   )    sample3min <- slice_sample(     random_sample |>       filter(!path %in% sample5min$path),     n = 1, by = site_id, weight_by = psel_normalized   )     random_sample_with_lengths <- random_sample |>     mutate(       Length_group =         case_when(           path %in% sample5min$path ~ \"5min\",           path %in% sample3min$path ~ \"3min\",           TRUE ~ \"1min\"         ),       length_clip = as.numeric(str_extract(Length_group, \"^\\\\d\")) * 60     ) }) #> # A tibble: 3 × 11 #>   Length_group P01_1 P02_1 P03_1 P04_1 P05_1 P06_1 P07_1 P08_1 P09_1 P10_1 #>   <chr>        <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1 1min             2     2     2     2     2     2     2     2     2     2 #> 2 3min             1     1     1     1     1     1     1     1     1     1 #> 3 5min             1     1     1     1     1     1     1     1     1     1"},{"path":"https://arutools.github.io/ARUtools/dev/articles/SubSample.html","id":"assign-start-times","dir":"Articles","previous_headings":"","what":"Assign start times","title":"Subsampling recordings","text":"ARUtools includes function get_wav_length, return length ‘wav’ file seconds. can used safely add random start time recordings don’t want start zero. document assume recordings 5 minutes.","code":"random_sample_with_lengths$length_clip <-   purrr::map(     1:nrow(random_sample_with_lengths),     ~ get_wav_length(       path = random_sample_with_lengths$path[[.x]],       return_numeric = T     )   ) random_sample_with_lengths$length <- 5 * 60 random_sample_with_lengths <-   random_sample_with_lengths |>   rowwise() |>   mutate(StartTime = case_when(     Length_group == \"5min\" ~ 0,     TRUE ~ runif(       1, 0,       pmax(         0,         length - length_clip       )     )   )) |>   ungroup()"},{"path":"https://arutools.github.io/ARUtools/dev/articles/SubSample.html","id":"format-output-filename","dir":"Articles","previous_headings":"Assign start times","what":"Format output filename","title":"Subsampling recordings","text":"Finally can format filenames Wildtrax, processes sites, dates, times based file name.","code":"final_selection <- random_sample_with_lengths |>   add_wildtrax()  final_selection |>   head() |>   dplyr::select(path, wildtrax_file_name) #> # A tibble: 6 × 2 #>   path                                         wildtrax_file_name    #>   <chr>                                        <glue>                #> 1 P01/P01_1/BARLT10962_2028-07-06T07:00:00.wav P01_1_20280706_070000 #> 2 P01/P01_1/BARLT10962_2028-06-02T07:00:00.wav P01_1_20280602_070000 #> 3 P01/P01_1/BARLT10962_2028-05-15T06:30:00.wav P01_1_20280515_063000 #> 4 P01/P01_1/BARLT10962_2028-07-04T06:30:00.wav P01_1_20280704_063000 #> # ℹ 2 more rows"},{"path":"https://arutools.github.io/ARUtools/dev/articles/SubSample.html","id":"clip-and-copy-files-for-upload","dir":"Articles","previous_headings":"Assign start times","what":"Clip and copy files for upload","title":"Subsampling recordings","text":"format_clip_wave rename, clip copy file location can used uploading Wildtrax Setting subset folders allow copy files organized folder structure can help checking errors prior uploading. large number files, may want run separately files require clipping run much quicker files need clipped. can use option use_job=T allow use job package, launch background job copying take long time. ’s , output folder now selected files, properly named Wildtrax ready upload.","code":"out_directory <- \"/path/to/upload/directory/\" dir.create(out_directory, recursive = T) ul_tab <- expand_grid(   period = c(\"Dawn\"), # Add 'Dusk' if using more than one time period   length = unique(selected_recordings$Length_group) ) purrr::map(glue::glue(\"{out_directory}/{ul_tab$period}/{ul_tab$length}\"),   dir.create,   recursive = T ) log_output <-   format_clip_wave(     segment_df = final_selection,     in_base_directory = \"\", out_base_directory = out_directory,     length_clip_col = \"length_clip\",     sub_dir_out_col = c(\"Time_period\", \"Length_group\"),     filepath_in_col = \"path\",     out_filename_col = \"wildtrax_file_name\",     use_job = F, filewarn = F   )"},{"path":"https://arutools.github.io/ARUtools/dev/articles/customizing.html","id":"regular-expressions","dir":"Articles","previous_headings":"","what":"Regular expressions","title":"Customizing `clean_metadata()`","text":"First let’s talk bit clean_metadata() extracts information. function uses regular expressions match specific text patterns file path recording. Regular expressions really powerful, also reasonably complicated can confusing. example, default, clean_metadata() matches site ids expression ((Q)|(P))(())(_|-)(()). Yikes! Broken , means look “Q” “P” (((Q)|(P))) followed two digits (\\\\d{2}) followed separator, either _ - (_|-) followed single digit (\\\\d{1}). clearly doesn’t define sites example . can supply regular expression, instead. However, sites follow reasonable pattern prefix, followed digits optionally suffix digits, might easier use helper function create regular expression . example, create site id pattern can use create_pattern_site_id(). specify prefix text well many digits might expect, separator, suffix text many suffix digits might . can useful look default patterns functions see might different data. See ?create_pattern_date create_pattern function pull documentation explore defaults well examples. can also useful test pattern running files. can use test_pattern() function see pattern successfully extracts site id first file list. Let’s continue customizing metadata patterns specifying ARU ids, dates times.","code":"m <- clean_metadata(project_files = f, pattern_site_id = \"site\\\\d{3}-(a|b)\\\\d{2}\") #> Extracting ARU info... #> Extracting Dates and Times... #> Identified possible problems with metadata extraction: #> ✖ No times were successfully detected (2/2) #> ✖ No ARU ids were successfully detected (2/2) m #> # A tibble: 2 × 11 #>   file_name     type  path  aru_id manufacturer model aru_type site_id tz_offset #>   <chr>         <chr> <chr> <chr>  <chr>        <chr> <chr>    <chr>   <chr>     #> 1 2020_05_04_0… wav   site… NA     Wildlife Ac… Song… SongMet… site10… NA        #> 2 2020_05_04_0… wav   site… NA     Wildlife Ac… Song… SongMet… site10… NA        #> # ℹ 2 more variables: date_time <dttm>, date <date> m$site_id #> [1] \"site100-a45\" \"site102-b56\" pat_site <- create_pattern_site_id(   prefix = \"site\", p_digits = 3,   sep = \"-\",   suffix = c(\"a\", \"b\"), s_digits = 2 ) pat_site #> [1] \"((site))((\\\\d{3}))(-)((b)|(a))((\\\\d{2}))\" m <- clean_metadata(project_files = f, pattern_site_id = pat_site) #> Extracting ARU info... #> Extracting Dates and Times... #> Identified possible problems with metadata extraction: #> ✖ No times were successfully detected (2/2) #> ✖ No ARU ids were successfully detected (2/2) m$site_id #> [1] \"site100-a45\" \"site102-b56\" test_pattern(f[1], pat_site) #> [1] \"site100-a45\" pat_aru <- create_pattern_aru_id(arus = \"s4a\", n_digits = 4)  m <- clean_metadata(   project_files = f,   pattern_site_id = pat_site,   pattern_aru_id = pat_aru,   pattern_dt_sep = \"_\" ) #> Extracting ARU info... #> Extracting Dates and Times... m #> # A tibble: 2 × 11 #>   file_name     type  path  aru_id manufacturer model aru_type site_id tz_offset #>   <chr>         <chr> <chr> <chr>  <chr>        <chr> <chr>    <chr>   <chr>     #> 1 2020_05_04_0… wav   site… s4a12… Wildlife Ac… Song… SongMet… site10… NA        #> 2 2020_05_04_0… wav   site… s4a11… Wildlife Ac… Song… SongMet… site10… NA        #> # ℹ 2 more variables: date_time <dttm>, date <date>"},{"path":[]},{"path":"https://arutools.github.io/ARUtools/dev/articles/customizing.html","id":"date-order","dir":"Articles","previous_headings":"Other options","what":"Date order","title":"Customizing `clean_metadata()`","text":"Depending date formatting, may also need specify order year, month day, addition changing pattern. Note need specify making pattern, telling function turn extracted text date. can specify one order c(\"mdy\", \"ymd\"), know multiple orders file names. particular, try avoid using mdy dmy. dates can ambiguous (example, order 05/05/2020?) may parsed correctly situations.","code":"f <- c(   \"P01-1/05042020_052500_S4A1234.wav\",   \"P01-1/05042020_054000_S4A1111.wav\" ) clean_metadata(   project_files = f,   pattern_dt_sep = \"_\",   pattern_date = create_pattern_date(order = \"mdy\"),   order_date = \"mdy\" ) #> Extracting ARU info... #> Extracting Dates and Times... #> # A tibble: 2 × 11 #>   file_name     type  path  aru_id manufacturer model aru_type site_id tz_offset #>   <chr>         <chr> <chr> <chr>  <chr>        <chr> <chr>    <chr>   <chr>     #> 1 05042020_052… wav   P01-… S4A12… Wildlife Ac… Song… SongMet… P01-1   NA        #> 2 05042020_054… wav   P01-… S4A11… Wildlife Ac… Song… SongMet… P01-1   NA        #> # ℹ 2 more variables: date_time <dttm>, date <date>"},{"path":"https://arutools.github.io/ARUtools/dev/articles/customizing.html","id":"matching-multiple-patterns","dir":"Articles","previous_headings":"Other options","what":"Matching multiple patterns","title":"Customizing `clean_metadata()`","text":"Sometimes files may use one pattern. can address problem one two ways. One option run clean_metadata() twice join outputs approach check number files end matches number expect. Another option supply multiple patterns clean_metadata() create_pattern_XXX() functions approach use depends situation. first approach means patterns matched rigid. less chance accidentally matching incorrect pattern. However, chance omitting files don’t match either pattern. second approach flexible matching patterns allows one step, convenient. However, flexible pattern , opportunities get incorrect matches date parsing. approaches, important double check results make sure ids date/times make sense.","code":"f <- c(   \"P01-1/05042020_052500_S4A1234.wav\",   \"P01-1/05042020_054000_S4A1111.wav\",   \"Site10/2020-01-01T09:00:00_BARLT100.wav\",   \"Site10/2020-01-02T09:00:00_BARLT100.wav\" ) m1 <- clean_metadata(   project_files = f,   pattern_dt_sep = \"_\",   pattern_date = create_pattern_date(order = \"mdy\"),   order_date = \"mdy\" ) #> Extracting ARU info... #> Extracting Dates and Times... #> Identified possible problems with metadata extraction: #> ✖ Not all dates were successfully detected (2/4) #> ✖ Not all times were successfully detected (2/4) #> ✖ Not all ARU ids were successfully detected (2/4) #> ✖ Not all sites were successfully detected (2/4) m1 <- filter(m1, !is.na(date_time)) # omit ones that didn't work m1 #> # A tibble: 2 × 11 #>   file_name     type  path  aru_id manufacturer model aru_type site_id tz_offset #>   <chr>         <chr> <chr> <chr>  <chr>        <chr> <chr>    <chr>   <chr>     #> 1 05042020_052… wav   P01-… S4A12… Wildlife Ac… Song… SongMet… P01-1   NA        #> 2 05042020_054… wav   P01-… S4A11… Wildlife Ac… Song… SongMet… P01-1   NA        #> # ℹ 2 more variables: date_time <dttm>, date <date>  m2 <- clean_metadata(   project_files = f,   pattern_site_id = create_pattern_site_id(prefix = \"Site\", s_digits = 0),   pattern_aru_id = create_pattern_aru_id(n_digits = 3) ) #> Extracting ARU info... #> Extracting Dates and Times... #> Identified possible problems with metadata extraction: #> ✖ Not all dates were successfully detected (1/4) #> ✖ Not all times were successfully detected (2/4) #> ✖ Not all sites were successfully detected (2/4) m2 <- filter(m2, !is.na(date_time)) # omit ones that didn't work m2 #> # A tibble: 2 × 11 #>   file_name     type  path  aru_id manufacturer model aru_type site_id tz_offset #>   <chr>         <chr> <chr> <chr>  <chr>        <chr> <chr>    <chr>   <chr>     #> 1 2020-01-01T0… wav   Site… BARLT… Frontier La… BAR-… BARLT    Site10  NA        #> 2 2020-01-02T0… wav   Site… BARLT… Frontier La… BAR-… BARLT    Site10  NA        #> # ℹ 2 more variables: date_time <dttm>, date <date>  m <- bind_rows(m1, m2) m #> # A tibble: 4 × 11 #>   file_name     type  path  aru_id manufacturer model aru_type site_id tz_offset #>   <chr>         <chr> <chr> <chr>  <chr>        <chr> <chr>    <chr>   <chr>     #> 1 05042020_052… wav   P01-… S4A12… Wildlife Ac… Song… SongMet… P01-1   NA        #> 2 05042020_054… wav   P01-… S4A11… Wildlife Ac… Song… SongMet… P01-1   NA        #> 3 2020-01-01T0… wav   Site… BARLT… Frontier La… BAR-… BARLT    Site10  NA        #> 4 2020-01-02T0… wav   Site… BARLT… Frontier La… BAR-… BARLT    Site10  NA        #> # ℹ 2 more variables: date_time <dttm>, date <date> nrow(m) #> [1] 4 m <- clean_metadata(   project_files = f,   pattern_dt_sep = c(\"_\", \"T\"),   pattern_date = create_pattern_date(order = c(\"ymd\", \"mdy\")),   order_date = c(\"ymd\", \"mdy\"),   pattern_aru_id = create_pattern_aru_id(n_digits = c(3, 4)),   pattern_site_id = create_pattern_site_id(     prefix = c(\"P\", \"Site\"),     sep = c(\"-\", \"\"),     s_digits = c(1, 0)   ) ) #> Extracting ARU info... #> Extracting Dates and Times... m #> # A tibble: 4 × 11 #>   file_name     type  path  aru_id manufacturer model aru_type site_id tz_offset #>   <chr>         <chr> <chr> <chr>  <chr>        <chr> <chr>    <chr>   <chr>     #> 1 05042020_052… wav   P01-… S4A12… Wildlife Ac… Song… SongMet… P01-1   NA        #> 2 05042020_054… wav   P01-… S4A11… Wildlife Ac… Song… SongMet… P01-1   NA        #> 3 2020-01-01T0… wav   Site… BARLT… Frontier La… BAR-… BARLT    Site10  NA        #> 4 2020-01-02T0… wav   Site… BARLT… Frontier La… BAR-… BARLT    Site10  NA        #> # ℹ 2 more variables: date_time <dttm>, date <date> check_meta(m) #> # A tibble: 3 × 11 #>   site_id aru_type  aru_id   type  n_files n_dirs n_days min_date            #>   <chr>   <chr>     <chr>    <chr>   <int>  <int>  <int> <dttm>              #> 1 P01-1   SongMeter S4A1111  wav         1      1      1 2020-05-04 05:40:00 #> 2 P01-1   SongMeter S4A1234  wav         1      1      1 2020-05-04 05:25:00 #> 3 Site10  BARLT     BARLT100 wav         2      1      2 2020-01-01 09:00:00 #> # ℹ 3 more variables: max_date <dttm>, min_time <time>, max_time <time> check_meta(m, date = TRUE) #> # A tibble: 4 × 10 #>   site_id aru_type  aru_id   type  date       n_files n_dirs n_days min_time #>   <chr>   <chr>     <chr>    <chr> <date>       <int>  <int>  <int> <time>   #> 1 P01-1   SongMeter S4A1111  wav   2020-05-04       1      1      1 05:40    #> 2 P01-1   SongMeter S4A1234  wav   2020-05-04       1      1      1 05:25    #> 3 Site10  BARLT     BARLT100 wav   2020-01-01       1      1      1 09:00    #> 4 Site10  BARLT     BARLT100 wav   2020-01-02       1      1      1 09:00    #> # ℹ 1 more variable: max_time <time> check_problems(m) #> # A tibble: 0 × 6 #> # ℹ 6 variables: path <chr>, aru_id <chr>, site_id <chr>, tz_offset <chr>, #> #   date_time <dttm>, date <date>  unique(m$site_id) #> [1] \"P01-1\"  \"Site10\" unique(m$aru_id) #> [1] \"S4A1234\"  \"S4A1111\"  \"BARLT100\""},{"path":"https://arutools.github.io/ARUtools/dev/articles/customizing.html","id":"subsetting-files","dir":"Articles","previous_headings":"Other options","what":"Subsetting files","title":"Customizing `clean_metadata()`","text":"may want extract meta data every file list directory. Possibly ’re relevant recordings, formatting issues make easier split separate groups first. can omit files using subset subset_type arguments. keep certain files, use default subset_type = \"keep\". omit certain files, use subset_type = \"omit\". keep files “” prefix (note ^ means ‘start’) omit files “” prefix","code":"clean_metadata(project_files = example_files, subset = \"^a\") #> Extracting ARU info... #> Extracting Dates and Times... #> # A tibble: 14 × 11 #>    file_name    type  path  aru_id manufacturer model aru_type site_id tz_offset #>    <chr>        <chr> <chr> <chr>  <chr>        <chr> <chr>    <chr>   <chr>     #>  1 P01_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P01_1   -0400     #>  2 P01_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P01_1   -0400     #>  3 P02_1_20200… wav   a_S4… S4A01… Wildlife Ac… Song… SongMet… P02_1   NA        #>  4 P02_1_20200… wav   a_S4… S4A01… Wildlife Ac… Song… SongMet… P02_1   NA        #>  5 P03_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P03_1   -0400     #>  6 P04_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P04_1   -0400     #>  7 P04_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P04_1   -0400     #>  8 P05_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P05_1   -0400     #>  9 P06_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P06_1   -0400     #> 10 P07_1_20200… wav   a_S4… S4A01… Wildlife Ac… Song… SongMet… P07_1   NA        #> 11 P07_1_20200… wav   a_S4… S4A01… Wildlife Ac… Song… SongMet… P07_1   NA        #> 12 P08_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P08_1   -0400     #> 13 P09_1_20200… wav   a_S4… S4A02… Wildlife Ac… Song… SongMet… P09_1   NA        #> 14 P10_1_20200… wav   a_S4… S4A03… Wildlife Ac… Song… SongMet… P10_1   NA        #> # ℹ 2 more variables: date_time <dttm>, date <date> clean_metadata(project_files = example_files, subset = \"^a\", subset_type = \"omit\") #> Extracting ARU info... #> Extracting Dates and Times... #> # A tibble: 28 × 11 #>    file_name    type  path  aru_id manufacturer model aru_type site_id tz_offset #>    <chr>        <chr> <chr> <chr>  <chr>        <chr> <chr>    <chr>   <chr>     #>  1 P01_1_20200… wav   j_BA… BARLT… Frontier La… BAR-… BARLT    P01_1   -0400     #>  2 P01_1_20200… wav   j_BA… BARLT… Frontier La… BAR-… BARLT    P01_1   -0400     #>  3 P02_1_20200… wav   j_S4… S4A01… Wildlife Ac… Song… SongMet… P02_1   NA        #>  4 P02_1_20200… wav   j_S4… S4A01… Wildlife Ac… Song… SongMet… P02_1   NA        #>  5 P03_1_20200… wav   j_BA… BARLT… Frontier La… BAR-… BARLT    P03_1   -0400     #>  6 P04_1_20200… wav   j_BA… BARLT… Frontier La… BAR-… BARLT    P04_1   -0400     #>  7 P04_1_20200… wav   j_BA… BARLT… Frontier La… BAR-… BARLT    P04_1   -0400     #>  8 P05_1_20200… wav   j_BA… BARLT… Frontier La… BAR-… BARLT    P05_1   -0400     #>  9 P06_1_20200… wav   j_BA… BARLT… Frontier La… BAR-… BARLT    P06_1   -0400     #> 10 P07_1_20200… wav   j_S4… S4A01… Wildlife Ac… Song… SongMet… P07_1   NA        #> # ℹ 18 more rows #> # ℹ 2 more variables: date_time <dttm>, date <date>"},{"path":"https://arutools.github.io/ARUtools/dev/articles/customizing.html","id":"matching-non-wave-files","dir":"Articles","previous_headings":"Other options","what":"Matching non-wave files","title":"Customizing `clean_metadata()`","text":"default clean_metadata() looks .wav files. want match something else, adjust file_type argument. wise ’ll run problems…","code":"f <- c(   \"a_BARLT10962_P01_1/P01_1_20200502T050000_ARU.mp4\",   \"a_BARLT10962_P01_1/P01_1_20200503T052000_ARU.mp4\" ) clean_metadata(project_files = f) #> Error in `clean_metadata()`: #> ! Did not find any 'wav' files. #> ℹ Use `file_type` to change file extension for sound files #> ℹ Check `project_dir`/`project_files` are correct clean_metadata(project_files = f, file_type = \"mp4\") #> Extracting ARU info... #> Extracting Dates and Times... #> # A tibble: 2 × 11 #>   file_name     type  path  aru_id manufacturer model aru_type site_id tz_offset #>   <chr>         <chr> <chr> <chr>  <chr>        <chr> <chr>    <chr>   <chr>     #> 1 P01_1_202005… mp4   a_BA… BARLT… Frontier La… BAR-… BARLT    P01_1   NA        #> 2 P01_1_202005… mp4   a_BA… BARLT… Frontier La… BAR-… BARLT    P01_1   NA        #> # ℹ 2 more variables: date_time <dttm>, date <date>"},{"path":"https://arutools.github.io/ARUtools/dev/articles/customizing.html","id":"look-arounds","dir":"Articles","previous_headings":"Other options","what":"Look arounds","title":"Customizing `clean_metadata()`","text":"cases identifying lies string interest can help extracting pattern interest. Details look arounds can found “stringr” package website. following code shows set files contain repeated patterns match site project folders. run clean_metadata() fails detect dates times. Even worse, returns wrong site_id values. tackle site_id issue can add look behind clue directory site_id always ends “202223/”. corrects site_id values generic “pattern_aru_id” means clean_metadata() fails detect dates time “pattern_aru_id” excluded looking dates times. end look arounds helped us pull stubborn site_id vaules separate overlapping patterns aru_id dates times.","code":"f <- c(   \"//BARLTs/DeploymentProjectXYZsites_202223/XYZBrantAirstrip/20230519_RemoteTrip2223/00015998_20230519T210900-0400_SS23.wav\",   \"//BARLTs/DeploymentProjectXYZsites_202223/XYZPermafrostPFSC-SP1/20230415_RemoteTrip2223/00015321_20230415T214700-0400_Owls23.wav\",   \"//BARLTs/DeploymentProjectXYZsites_202223/XYZfoxden30/20230623_RemoteTrip2223/00015370_20230623T062000-0400_SR23.wav\",   \"//BARLTs/DeploymentProjectXYZsites_202223/XYZfoxden107/20220922_RemoteTrip2223/00016130_20220922T000200-0400_NFC22.wav\",   \"//BARLTs/DeploymentProjectXYZsites_00202223/XYZfoxden107/20230711_RemoteTrip2223/00016130_20230711T093600-0400_SR23.wav\" )  m <- clean_metadata(   project_files = f,   pattern_site_id = create_pattern_site_id(prefix = \"XYZ\\\\w+\", p_digits = 0:3, sep = c(\"\", \"-\"), s_digits = 0:1),   pattern_aru_id = create_pattern_aru_id(arus = \"\", n_digits = 8), quiet = T ) #> Identified possible problems with metadata extraction: #> ✖ No dates were successfully detected (5/5) #> ✖ No times were successfully detected (5/5) m$site_id #> [1] \"XYZsites_202223\"   \"XYZsites_202223\"   \"XYZsites_202223\"   #> [4] \"XYZsites_202223\"   \"XYZsites_00202223\" m_site_id_fix <- clean_metadata(   project_files = f,   pattern_site_id = create_pattern_site_id(     prefix = \"XYZ\\\\w+\", p_digits = 0:3, sep = c(\"\", \"-\"), s_digits = 0:1,     look_behind = \"202223/\"   ),   pattern_aru_id = create_pattern_aru_id(arus = \"\", n_digits = 8), quiet = T ) #> Identified possible problems with metadata extraction: #> ✖ No dates were successfully detected (5/5) #> ✖ No times were successfully detected (5/5)  m_site_id_fix$site_id #> [1] \"XYZBrantAirstrip\"  \"XYZPermafrostPFSC\" \"XYZfoxden30\"       #> [4] \"XYZfoxden107\"      \"XYZfoxden107\" m_fix <- clean_metadata(   project_files = f,   pattern_site_id = create_pattern_site_id(     prefix = \"XYZ\\\\w+\", p_digits = 0:3, sep = c(\"\", \"-\"), s_digits = 0:1,     look_behind = \"202223/\"   ),   pattern_aru_id = create_pattern_aru_id(arus = \"\", n_digits = 8,                                           sep = \"\",                                           look_behind = \"RemoteTrip2223/\",                                           look_ahead = \"_\"),   quiet = T )"},{"path":"https://arutools.github.io/ARUtools/dev/articles/spatial.html","id":"problems","dir":"Articles","previous_headings":"","what":"Problems","title":"Working with spatial data","text":"However, sometimes spatial data sets might trickier use. example, sf spatial data sets missing coordinates, meaning using add_sites() function, ’ll get warning data frame back try add incomplete list sites. resolve , either add missing site information, omit files joining. Fixed!","code":"m <- clean_metadata(project_files = example_files) #> Extracting ARU info... #> Extracting Dates and Times...  sites <- st_as_sf(example_sites, coords = c(\"lon\", \"lat\"), crs = 4326) |>   clean_site_index(     name_aru_id = \"ARU\",     name_site_id = \"Sites\",     name_date_time = c(\"Date_set_out\", \"Date_removed\")   ) #> There are overlapping date ranges #> • Shifting start/end times to 'noon' #> • Skip this with `resolve_overlaps = FALSE`  sites <- sites[-1, ] # Omit that first site  m <- add_sites(m, sites) #> Joining by columns `date_time_start` and `date_time_end` #> Identified possible problems with metadata extraction: #> ✖ Not all files were matched to a site reference (6/42) #> • Consider adjusting the `by` argument #> Warning in add_sites(m, sites): Cannot have missing coordinates in spatial data frames #> • Returning non-spatial data frame m #> # A tibble: 42 × 13 #>    file_name    type  path  aru_id manufacturer model aru_type site_id tz_offset #>    <chr>        <chr> <chr> <chr>  <chr>        <chr> <chr>    <chr>   <chr>     #>  1 P01_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P01_1   -0400     #>  2 P01_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P01_1   -0400     #>  3 P02_1_20200… wav   a_S4… S4A01… Wildlife Ac… Song… SongMet… P02_1   NA        #>  4 P02_1_20200… wav   a_S4… S4A01… Wildlife Ac… Song… SongMet… P02_1   NA        #>  5 P03_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P03_1   -0400     #>  6 P04_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P04_1   -0400     #>  7 P04_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P04_1   -0400     #>  8 P05_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P05_1   -0400     #>  9 P06_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P06_1   -0400     #> 10 P07_1_20200… wav   a_S4… S4A01… Wildlife Ac… Song… SongMet… P07_1   NA        #> # ℹ 32 more rows #> # ℹ 4 more variables: date_time <dttm>, date <date>, longitude <dbl>, #> #   latitude <dbl> m <- clean_metadata(project_files = example_files) |>   filter(date > \"2020-05-03\") # Filter out recordings that don't match a site #> Extracting ARU info... #> Extracting Dates and Times...  m <- add_sites(m, sites) #> Joining by columns `date_time_start` and `date_time_end` m #> Simple feature collection with 36 features and 11 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: -91.38 ymin: 45 xmax: -84.45 ymax: 52.68 #> Geodetic CRS:  WGS 84 #> # A tibble: 36 × 12 #>    file_name    type  path  aru_id manufacturer model aru_type site_id tz_offset #>  * <chr>        <chr> <chr> <chr>  <chr>        <chr> <chr>    <chr>   <chr>     #>  1 P02_1_20200… wav   a_S4… S4A01… Wildlife Ac… Song… SongMet… P02_1   NA        #>  2 P02_1_20200… wav   a_S4… S4A01… Wildlife Ac… Song… SongMet… P02_1   NA        #>  3 P03_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P03_1   -0400     #>  4 P04_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P04_1   -0400     #>  5 P04_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P04_1   -0400     #>  6 P05_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P05_1   -0400     #>  7 P06_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P06_1   -0400     #>  8 P07_1_20200… wav   a_S4… S4A01… Wildlife Ac… Song… SongMet… P07_1   NA        #>  9 P07_1_20200… wav   a_S4… S4A01… Wildlife Ac… Song… SongMet… P07_1   NA        #> 10 P08_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P08_1   -0400     #> # ℹ 26 more rows #> # ℹ 3 more variables: date_time <dttm>, date <date>, geometry <POINT [°]>"},{"path":"https://arutools.github.io/ARUtools/dev/articles/timezones.html","id":"what-timezone-are-my-data-in","dir":"Articles","previous_headings":"","what":"What timezone are my data in?","title":"Dealing with Timezones","text":"ask R timezone data , R say “UTC” ’s probably really case. three possible options timezones might look like: times timezone programmed ARUs set . likely either timezone region deployed, timezone lab home base (doesn’t really matter , long ’re know one ). several different timezones among recordings, correspond deployed. likely happen ARUs set use GPS get timezone study area straddled timezone boundary. several different timezones among recordings, correspond deployed. might happen timezones set ARUs different projects corrected deployment. ARUtools, options deal withe first two scenarios. However, find third scenario, best thing split files timezone run workflow individually batch.","code":"tz(m$date_time) #> [1] \"UTC\""},{"path":"https://arutools.github.io/ARUtools/dev/articles/timezones.html","id":"calculating-time-to-sunrisesunset","dir":"Articles","previous_headings":"","what":"Calculating time to sunrise/sunset","title":"Dealing with Timezones","text":"simplicity, don’t need worry ‘real’ timezone except calculate time sunrise/sunset. ’s important know timezone patterns data. first scenario, know recordings timezone know timezone . can specify timezone specifically: Alternatively, second scenario, know timezones may different, importantly, correspond location unit deployed. can use aru_tz = \"local\" calc_sun() use recording coordinates figure timezone . Finally, final scenario, know timezones , correspond location unit deployed. case ’ll split data use specific timezones. Let’s assume know timezones sites P06_1 P09_1 Central, rest Eastern. actually use timezone sites located , compare m_joint m_local ’ll see exception timezone called results (“America/Detroit” timezone “America/Toronto”). ’ll also note Eastern timezone (America/Toronto America/Detroit), match m_est.","code":"m_est <- calc_sun(m, aru_tz = \"America/Toronto\") m_local <- calc_sun(m, aru_tz = \"local\") # Split by timezone m1 <- filter(m, site_id %in% c(\"P06_1\", \"P09_1\")) # Get P06_1 and P09_1 m2 <- filter(m, !site_id %in% c(\"P06_1\", \"P09_1\")) # Get all except the above  # Calculate time to sunrise/sunset individually m1_cst <- calc_sun(m1, aru_tz = \"America/Winnipeg\") m2_est <- calc_sun(m2, aru_tz = \"America/Toronto\")  # Join them back in m_joint <- bind_rows(m1_cst, m2_est)"},{"path":"https://arutools.github.io/ARUtools/dev/articles/timezones.html","id":"important-things-to-note","dir":"Articles","previous_headings":"","what":"Important things to note","title":"Dealing with Timezones","text":"timezone recordings, must site index, won’t join properly add_sites() Unless know timezones match deployment location, must know timezone recordings made . calc_sun() returns relative time sunrise sunset, ’s important know timezone recording , ’s important timezone matches ’s deployment area.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/articles/timezones.html","id":"an-example","dir":"Articles","previous_headings":"","what":"An example","title":"Dealing with Timezones","text":"Let’s assume two sites, one Eastern timezone, one Western. However, programmed record 4am, 5am 6am Eastern. ’ll first use example data create mini meta data set. now calculate time sunrise/sunset (t2sr t2ss) find difference sites 15min, accounting fact site P06_1 farther west P01_1 recording 6am occurs 28.8min sunrise, whereas P01_1’s 6am recording occurs 14.9 min sunrise. However, incorrectly assume ARU unit located central timezone recording timezone, get different results. times sunrise/sunset site P06_1 offset hour, ’re assuming wrong timezone (hour different correct one). Therefore take home need two things: make sure timezones match recordings site index know timezones (least can derived coordinates).","code":"m_mini <- filter(m, site_id %in% c(\"P01_1\", \"P06_1\")) |>   select(aru_id, site_id, longitude, latitude) |>   distinct() |>   cross_join(data.frame(date_time = c(     \"2020-05-02 05:00:00\",     \"2020-05-02 06:00:00\",     \"2020-05-02 07:00:00\"   ))) |>   mutate(     date = as_date(date_time),     path = paste0(aru_id, \"_\", site_id, \"_\", hour(date_time), \".csv\")   ) calc_sun(m_mini, aru_tz = \"America/Toronto\") |>   arrange(date_time) #> # A tibble: 6 × 10 #>   aru_id   site_id longitude latitude date_time           date       path  tz    #>   <chr>    <chr>       <dbl>    <dbl> <dttm>              <date>     <chr> <chr> #> 1 BARLT10… P01_1       -85.0     50.0 2020-05-02 05:00:00 2020-05-02 BARL… Amer… #> 2 BARLT10… P06_1       -90.1     52   2020-05-02 05:00:00 2020-05-02 BARL… Amer… #> 3 BARLT10… P01_1       -85.0     50.0 2020-05-02 06:00:00 2020-05-02 BARL… Amer… #> 4 BARLT10… P06_1       -90.1     52   2020-05-02 06:00:00 2020-05-02 BARL… Amer… #> 5 BARLT10… P01_1       -85.0     50.0 2020-05-02 07:00:00 2020-05-02 BARL… Amer… #> 6 BARLT10… P06_1       -90.1     52   2020-05-02 07:00:00 2020-05-02 BARL… Amer… #> # ℹ 2 more variables: t2sr <dbl>, t2ss <dbl> calc_sun(m_mini, aru_tz = \"local\") |>   arrange(date_time) #> # A tibble: 6 × 10 #>   aru_id   site_id longitude latitude date_time           date       path  tz    #>   <chr>    <chr>       <dbl>    <dbl> <dttm>              <date>     <chr> <chr> #> 1 BARLT10… P01_1       -85.0     50.0 2020-05-02 05:00:00 2020-05-02 BARL… Amer… #> 2 BARLT10… P06_1       -90.1     52   2020-05-02 05:00:00 2020-05-02 BARL… Amer… #> 3 BARLT10… P01_1       -85.0     50.0 2020-05-02 06:00:00 2020-05-02 BARL… Amer… #> 4 BARLT10… P06_1       -90.1     52   2020-05-02 06:00:00 2020-05-02 BARL… Amer… #> 5 BARLT10… P01_1       -85.0     50.0 2020-05-02 07:00:00 2020-05-02 BARL… Amer… #> 6 BARLT10… P06_1       -90.1     52   2020-05-02 07:00:00 2020-05-02 BARL… Amer… #> # ℹ 2 more variables: t2sr <dbl>, t2ss <dbl>"},{"path":"https://arutools.github.io/ARUtools/dev/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"David Hope. Author, maintainer. Steffi LaZerte. Author. Government Canada. Copyright holder, funder.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Hope, David Steffi LaZerte. ARUtools: package ARU data. https://github.com/arutools/ARUtools","code":"@Manual{,   title = {ARUtools: a package for ARU data},   author = {David Hope and Steffi LaZerte},   year = {2024},   url = {https://github.com/arutools/ARUtools}, }"},{"path":"https://arutools.github.io/ARUtools/dev/index.html","id":"arutools-","dir":"","previous_headings":"","what":"Management and Processing of Autonomous Recording Unit (ARU) Data","title":"Management and Processing of Autonomous Recording Unit (ARU) Data","text":"goal ARUtools facilitate processing ARU data subsampling recordings. Parse Autonomous Recording Unit (ARU) data sub-sampling recordings. Extract Metadata recordings, select subset recordings interpretation, prepare files processing ‘WildTrax’ https://wildtrax.ca/ platform. Read process metadata recordings collected using SongMeter BAR-LT types ARUs.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Management and Processing of Autonomous Recording Unit (ARU) Data","text":"easiest way install ARUtools ","code":"install.packages(\"ARUtools\")"},{"path":"https://arutools.github.io/ARUtools/dev/index.html","id":"development-version","dir":"","previous_headings":"Installation","what":"Development version","title":"Management and Processing of Autonomous Recording Unit (ARU) Data","text":"can install current version ARUtools R-universe repository. Alternatively can build install package GitHub code . need Rtools installed first: Using “remotes”","code":"install.packages(\"ARUtools\",                  repos = c(\"https://arutools.r-universe.dev\",                            \"https://cran.r-project.org\") ) # install.packages(\"pak\") # Uncomment if you don't have remotes installed. pak::pak(\"arutools/ARUtools\") # install.packages(\"remotes\") remotes::install_github(\"arutools/ARUtools\")"},{"path":"https://arutools.github.io/ARUtools/dev/index.html","id":"learn-to-use","dir":"","previous_headings":"","what":"Learn to use","title":"Management and Processing of Autonomous Recording Unit (ARU) Data","text":"easiest way dig using ARUtools package using documentation webpage currently six vignettes help get running cleaning ARU metadata Getting started ARUtools (vignette(\"ARUtools\")) Customizing clean_metadata() (vignette(\"customizing\")) Dealing timezones (vignette(\"timezones\")) Working spatial data (vignette(\"spatial\")) Subsampling recordings (vignette(\"SubSample\")) useful functions (vignette(\"Misc\") )","code":""},{"path":"https://arutools.github.io/ARUtools/dev/index.html","id":"provide-feedback","dir":"","previous_headings":"","what":"Provide feedback","title":"Management and Processing of Autonomous Recording Unit (ARU) Data","text":"run problems ideas extensions, please don’t hesitate submit issue.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/index.html","id":"motivation-and-limitations","dir":"","previous_headings":"","what":"Motivation and limitations","title":"Management and Processing of Autonomous Recording Unit (ARU) Data","text":"package initially started life series scripts process recordings multiple large projects around monitoring migratory bird populations Ontario’s North. Moving scripts package stemmed following wise advice Hadley Wickham: good rule thumb consider writing function whenever ’ve copied pasted block code twice (.e. now three copies code). multiple projects, data issues, became clear either require copy/pasting lot code likely break something developing series functions shared across projects (.e. package). initial version code usable , ’re using package, fantastic work Steffi LaZerte translated mess user-friendly functions see today. However, due variable nature data management, possible ARUtools may work well project. run issues, please submit issue. also good packages may use : wildRtrax (R)  warbleR (R) emu (command line) SoX (command line) Sound-Extraction (python)","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/ARUtools.html","id":null,"dir":"Reference","previous_headings":"","what":"ARUtools: Management and Processing of Autonomous Recording Unit (ARU) Data — ARUtools","title":"ARUtools: Management and Processing of Autonomous Recording Unit (ARU) Data — ARUtools","text":"Parse Autonomous Recording Unit (ARU) data sub-sampling recordings. Extract Metadata recordings, select subset recordings interpretation, prepare files processing WildTrax https://wildtrax.ca/ platform. Read process metadata recordings collected using Song Meter BAR-LT types ARUs.","code":""},{"path":[]},{"path":"https://arutools.github.io/ARUtools/dev/reference/ARUtools.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"ARUtools: Management and Processing of Autonomous Recording Unit (ARU) Data — ARUtools","text":"Maintainer: David Hope david.hope@ec.gc.ca (ORCID) Authors: Steffi LaZerte sel@steffilazerte.ca (ORCID) contributors: Government Canada [copyright holder, funder]","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/acoustic_indices.html","id":null,"dir":"Reference","previous_headings":"","what":"Get acoustic complexity values — acoustic_indices","title":"Get acoustic complexity values — acoustic_indices","text":"Wrapper 'soundecology' package calculate acoustic complexity, bioacoustic index, acoustic diversity. See Value details indices.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/acoustic_indices.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get acoustic complexity values — acoustic_indices","text":"","code":"acoustic_indices(   path,   min_freq = NA,   max_freq = NA,   units = \"samples\",   quiet = FALSE )"},{"path":"https://arutools.github.io/ARUtools/dev/reference/acoustic_indices.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get acoustic complexity values — acoustic_indices","text":"path Character. Path wave file. min_freq Numeric. Minimum frequency acoustic complexity (see soundecology::acoustic_complexity()) max_freq Numeric. Maximum frequency acoustic complexity (see soundecology::acoustic_complexity()) units Character. Wave file units reading file. Defaults \"samples\" (see tuneR::readWave()). quiet Logical. Whether suppress progress messages non-essential updates.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/acoustic_indices.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get acoustic complexity values — acoustic_indices","text":"Returns data frame acoustic indices. prefaced complx_ soundecology::acoustic_complexity() bio_ soundecology::bioacoustic_index() div_ soundecology::acoustic_diversity()","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/acoustic_indices.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get acoustic complexity values — acoustic_indices","text":"","code":"w <- tuneR::sine(440, duration = 300000) # > 5s tuneR::writeWave(w, \"test_wave.wav\") acoustic_indices(\"test_wave.wav\") #> Calculating acoustic indices for test_wave.wav #>  #>  max_freq not set, using value of: 22050  #>  #>  #>  min_freq not set, using value of: 0  #>  #>  #>  This is a mono file. #>  #>  Calculating index. Please wait...  #>  #>   Acoustic Complexity Index (total): 134.1618 #>  #>  #>  This is a mono file. #>  #>  Calculating index. Please wait...  #>  #>   Bioacoustic Index: 10.97814 #>  #>  #>  This is a mono file. #>  #>  Calculating index. Please wait...  #>  #>   Acoustic Diversity Index: 0 #> # A tibble: 10 × 13 #>    file      complx_AciTotAll_left complx_AciTotAll_right complx_AciTotAll_lef…¹ #>    <chr>                     <dbl> <lgl>                                   <dbl> #>  1 test_wav…                  134. NA                                      1183. #>  2 test_wav…                  134. NA                                      1183. #>  3 test_wav…                  134. NA                                      1183. #>  4 test_wav…                  134. NA                                      1183. #>  5 test_wav…                  134. NA                                      1183. #>  6 test_wav…                  134. NA                                      1183. #>  7 test_wav…                  134. NA                                      1183. #>  8 test_wav…                  134. NA                                      1183. #>  9 test_wav…                  134. NA                                      1183. #> 10 test_wav…                  134. NA                                      1183. #> # ℹ abbreviated name: ¹​complx_AciTotAll_left_bymin #> # ℹ 9 more variables: complx_AciTotAll_right_bymin <lgl>, bio_left_area <dbl>, #> #   bio_right_area <lgl>, div_adi_left <dbl>, div_adi_right <lgl>, #> #   div_left_band_values <dbl>, div_right_band_values <lgl>, #> #   div_left_bandrange_values <chr>, div_right_bandrange_values <lgl> acoustic_indices(\"test_wave.wav\", quiet = TRUE) #> # A tibble: 10 × 13 #>    file      complx_AciTotAll_left complx_AciTotAll_right complx_AciTotAll_lef…¹ #>    <chr>                     <dbl> <lgl>                                   <dbl> #>  1 test_wav…                  134. NA                                      1183. #>  2 test_wav…                  134. NA                                      1183. #>  3 test_wav…                  134. NA                                      1183. #>  4 test_wav…                  134. NA                                      1183. #>  5 test_wav…                  134. NA                                      1183. #>  6 test_wav…                  134. NA                                      1183. #>  7 test_wav…                  134. NA                                      1183. #>  8 test_wav…                  134. NA                                      1183. #>  9 test_wav…                  134. NA                                      1183. #> 10 test_wav…                  134. NA                                      1183. #> # ℹ abbreviated name: ¹​complx_AciTotAll_left_bymin #> # ℹ 9 more variables: complx_AciTotAll_right_bymin <lgl>, bio_left_area <dbl>, #> #   bio_right_area <lgl>, div_adi_left <dbl>, div_adi_right <lgl>, #> #   div_left_band_values <dbl>, div_right_band_values <lgl>, #> #   div_left_bandrange_values <chr>, div_right_bandrange_values <lgl> unlink(\"test_wave.wav\")"},{"path":"https://arutools.github.io/ARUtools/dev/reference/add_pattern_aru_type.html","id":null,"dir":"Reference","previous_headings":"","what":"Add an ARU to the list of identified ARUs — add_pattern_aru_type","title":"Add an ARU to the list of identified ARUs — add_pattern_aru_type","text":"Add ARU list identified ARUs","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/add_pattern_aru_type.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add an ARU to the list of identified ARUs — add_pattern_aru_type","text":"","code":"add_pattern_aru_type(pattern, aru_type)"},{"path":"https://arutools.github.io/ARUtools/dev/reference/add_pattern_aru_type.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add an ARU to the list of identified ARUs — add_pattern_aru_type","text":"pattern regular expression extract file path aru_type Name ARUtype","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/add_pattern_aru_type.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add an ARU to the list of identified ARUs — add_pattern_aru_type","text":"","code":"org_pat <- get_pattern(\"pattern_aru_type\")  print(org_pat) #>             barlt               SMM           SM(\\\\d)           S(\\\\d)A  #>          \"BAR-LT\" \"Song Meter Mini\"  \"Song Meter \\\\1\"  \"Song Meter \\\\1\"   add_pattern_aru_type(\"CWS\\\\d\", \"Canadian Wildlife Detector \\1\")  get_pattern(\"pattern_aru_type\") #>                             barlt                               SMM  #>                          \"BAR-LT\"                 \"Song Meter Mini\"  #>                           SM(\\\\d)                           S(\\\\d)A  #>                  \"Song Meter \\\\1\"                  \"Song Meter \\\\1\"  #>                            CWS\\\\d  #> \"Canadian Wildlife Detector \\001\"   set_pattern(\"pattern_aru_type\", org_pat)"},{"path":"https://arutools.github.io/ARUtools/dev/reference/add_sites.html","id":null,"dir":"Reference","previous_headings":"","what":"Add site-level data to the metadata — add_sites","title":"Add site-level data to the metadata — add_sites","text":"Uses dates join site-level data (coordinates site ids) meta data. site data single dates, buffer used determine recordings belong site observation. Can join site ids alone set by_date = NULL.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/add_sites.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add site-level data to the metadata — add_sites","text":"","code":"add_sites(   meta,   sites,   buffer_before = 0,   buffer_after = NULL,   by = c(\"site_id\", \"aru_id\"),   by_date = \"date_time\",   quiet = FALSE )"},{"path":"https://arutools.github.io/ARUtools/dev/reference/add_sites.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add site-level data to the metadata — add_sites","text":"meta Data frame. Recording metadata. Output clean_metadata(). sites Data frame. Site-level data clean_site_index(). buffer_before Numeric. Number hours deployment include recordings. NULL means include time last deployment. Coupled buffer_after, creates window around date/time join recordings site-level data. Ignored sites start end column date/times. Default 0. buffer_after Numeric. Number hours deployment include recordings. NULL means include time next deployment. Coupled buffer_before, creates window around date/time join recordings site-level data. Ignored sites start end column date/times. Default NULL. Character. Columns identify deployment sites well meta, besides date/time, used join data. Default site_id aru_id. by_date Character. Date/time type join data . date faster date_time precise. Default date_time. NULL means ignore dates join columns (dplyr::left_join()). quiet Logical. Whether suppress progress messages non-essential updates.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/add_sites.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add site-level data to the metadata — add_sites","text":"data frame metadata site-level data joined .","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/add_sites.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add site-level data to the metadata — add_sites","text":"","code":"m <- clean_metadata(project_files = example_files) #> Extracting ARU info... #> Extracting Dates and Times... s <- clean_site_index(example_sites_clean,   name_date = c(\"date_time_start\", \"date_time_end\") ) m <- add_sites(m, s) #> Joining by columns `date_time_start` and `date_time_end`  # Without dates (by site only) m <- clean_metadata(project_files = example_files) #> Extracting ARU info... #> Extracting Dates and Times... eg <- dplyr::select(example_sites_clean, -date_time_start, -date_time_end) s <- clean_site_index(eg, name_date_time = NULL) m <- add_sites(m, s, by_date = NULL) #> Ignoring dates - Joining with `by` columns only (`by_date == NULL`)"},{"path":"https://arutools.github.io/ARUtools/dev/reference/add_wildtrax.html","id":null,"dir":"Reference","previous_headings":"","what":"Add file name formated for Wildtrax to metadata — add_wildtrax","title":"Add file name formated for Wildtrax to metadata — add_wildtrax","text":"Create append file name appropriate uploading data Wildtrax platform https://wildtrax.ca/.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/add_wildtrax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add file name formated for Wildtrax to metadata — add_wildtrax","text":"","code":"add_wildtrax(meta)"},{"path":"https://arutools.github.io/ARUtools/dev/reference/add_wildtrax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add file name formated for Wildtrax to metadata — add_wildtrax","text":"meta Data frame. Recording metadata. Output clean_metadata().","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/add_wildtrax.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add file name formated for Wildtrax to metadata — add_wildtrax","text":"Data frame metadata appended column WildTrax appropriate file names.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/add_wildtrax.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add file name formated for Wildtrax to metadata — add_wildtrax","text":"","code":"m <- clean_metadata(project_files = example_files) #> Extracting ARU info... #> Extracting Dates and Times... m <- add_wildtrax(m) m #> # A tibble: 42 × 12 #>    file_name    type  path  aru_id manufacturer model aru_type site_id tz_offset #>    <chr>        <chr> <chr> <chr>  <chr>        <chr> <chr>    <chr>   <chr>     #>  1 P01_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P01_1   -0400     #>  2 P01_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P01_1   -0400     #>  3 P02_1_20200… wav   a_S4… S4A01… Wildlife Ac… Song… SongMet… P02_1   NA        #>  4 P02_1_20200… wav   a_S4… S4A01… Wildlife Ac… Song… SongMet… P02_1   NA        #>  5 P03_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P03_1   -0400     #>  6 P04_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P04_1   -0400     #>  7 P04_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P04_1   -0400     #>  8 P05_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P05_1   -0400     #>  9 P06_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P06_1   -0400     #> 10 P07_1_20200… wav   a_S4… S4A01… Wildlife Ac… Song… SongMet… P07_1   NA        #> # ℹ 32 more rows #> # ℹ 3 more variables: date_time <dttm>, date <date>, wildtrax_file_name <glue>"},{"path":"https://arutools.github.io/ARUtools/dev/reference/calc_selection_weights.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Selection Weights — calc_selection_weights","title":"Calculate Selection Weights — calc_selection_weights","text":"Calculate selection weights series recordings based selection parameters defined sim_selection_weights().","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/calc_selection_weights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Selection Weights — calc_selection_weights","text":"","code":"calc_selection_weights(   meta_sun,   params,   col_site_id = site_id,   col_min = t2sr,   col_day = date )"},{"path":"https://arutools.github.io/ARUtools/dev/reference/calc_selection_weights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Selection Weights — calc_selection_weights","text":"meta_sun (Spatial) Data frame. Recording meta data time sunrise/sunset. Output calc_sun(). Must least col_min, col_day, col_site_id. params Named list. Parameters created sim_selection_weights(), containing min_range, min_mean, min_sd, day_range, day_mean, day_sd, offset, return_log, selection_fun. col_site_id Column. Unquoted column containing site strata IDs (defaults site_id). col_min Column. Unquoted column containing minutes sunrise (t2sr) sunset (t2ss) output calc_sun() (defaults t2sr). col_day Column. Unquoted column containing dates day--year (doy) use (defaults date).","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/calc_selection_weights.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Selection Weights — calc_selection_weights","text":"Returns data appended selection weights columns: psel_by - minutes column used psel_min - Probability selection time day (min column) psel_doy - Probability selection day year psel - Probability selection overall psel_scaled - Probability selection scaled overall psel_std - Probability selection standardized within site psel_normalized - Probability selection normalized within site","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/calc_selection_weights.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Selection Weights — calc_selection_weights","text":"","code":"s <- clean_site_index(example_sites_clean,   name_date_time = c(\"date_time_start\", \"date_time_end\") ) m <- clean_metadata(project_files = example_files) |>   add_sites(s) |>   calc_sun() #> Extracting ARU info... #> Extracting Dates and Times... #> Joining by columns `date_time_start` and `date_time_end`  params <- sim_selection_weights()  calc_selection_weights(m, params = params) #> # A tibble: 27 × 24 #>    file_name    type  path  aru_id manufacturer model aru_type site_id tz_offset #>    <chr>        <chr> <chr> <chr>  <chr>        <chr> <chr>    <chr>   <chr>     #>  1 P01_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P01_1   -0400     #>  2 P02_1_20200… wav   a_S4… S4A01… Wildlife Ac… Song… SongMet… P02_1   NA        #>  3 P02_1_20200… wav   a_S4… S4A01… Wildlife Ac… Song… SongMet… P02_1   NA        #>  4 P03_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P03_1   -0400     #>  5 P06_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P06_1   -0400     #>  6 P07_1_20200… wav   a_S4… S4A01… Wildlife Ac… Song… SongMet… P07_1   NA        #>  7 P07_1_20200… wav   a_S4… S4A01… Wildlife Ac… Song… SongMet… P07_1   NA        #>  8 P08_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P08_1   -0400     #>  9 P09_1_20200… wav   a_S4… S4A02… Wildlife Ac… Song… SongMet… P09_1   NA        #> 10 P01_1_20200… wav   j_BA… BARLT… Frontier La… BAR-… BARLT    P01_1   -0400     #> # ℹ 17 more rows #> # ℹ 15 more variables: date_time <dttm>, date <date>, longitude <dbl>, #> #   latitude <dbl>, tz <chr>, t2sr <dbl>, t2ss <dbl>, doy <dbl>, psel_by <chr>, #> #   psel_min <dbl>, psel_doy <dbl>, psel <dbl>, psel_scaled <dbl>, #> #   psel_std <dbl>, psel_normalized <dbl>"},{"path":"https://arutools.github.io/ARUtools/dev/reference/calc_sun.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate time to sunrise/sunset — calc_sun","title":"Calculate time to sunrise/sunset — calc_sun","text":"Calculate sunrise/sunset sound file day , day day get nearest sunrise recording. Times calculated using 'suncalc' package.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/calc_sun.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate time to sunrise/sunset — calc_sun","text":"","code":"calc_sun(meta_sites, aru_tz = \"local\")"},{"path":"https://arutools.github.io/ARUtools/dev/reference/calc_sun.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate time to sunrise/sunset — calc_sun","text":"meta_sites (Spatial) Data frame. Recording metadata added coordinates. Output clean_metadata() add_sites() (either clean_gps() clean_site_index()). aru_tz Character. Must either \"local\" timezone listed OlsonNames(). See Details.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/calc_sun.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate time to sunrise/sunset — calc_sun","text":"Data frame metadata added timezone recording time (tz), time sunrise/sunset (t2sr, t2ss).","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/calc_sun.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate time to sunrise/sunset — calc_sun","text":"Timezones. ensure sunrise/sunset times calculated correctly relative time recording, need know timezone date/time recording. ARUs calibrated specific timezone going field, can specified using, example, aru_tz = \"America/Toronto\". hand ARU calibrated whichever timezone local deployed use aru_tz = \"local\". specific timezone calculated individually based longitude latitude recording.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/calc_sun.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate time to sunrise/sunset — calc_sun","text":"","code":"s <- clean_site_index(example_sites_clean,   name_date = c(\"date_time_start\", \"date_time_end\") ) m <- clean_metadata(project_files = example_files) |>   add_sites(s) #> Extracting ARU info... #> Extracting Dates and Times... #> Joining by columns `date_time_start` and `date_time_end` calc_sun(m) #> # A tibble: 42 × 16 #>    file_name    type  path  aru_id manufacturer model aru_type site_id tz_offset #>    <chr>        <chr> <chr> <chr>  <chr>        <chr> <chr>    <chr>   <chr>     #>  1 P01_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P01_1   -0400     #>  2 P01_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P01_1   -0400     #>  3 P02_1_20200… wav   a_S4… S4A01… Wildlife Ac… Song… SongMet… P02_1   NA        #>  4 P02_1_20200… wav   a_S4… S4A01… Wildlife Ac… Song… SongMet… P02_1   NA        #>  5 P03_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P03_1   -0400     #>  6 P04_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P04_1   -0400     #>  7 P04_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P04_1   -0400     #>  8 P05_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P05_1   -0400     #>  9 P06_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P06_1   -0400     #> 10 P07_1_20200… wav   a_S4… S4A01… Wildlife Ac… Song… SongMet… P07_1   NA        #> # ℹ 32 more rows #> # ℹ 7 more variables: date_time <dttm>, date <date>, longitude <dbl>, #> #   latitude <dbl>, tz <chr>, t2sr <dbl>, t2ss <dbl>"},{"path":"https://arutools.github.io/ARUtools/dev/reference/check_file.html","id":null,"dir":"Reference","previous_headings":"","what":"Explore a file — check_file","title":"Explore a file — check_file","text":"Shows first lines text file. Useful trying understand problems GPS files.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/check_file.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Explore a file — check_file","text":"","code":"check_file(file_name, n_max = 10, ...)"},{"path":"https://arutools.github.io/ARUtools/dev/reference/check_file.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Explore a file — check_file","text":"file_name Character. File path check. n_max Numeric. Number lines file show. Default 10. ... Arguments passed readr::read_lines()","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/check_file.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Explore a file — check_file","text":"character vector one element line","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/check_file.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Explore a file — check_file","text":"Wrapper around readr::read_lines(n_max).","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/check_file.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Explore a file — check_file","text":"","code":"f <- system.file(\"extdata\", \"logfile_00015141_SD1.txt\", package = \"ARUtools\") check_file(f) #>  [1] \"\"                                                            #>  [2] \"-----------------------------------------------------------\" #>  [3] \" FRONTIER LABS Bioacoustic Audio Recorder \"                  #>  [4] \" Serial Number: 00015141\"                                    #>  [5] \" Config: Stereo, Ext-power\"                                  #>  [6] \" Firmware: 3.30 (Jul 20 2021 15:53:03)\"                      #>  [7] \"-----------------------------------------------------------\" #>  [8] \"2022-05-27 11:24:03 SD Card format successful\"               #>  [9] \"2022-05-27 11:24:04 SD Card 1 removed!\"                      #> [10] \"2022-05-27 11:24:04 SD Card 1 inserted!\""},{"path":"https://arutools.github.io/ARUtools/dev/reference/check_meta.html","id":null,"dir":"Reference","previous_headings":"","what":"Check output of clean_metadata() — check_meta","title":"Check output of clean_metadata() — check_meta","text":"Cleaning metadata can take series tries. function helps summarize explore metadata possible patterns may help find problems.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/check_meta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check output of clean_metadata() — check_meta","text":"","code":"check_meta(meta, date = FALSE)"},{"path":"https://arutools.github.io/ARUtools/dev/reference/check_meta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check output of clean_metadata() — check_meta","text":"meta Data frame. Recording metadata. Output clean_metadata(). date Logical. Whether summarize output date (well site_id aru_id. Default FALSE.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/check_meta.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check output of clean_metadata() — check_meta","text":"data frame summarizing metadata site_id, aru_type, aru_id, (optionally) date. Presents number files, directories, days worth recordings, well minimum maximum recording times.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/check_meta.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check output of clean_metadata() — check_meta","text":"","code":"m <- clean_metadata(project_files = example_files) #> Extracting ARU info... #> Extracting Dates and Times...  check_meta(m) #> # A tibble: 10 × 11 #>    site_id aru_type  aru_id     type  n_files n_dirs n_days min_date            #>    <chr>   <chr>     <chr>      <chr>   <int>  <int>  <int> <dttm>              #>  1 P01_1   BARLT     BARLT10962 wav         6      3      2 2020-05-02 05:00:00 #>  2 P02_1   SongMeter S4A01234   wav         6      3      2 2020-05-04 05:25:00 #>  3 P03_1   BARLT     BARLT10962 wav         3      3      1 2020-05-06 10:00:00 #>  4 P04_1   BARLT     BARLT11111 wav         6      3      2 2020-05-06 05:00:00 #>  5 P05_1   BARLT     BARLT10962 wav         3      3      1 2020-05-07 05:00:00 #>  6 P06_1   BARLT     BARLT10962 wav         3      3      1 2020-05-09 05:20:00 #>  7 P07_1   SongMeter S4A01234   wav         6      3      2 2020-05-09 05:25:00 #>  8 P08_1   BARLT     BARLT10962 wav         3      3      1 2020-05-11 10:00:00 #>  9 P09_1   SongMeter S4A02222   wav         3      3      1 2020-05-11 05:00:00 #> 10 P10_1   SongMeter S4A03333   wav         3      3      1 2020-05-11 03:25:00 #> # ℹ 3 more variables: max_date <dttm>, min_time <time>, max_time <time> check_meta(m, date = TRUE) #> # A tibble: 14 × 10 #>    site_id aru_type  aru_id     type  date       n_files n_dirs n_days min_time #>    <chr>   <chr>     <chr>      <chr> <date>       <int>  <int>  <int> <time>   #>  1 P01_1   BARLT     BARLT10962 wav   2020-05-02       3      3      1 05:00    #>  2 P01_1   BARLT     BARLT10962 wav   2020-05-03       3      3      1 05:20    #>  3 P02_1   SongMeter S4A01234   wav   2020-05-04       3      3      1 05:25    #>  4 P02_1   SongMeter S4A01234   wav   2020-05-05       3      3      1 07:30    #>  5 P03_1   BARLT     BARLT10962 wav   2020-05-06       3      3      1 10:00    #>  6 P04_1   BARLT     BARLT11111 wav   2020-05-06       3      3      1 05:00    #>  7 P04_1   BARLT     BARLT11111 wav   2020-05-07       3      3      1 03:25    #>  8 P05_1   BARLT     BARLT10962 wav   2020-05-07       3      3      1 05:00    #>  9 P06_1   BARLT     BARLT10962 wav   2020-05-09       3      3      1 05:20    #> 10 P07_1   SongMeter S4A01234   wav   2020-05-09       3      3      1 05:25    #> 11 P07_1   SongMeter S4A01234   wav   2020-05-10       3      3      1 07:30    #> 12 P08_1   BARLT     BARLT10962 wav   2020-05-11       3      3      1 10:00    #> 13 P09_1   SongMeter S4A02222   wav   2020-05-11       3      3      1 05:00    #> 14 P10_1   SongMeter S4A03333   wav   2020-05-11       3      3      1 03:25    #> # ℹ 1 more variable: max_time <time>"},{"path":"https://arutools.github.io/ARUtools/dev/reference/check_problems.html","id":null,"dir":"Reference","previous_headings":"","what":"Check problems in output of clean_metadata() — check_problems","title":"Check problems in output of clean_metadata() — check_problems","text":"Cleaning metadata can take series tries. function helps summarize explore missing metadata (problems).","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/check_problems.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check problems in output of clean_metadata() — check_problems","text":"","code":"check_problems(   df,   check = c(\"site_id\", \"aru_id\", \"date\", \"date_time\", \"longitude\", \"latitude\"),   path = FALSE,   date = FALSE )"},{"path":"https://arutools.github.io/ARUtools/dev/reference/check_problems.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check problems in output of clean_metadata() — check_problems","text":"df Data frame. Either meta data (clean_metadata()) GPS coordinates (clean_gps()) check Character. Character vector columns check missing values. Default site_id, aru_id, date, date_time, longitude latitude. path Logical. Whether return just file paths missing attributes. Default FALSE date Logical. Whether summarize output date (well site_id aru_id. Default FALSE.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/check_problems.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check problems in output of clean_metadata() — check_problems","text":"data frame summarizing metadata site_id, aru_type, aru_id, (optionally) date. Presents number files, directories, days worth recordings, well minimum maximum recording times.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/check_problems.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check problems in output of clean_metadata() — check_problems","text":"","code":"m <- clean_metadata(project_files = example_files, pattern_aru_id = \"test\") #> Extracting ARU info... #> Extracting Dates and Times... #> Identified possible problems with metadata extraction: #> ✖ No ARU ids were successfully detected (42/42)  check_problems(m) #> # A tibble: 42 × 6 #>    path                  aru_id site_id tz_offset date_time           date       #>    <chr>                 <chr>  <chr>   <chr>     <dttm>              <date>     #>  1 a_BARLT10962_P01_1/P… NA     P01_1   -0400     2020-05-02 05:00:00 2020-05-02 #>  2 a_BARLT10962_P01_1/P… NA     P01_1   -0400     2020-05-03 05:20:00 2020-05-03 #>  3 a_S4A01234_P02_1/P02… NA     P02_1   NA        2020-05-04 05:25:00 2020-05-04 #>  4 a_S4A01234_P02_1/P02… NA     P02_1   NA        2020-05-05 07:30:00 2020-05-05 #>  5 a_BARLT10962_P03_1/P… NA     P03_1   -0400     2020-05-06 10:00:00 2020-05-06 #>  6 a_BARLT11111_P04_1/P… NA     P04_1   -0400     2020-05-06 05:00:00 2020-05-06 #>  7 a_BARLT11111_P04_1/P… NA     P04_1   -0400     2020-05-07 03:25:00 2020-05-07 #>  8 a_BARLT10962_P05_1/P… NA     P05_1   -0400     2020-05-07 05:00:00 2020-05-07 #>  9 a_BARLT10962_P06_1/P… NA     P06_1   -0400     2020-05-09 05:20:00 2020-05-09 #> 10 a_S4A01234_P07_1/P07… NA     P07_1   NA        2020-05-09 05:25:00 2020-05-09 #> # ℹ 32 more rows check_problems(m, date = TRUE) #> # A tibble: 14 × 7 #>    site_id aru_id date       date_time_min       date_time_max       date_time_n #>    <chr>   <chr>  <date>     <dttm>              <dttm>                    <int> #>  1 P01_1   NA     2020-05-02 2020-05-02 05:00:00 2020-05-02 05:00:00           3 #>  2 P01_1   NA     2020-05-03 2020-05-03 05:20:00 2020-05-03 05:20:00           3 #>  3 P02_1   NA     2020-05-04 2020-05-04 05:25:00 2020-05-04 05:25:00           3 #>  4 P02_1   NA     2020-05-05 2020-05-05 07:30:00 2020-05-05 07:30:00           3 #>  5 P03_1   NA     2020-05-06 2020-05-06 10:00:00 2020-05-06 10:00:00           3 #>  6 P04_1   NA     2020-05-06 2020-05-06 05:00:00 2020-05-06 05:00:00           3 #>  7 P04_1   NA     2020-05-07 2020-05-07 03:25:00 2020-05-07 03:25:00           3 #>  8 P05_1   NA     2020-05-07 2020-05-07 05:00:00 2020-05-07 05:00:00           3 #>  9 P06_1   NA     2020-05-09 2020-05-09 05:20:00 2020-05-09 05:20:00           3 #> 10 P07_1   NA     2020-05-09 2020-05-09 05:25:00 2020-05-09 05:25:00           3 #> 11 P07_1   NA     2020-05-10 2020-05-10 07:30:00 2020-05-10 07:30:00           3 #> 12 P08_1   NA     2020-05-11 2020-05-11 10:00:00 2020-05-11 10:00:00           3 #> 13 P09_1   NA     2020-05-11 2020-05-11 05:00:00 2020-05-11 05:00:00           3 #> 14 P10_1   NA     2020-05-11 2020-05-11 03:25:00 2020-05-11 03:25:00           3 #> # ℹ 1 more variable: date_time_n_na <int> check_problems(m, path = TRUE) #>  [1] \"a_BARLT10962_P01_1/P01_1_20200502T050000-0400_ARU.wav\" #>  [2] \"a_BARLT10962_P01_1/P01_1_20200503T052000-0400_ARU.wav\" #>  [3] \"a_S4A01234_P02_1/P02_1_20200504T052500_ARU.wav\"        #>  [4] \"a_S4A01234_P02_1/P02_1_20200505T073000_ARU.wav\"        #>  [5] \"a_BARLT10962_P03_1/P03_1_20200506T100000-0400_ARU.wav\" #>  [6] \"a_BARLT11111_P04_1/P04_1_20200506T050000-0400_ARU.wav\" #>  [7] \"a_BARLT11111_P04_1/P04_1_20200507T032500-0400_ARU.wav\" #>  [8] \"a_BARLT10962_P05_1/P05_1_20200507T050000-0400_ARU.wav\" #>  [9] \"a_BARLT10962_P06_1/P06_1_20200509T052000-0400_ARU.wav\" #> [10] \"a_S4A01234_P07_1/P07_1_20200509T052500_ARU.wav\"        #> [11] \"a_S4A01234_P07_1/P07_1_20200510T073000_ARU.wav\"        #> [12] \"a_BARLT10962_P08_1/P08_1_20200511T100000-0400_ARU.wav\" #> [13] \"a_S4A02222_P09_1/P09_1_20200511T050000_ARU.wav\"        #> [14] \"a_S4A03333_P10_1/P10_1_20200511T032500_ARU.wav\"        #> [15] \"j_BARLT10962_P01_1/P01_1_20200502T050000-0400_ARU.wav\" #> [16] \"j_BARLT10962_P01_1/P01_1_20200503T052000-0400_ARU.wav\" #> [17] \"j_S4A01234_P02_1/P02_1_20200504T052500_ARU.wav\"        #> [18] \"j_S4A01234_P02_1/P02_1_20200505T073000_ARU.wav\"        #> [19] \"j_BARLT10962_P03_1/P03_1_20200506T100000-0400_ARU.wav\" #> [20] \"j_BARLT11111_P04_1/P04_1_20200506T050000-0400_ARU.wav\" #> [21] \"j_BARLT11111_P04_1/P04_1_20200507T032500-0400_ARU.wav\" #> [22] \"j_BARLT10962_P05_1/P05_1_20200507T050000-0400_ARU.wav\" #> [23] \"j_BARLT10962_P06_1/P06_1_20200509T052000-0400_ARU.wav\" #> [24] \"j_S4A01234_P07_1/P07_1_20200509T052500_ARU.wav\"        #> [25] \"j_S4A01234_P07_1/P07_1_20200510T073000_ARU.wav\"        #> [26] \"j_BARLT10962_P08_1/P08_1_20200511T100000-0400_ARU.wav\" #> [27] \"j_S4A02222_P09_1/P09_1_20200511T050000_ARU.wav\"        #> [28] \"j_S4A03333_P10_1/P10_1_20200511T032500_ARU.wav\"        #> [29] \"o_BARLT10962_P01_1/P01_1_20200502T050000-0400_ARU.wav\" #> [30] \"o_BARLT10962_P01_1/P01_1_20200503T052000-0400_ARU.wav\" #> [31] \"o_S4A01234_P02_1/P02_1_20200504T052500_ARU.wav\"        #> [32] \"o_S4A01234_P02_1/P02_1_20200505T073000_ARU.wav\"        #> [33] \"o_BARLT10962_P03_1/P03_1_20200506T100000-0400_ARU.wav\" #> [34] \"o_BARLT11111_P04_1/P04_1_20200506T050000-0400_ARU.wav\" #> [35] \"o_BARLT11111_P04_1/P04_1_20200507T032500-0400_ARU.wav\" #> [36] \"o_BARLT10962_P05_1/P05_1_20200507T050000-0400_ARU.wav\" #> [37] \"o_BARLT10962_P06_1/P06_1_20200509T052000-0400_ARU.wav\" #> [38] \"o_S4A01234_P07_1/P07_1_20200509T052500_ARU.wav\"        #> [39] \"o_S4A01234_P07_1/P07_1_20200510T073000_ARU.wav\"        #> [40] \"o_BARLT10962_P08_1/P08_1_20200511T100000-0400_ARU.wav\" #> [41] \"o_S4A02222_P09_1/P09_1_20200511T050000_ARU.wav\"        #> [42] \"o_S4A03333_P10_1/P10_1_20200511T032500_ARU.wav\""},{"path":"https://arutools.github.io/ARUtools/dev/reference/clean_gps.html","id":null,"dir":"Reference","previous_headings":"","what":"Check and clean GPS data — clean_gps","title":"Check and clean GPS data — clean_gps","text":"Check clean GPS data ARU logs. GPS points checked obvious problems (expected range, distance cutoffs timing) attached meta data frame. Note often safer reliable create Site Index file including site ids, GPS coordinates. file can cleaned prepared clean_site_index() instead.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/clean_gps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check and clean GPS data — clean_gps","text":"","code":"clean_gps(   meta = NULL,   dist_cutoff = 100,   dist_crs = 3161,   dist_by = c(\"site_id\", \"aru_id\"),   quiet = FALSE,   verbose = FALSE )"},{"path":"https://arutools.github.io/ARUtools/dev/reference/clean_gps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check and clean GPS data — clean_gps","text":"meta Data frame. Output clean_metadata(). dist_cutoff Numeric. Maximum distance (m) GPS points within site. Default 100m can set Inf skip. dist_crs Numeric. Coordinate Reference System use calculating distance (one m). dist_by Character. Column identifies sites within compare distance among GPS points. valid dist_cutoff Inf. quiet Logical. Whether suppress progress messages non-essential updates. verbose Logical. Show extra loading information. Default FALSE.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/clean_gps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check and clean GPS data — clean_gps","text":"Data frame site-level metadata.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/clean_gps.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check and clean GPS data — clean_gps","text":"checking maximum distance (dist_cutoff) among GPS points within group (dist_by), returned data frame include column max_dist, represents largest distance among points within group.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/clean_gps.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check and clean GPS data — clean_gps","text":"","code":"if (FALSE) { # dir.exists(\"my_project\") m <- clean_metadata(project_dir = \"my_project\") g <- clean_gps(meta = m) }"},{"path":"https://arutools.github.io/ARUtools/dev/reference/clean_logs.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract log data from BAR-LT log files — clean_logs","title":"Extract log data from BAR-LT log files — clean_logs","text":"Process BAR-LT log files data frame reflecting metadata, schedule information, events. Events time-stamped logs either GPS fixes (lat lon) recordings (rec_file, rec_size, rec_end).","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/clean_logs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract log data from BAR-LT log files — clean_logs","text":"","code":"clean_logs(log_files, return = \"all\", progress = TRUE)"},{"path":"https://arutools.github.io/ARUtools/dev/reference/clean_logs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract log data from BAR-LT log files — clean_logs","text":"log_files Character vector log files process. return Character. kind data return, GPS fixes (\"gps\"), recording events (\"recordings\") \"\" (default). progress Logical. Whether use purrr::map() progress bars (default TRUE).","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/clean_logs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract log data from BAR-LT log files — clean_logs","text":"Data frame containing file_names paths log files events date_times lat lon \"gps\" events rec_file, rec_size rec_end \"recording\" events (recording start date_time event) schedule information schedule_date, schedule_name, schedule_lat, schedule_lon, schedule_sr (sunrise), schedule_ss (sunset) metadata information meta_serial meta_firmware","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/clean_logs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract log data from BAR-LT log files — clean_logs","text":"Note log files can glitches. start time recording (generally problem recording made), date_time value recording rec_end time. BAR-LT units adjust time according GPS locations, times \"local\" area.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/clean_logs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract log data from BAR-LT log files — clean_logs","text":"","code":"if (FALSE) { # dir.exists(\"my_project_folder\") # Replace \"my_project_folder\" with your directory containing your recordings and logfiles log_files <- fs::dir_ls(\"my_project_folder\", recurse = TRUE, glob = \"*logfile*\") log_files logs <- clean_logs(log_files)  log_files <- \"../ARUtools - Extra/aru_log_files/P028/1A_BARLT10962/logfile_00010962_SD1.txt\"  clean_logs(log_files) clean_logs(log_files, return = \"gps\") clean_logs(log_files, return = \"recordings\")  log_files <- fs::dir_ls(\"../ARUtools - Extra/aru_log_files/\", recurse = TRUE, glob = \"*logfile*\")  l <- clean_logs(log_files) }"},{"path":"https://arutools.github.io/ARUtools/dev/reference/clean_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract and clean ARU metadata from file names — clean_metadata","title":"Extract and clean ARU metadata from file names — clean_metadata","text":"Using regular expressions, metadata extracted file names directory structure, checked cleaned.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/clean_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract and clean ARU metadata from file names — clean_metadata","text":"","code":"clean_metadata(   project_dir = NULL,   project_files = NULL,   file_type = \"wav\",   subset = NULL,   subset_type = \"keep\",   pattern_site_id = create_pattern_site_id(),   pattern_aru_id = create_pattern_aru_id(),   pattern_date = create_pattern_date(),   pattern_time = create_pattern_time(),   pattern_dt_sep = create_pattern_dt_sep(),   pattern_tz_offset = create_pattern_tz_offset(),   order_date = \"ymd\",   quiet = FALSE )"},{"path":"https://arutools.github.io/ARUtools/dev/reference/clean_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract and clean ARU metadata from file names — clean_metadata","text":"project_dir Character. Directory project files stored. File paths used extract information must actually exist. project_files Character. Vector project file paths. paths can absolute relative working directory, actually need point existing files unless plan use clean_gps() sampling steps line. Must provided project_dir NULL. file_type Character. Type file (extension) summarize. Default wav. subset Character. Text pattern mark subset files/directories either \"keep\" \"omit\" (see subset_type) subset_type Character. Either keep (default) omit files/directories match pattern subset. pattern_site_id Character. Regular expression extract site ids. See create_pattern_site_id(). Can vector multiple patterns match. pattern_aru_id Character. Regular expression extract ARU ids. See create_pattern_aru_id(). Can vector multiple patterns match. pattern_date Character. Regular expression extract dates. See create_pattern_date(). Can vector multiple patterns match. pattern_time Character. Regular expression extract times. See create_pattern_time(). Can vector multiple patterns match. pattern_dt_sep Character. Regular expression mark separators dates times. See create_pattern_dt_sep(). pattern_tz_offset Character. Regular expression extract time zone offsets file names. See. create_pattern_tz_offset(). order_date Character. Order date appears . \"ymd\" (default), \"mdy\", \"dmy\". Can vector multiple patterns match. quiet Logical. Whether suppress progress messages non-essential updates.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/clean_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract and clean ARU metadata from file names — clean_metadata","text":"Data frame extracted metadata","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/clean_metadata.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract and clean ARU metadata from file names — clean_metadata","text":"Note times extracted first combining date, date/time separator time patterns. means problem combination, dates might extracted date/times . mismatch can used determine part pattern needs tweaked. See vignette(\"customizing\", package = \"ARUtools\") details customizing clean_metadata() project.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/clean_metadata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract and clean ARU metadata from file names — clean_metadata","text":"","code":"clean_metadata(project_files = example_files) #> Extracting ARU info... #> Extracting Dates and Times... #> # A tibble: 42 × 11 #>    file_name    type  path  aru_id manufacturer model aru_type site_id tz_offset #>    <chr>        <chr> <chr> <chr>  <chr>        <chr> <chr>    <chr>   <chr>     #>  1 P01_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P01_1   -0400     #>  2 P01_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P01_1   -0400     #>  3 P02_1_20200… wav   a_S4… S4A01… Wildlife Ac… Song… SongMet… P02_1   NA        #>  4 P02_1_20200… wav   a_S4… S4A01… Wildlife Ac… Song… SongMet… P02_1   NA        #>  5 P03_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P03_1   -0400     #>  6 P04_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P04_1   -0400     #>  7 P04_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P04_1   -0400     #>  8 P05_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P05_1   -0400     #>  9 P06_1_20200… wav   a_BA… BARLT… Frontier La… BAR-… BARLT    P06_1   -0400     #> 10 P07_1_20200… wav   a_S4… S4A01… Wildlife Ac… Song… SongMet… P07_1   NA        #> # ℹ 32 more rows #> # ℹ 2 more variables: date_time <dttm>, date <date> clean_metadata(project_files = example_files, subset = \"P02\") #> Extracting ARU info... #> Extracting Dates and Times... #> # A tibble: 6 × 11 #>   file_name     type  path  aru_id manufacturer model aru_type site_id tz_offset #>   <chr>         <chr> <chr> <chr>  <chr>        <chr> <chr>    <chr>   <chr>     #> 1 P02_1_202005… wav   a_S4… S4A01… Wildlife Ac… Song… SongMet… P02_1   NA        #> 2 P02_1_202005… wav   a_S4… S4A01… Wildlife Ac… Song… SongMet… P02_1   NA        #> 3 P02_1_202005… wav   j_S4… S4A01… Wildlife Ac… Song… SongMet… P02_1   NA        #> 4 P02_1_202005… wav   j_S4… S4A01… Wildlife Ac… Song… SongMet… P02_1   NA        #> 5 P02_1_202005… wav   o_S4… S4A01… Wildlife Ac… Song… SongMet… P02_1   NA        #> 6 P02_1_202005… wav   o_S4… S4A01… Wildlife Ac… Song… SongMet… P02_1   NA        #> # ℹ 2 more variables: date_time <dttm>, date <date>"},{"path":"https://arutools.github.io/ARUtools/dev/reference/clean_site_index.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare and clean site index file — clean_site_index","title":"Prepare and clean site index file — clean_site_index","text":"site index file contains information specific ARUs deployed . function cleans file (csv, xlsx) data frame preparation adding details output clean_metadata(). can used specify missing information according date, GPS lon/lats site ids.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/clean_site_index.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare and clean site index file — clean_site_index","text":"","code":"clean_site_index(   site_index,   name_aru_id = \"aru_id\",   name_site_id = \"site_id\",   name_date_time = \"date\",   name_coords = c(\"longitude\", \"latitude\"),   name_extra = NULL,   resolve_overlaps = TRUE,   quiet = FALSE )"},{"path":"https://arutools.github.io/ARUtools/dev/reference/clean_site_index.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare and clean site index file — clean_site_index","text":"site_index (Spatial) Data frame file path. Site index data clean. file path, must local csv xlsx file. name_aru_id Character. Name column contains ARU ids. Default \"aru_id\". name_site_id Character. Name column contains site ids. Default \"site_id\". name_date_time Character. Column name contains dates date/times. Can vector two names 'start' 'end' columns. Can NULL ignore dates. Default \"date\". name_coords Character. Column names contain longitude latitude (order). Ignored site_index spatial. Default c(\"longitude\", \"latitude\") name_extra Character. Column names extra data include. named vector, rename columns (see examples). Default NULL. resolve_overlaps Logical. Whether resolve date overlaps shifting start/end dates noon (default TRUE). assumes ARUs generally deployed/removed midnight (official start/end day) noon used approximation ARU deployed removed. possible, use specific deployment times avoid issue. quiet Logical. Whether suppress progress messages non-essential updates.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/clean_site_index.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare and clean site index file — clean_site_index","text":"Standardized site index data frame","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/clean_site_index.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Prepare and clean site index file — clean_site_index","text":"Note times assumed 'local' time timezone used (removed present, replaced UTC). allows sites different timezones processed time.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/clean_site_index.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prepare and clean site index file — clean_site_index","text":"","code":"s <- clean_site_index(example_sites,   name_aru_id = \"ARU\",   name_site_id = \"Sites\",   name_date_time = c(\"Date_set_out\", \"Date_removed\"),   name_coords = c(\"lon\", \"lat\") ) #> There are overlapping date ranges #> • Shifting start/end times to 'noon' #> • Skip this with `resolve_overlaps = FALSE`  s <- clean_site_index(example_sites,   name_aru_id = \"ARU\",   name_site_id = \"Sites\",   name_date_time = c(\"Date_set_out\", \"Date_removed\"),   name_coords = c(\"lon\", \"lat\"),   name_extra = c(\"plot\" = \"Plots\") ) #> There are overlapping date ranges #> • Shifting start/end times to 'noon' #> • Skip this with `resolve_overlaps = FALSE`  # Without dates eg <- dplyr::select(example_sites, -Date_set_out, -Date_removed) s <- clean_site_index(eg,   name_aru_id = \"ARU\",   name_site_id = \"Sites\",   name_date_time = NULL,   name_coords = c(\"lon\", \"lat\"),   name_extra = c(\"plot\" = \"Plots\") )"},{"path":"https://arutools.github.io/ARUtools/dev/reference/clip_wave.html","id":null,"dir":"Reference","previous_headings":"","what":"Clip multiple wave files and format names — clip_wave","title":"Clip multiple wave files and format names — clip_wave","text":"Process multiple wave files copying new filename clipping given length.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/clip_wave.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clip multiple wave files and format names — clip_wave","text":"","code":"clip_wave(   waves,   dir_out,   dir_in = NULL,   col_path_in = path,   col_subdir_out = subdir_out,   col_filename_out = filename_out,   col_clip_length = clip_length,   col_start_time = start_time,   overwrite = FALSE,   create_dir = TRUE,   diff_limit = 30 )"},{"path":"https://arutools.github.io/ARUtools/dev/reference/clip_wave.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clip multiple wave files and format names — clip_wave","text":"waves Data frame. Details file locations. dir_out Character. Output directory. dir_in Character. Directory wave files read . Default NULL meaning current working directory. col_path_in Column. Unquoted column containing current file paths. Default path. Note: file paths must either relative dir_in absolute. col_subdir_out Column. Unquoted column containing subdirectories put output files. Default subdir_out. col_filename_out Column. Unquoted column containing output filenames. Default filename_out. col_clip_length Column. Unquoted column containing length new clip. Default length. col_start_time Column. Unquoted column containing start time new clip. Default start_time. overwrite Logical. Overwrite pre-existing files clipping moving. Default FALSE. create_dir Logical. Whether create directory structure newly formatted clipped wave files. diff_limit Numeric. much longer seconds clip lengths can compared file lengths triggering error. Default 30.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/clip_wave.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clip multiple wave files and format names — clip_wave","text":"TRUE successful clipped wave files created","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/clip_wave.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Clip multiple wave files and format names — clip_wave","text":"","code":"if (FALSE) { # dir.exists(\"test1\") w <- data.frame(   path = temp_wavs(n = 4),   subdir_out = c(\"test1/a\", \"test2/a\", \"test3/c\", \"test4/d\"),   subsub_dir_out = rep(\"zz\", 4),   filename_out = c(\"wave1_clean.wav\", \"wave2_clean.wav\", \"wave3_clean.wav\", \"wave4_clean.wav\"),   clip_length = c(1, 1, 1, 2),   start_time = c(1.2, 0.5, 1, 0) )  clip_wave(w, dir_out = \"clean\", col_subdir_out = c(subdir_out, subsub_dir_out))  unlink(\"clean\", recursive = TRUE) # Remove this new 'clean' directory }"},{"path":"https://arutools.github.io/ARUtools/dev/reference/clip_wave_single.html","id":null,"dir":"Reference","previous_headings":"","what":"Clip single wave file — clip_wave_single","title":"Clip single wave file — clip_wave_single","text":"Clip copy single wave files given length. See clip_wave() processing multiple files.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/clip_wave_single.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clip single wave file — clip_wave_single","text":"","code":"clip_wave_single(   path_in,   path_out,   clip_length,   start_time = 0,   wave_length = NULL,   overwrite = FALSE )"},{"path":"https://arutools.github.io/ARUtools/dev/reference/clip_wave_single.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clip single wave file — clip_wave_single","text":"path_in Character. Path wave file clip. path_out Character. Path copy new clipped wave file . clip_length Numeric. Length new clip seconds. start_time Numeric. Time seconds new clip start. Default 0. wave_length Numeric. Length clipped wave file seconds (NULL, default, length time start_time end file). overwrite Logical. Whether overwrite existing files creating new clipped wave files. Default (FALSE) error file already exists.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/clip_wave_single.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clip single wave file — clip_wave_single","text":"TRUE successful","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/clip_wave_single.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Clip single wave file — clip_wave_single","text":"","code":"# Create test wave file f <- temp_wavs(1)  # Clip file and check it out clip_wave_single(f, \"new_file.wav\", clip_length = 1) #> [1] TRUE tuneR::readWave(\"new_file.wav\") #>  #> Wave Object #> \tNumber of Samples:      44100 #> \tDuration (seconds):     1 #> \tSamplingrate (Hertz):   44100 #> \tChannels (Mono/Stereo): Mono #> \tPCM (integer format):   FALSE #> \tBit (8/16/24/32/64):    32  #>  unlink(\"new_file.wav\")"},{"path":"https://arutools.github.io/ARUtools/dev/reference/common_docs.html","id":null,"dir":"Reference","previous_headings":"","what":"Common arguments and documentation for various functions — common_docs","title":"Common arguments and documentation for various functions — common_docs","text":"Common arguments documentation various functions","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/common_docs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Common arguments and documentation for various functions — common_docs","text":"project_dir Character. Directory project files stored. File paths used extract information must actually exist. project_files Character. Vector project file paths. paths can absolute relative working directory, actually need point existing files unless plan use clean_gps() sampling steps line. Must provided project_dir NULL. subset Character. Text pattern mark subset files/directories either \"keep\" \"omit\" (see subset_type) subset_type Character. Either keep (default) omit files/directories match pattern subset. meta Data frame. Recording metadata. Output clean_metadata(). meta_sites (Spatial) Data frame. Recording metadata added coordinates. Output clean_metadata() add_sites() (either clean_gps() clean_site_index()). col_site_id Column. Unquoted column containing site strata IDs (defaults site_id). date Logical. Whether summarize output date (well site_id aru_id. Default FALSE. path Character. Path wave file. dir_out Character. Output directory. quiet Logical. Whether suppress progress messages non-essential updates.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/common_docs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Common arguments and documentation for various functions — common_docs","text":"Use @inheritParams common_docs include function documentation matching argument (include matching args)","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/count_files.html","id":null,"dir":"Reference","previous_headings":"","what":"Count files in a project directory — count_files","title":"Count files in a project directory — count_files","text":"Helper function explore number files directory, recursively.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/count_files.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Count files in a project directory — count_files","text":"","code":"count_files(project_dir, subset = NULL, subset_type = \"keep\")"},{"path":"https://arutools.github.io/ARUtools/dev/reference/count_files.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Count files in a project directory — count_files","text":"project_dir Character. Directory project files stored. File paths used extract information must actually exist. subset Character. Text pattern mark subset files/directories either \"keep\" \"omit\" (see subset_type) subset_type Character. Either keep (default) omit files/directories match pattern subset.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/count_files.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Count files in a project directory — count_files","text":"data frame number files directory","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/count_files.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Count files in a project directory — count_files","text":"","code":"if (FALSE) { # dir.exists(\"PROJECT_DIR\") count_files(\"PROJECT_DIR\") }"},{"path":"https://arutools.github.io/ARUtools/dev/reference/create_dirs.html","id":null,"dir":"Reference","previous_headings":"","what":"Create directory structure for recording folders — create_dirs","title":"Create directory structure for recording folders — create_dirs","text":"Create set nested folders storing ARU recordings plots sites.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/create_dirs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create directory structure for recording folders — create_dirs","text":"","code":"create_dirs(   plots,   site_ids,   base_dir = NULL,   dir_list = FALSE,   dry_run = TRUE,   expect_dirs = FALSE )"},{"path":"https://arutools.github.io/ARUtools/dev/reference/create_dirs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create directory structure for recording folders — create_dirs","text":"plots Character vector. Hexagon cluster names folder names. site_ids Character vector. Site IDs. include plot/cluster id name. base_dir Character. Base directory build directory structure . dir_list Logical. Whether return vector directories () created (defaults FALSE). dry_run Logical. Whether dry-run process (.e. actually create directories; defaults TRUE) expect_dirs Logical. Expect directories may already exist? Default (FALSE) stop directories created already exist.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/create_dirs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create directory structure for recording folders — create_dirs","text":"dir_list = TRUE, returns list directories () created. dry run, also creates folder structure.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/create_dirs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create directory structure for recording folders — create_dirs","text":"","code":"# Default is to do a dry-run (don't actually create the directories) create_dirs(   plots = c(\"river1\", \"river2\", \"river3\"),   site_ids = c(     \"river1_sm01\", \"river1_sm02\", \"river2_sm03\", \"river2_sm04\",     \"river3_sm05\", \"river3_sm06\"   ),   base_dir = \"Recordings\" ) #> This is a dry run, no directories are created #> ℹ Use `dir_list = TRUE` to return a list of directories to be created  # Get a list of directories which would be created create_dirs(   plots = c(\"river1\", \"river2\", \"river3\"),   site_ids = c(     \"river1_sm01\", \"river1_sm02\", \"river2_sm03\", \"river2_sm04\",     \"river3_sm05\", \"river3_sm06\"   ),   base_dir = \"Recordings\", dir_list = TRUE ) #> This is a dry run, no directories are created #> [1] \"/home/runner/work/ARUtools/ARUtools/docs/dev/reference/Recordings/river1/river1_sm01\" #> [2] \"/home/runner/work/ARUtools/ARUtools/docs/dev/reference/Recordings/river1/river1_sm02\" #> [3] \"/home/runner/work/ARUtools/ARUtools/docs/dev/reference/Recordings/river2/river2_sm03\" #> [4] \"/home/runner/work/ARUtools/ARUtools/docs/dev/reference/Recordings/river2/river2_sm04\" #> [5] \"/home/runner/work/ARUtools/ARUtools/docs/dev/reference/Recordings/river3/river3_sm05\" #> [6] \"/home/runner/work/ARUtools/ARUtools/docs/dev/reference/Recordings/river3/river3_sm06\"  if (FALSE) { # dir.exists(\"Recordings\") # Create directories AND return a list of those created d <- create_dirs(   plots = c(\"river1\", \"river2\", \"river3\"),   site_ids = c(     \"river1_sm01\", \"river1_sm02\", \"river2_sm03\", \"river2_sm04\",     \"river3_sm05\", \"river3_sm06\"   ),   base_dir = \"Recordings\", dir_list = TRUE, expect_dirs =TRUE,   dry_run = FALSE ) d }"},{"path":"https://arutools.github.io/ARUtools/dev/reference/create_lookaround.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a look around expression and add it to an existing regular expression — create_lookaround","title":"Create a look around expression and add it to an existing regular expression — create_lookaround","text":"Lookarounds allow position regular expression specificity.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/create_lookaround.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a look around expression and add it to an existing regular expression — create_lookaround","text":"","code":"create_lookaround(pattern, lookaround_pattern, position, negate = FALSE)"},{"path":"https://arutools.github.io/ARUtools/dev/reference/create_lookaround.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a look around expression and add it to an existing regular expression — create_lookaround","text":"pattern String. Pattern wish add look around lookaround_pattern String. Pattern wish look . position String. One '', '', 'ahead', 'behind'. Capitalization matter negate Logical. allows exclude cases look around detected.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/create_lookaround.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a look around expression and add it to an existing regular expression — create_lookaround","text":"Returns string can used regular expression","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/create_lookaround.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a look around expression and add it to an existing regular expression — create_lookaround","text":"","code":"# Here is a string with three patterns of digits text <- \"cars123ruin456cities789\"  # To extract the first one we can use this pattern stringr::str_extract(text, \"\\\\d{3}\") #> [1] \"123\" # or create_lookaround(\"\\\\d{3}\", \"cars\", \"before\") |> stringr::str_extract(string=text) #> [1] \"123\"  # To exclude the first one we can write create_lookaround(\"\\\\d{3}\", \"cars\", \"before\", negate=TRUE) |> stringr::str_extract_all(string=text) #> [[1]] #> [1] \"456\" \"789\" #>   # To extract the second one we can write  create_lookaround(\"\\\\d{3}\", \"ruin\", \"before\") |> stringr::str_extract(string=text) #> [1] \"456\"  # or  create_lookaround(\"\\\\d{3}\", \"cities\", \"after\") |> stringr::str_extract(string=text) #> [1] \"456\""},{"path":"https://arutools.github.io/ARUtools/dev/reference/create_pattern.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a pattern to match date — create_pattern","title":"Create a pattern to match date — create_pattern","text":"Helper functions create regular expression patterns match different metadata file paths.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/create_pattern.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a pattern to match date — create_pattern","text":"","code":"create_pattern_date(   order = \"ymd\",   sep = c(\"_\", \"-\", \"\"),   yr_digits = 4,   look_ahead = \"\",   look_behind = \"\" )  create_pattern_time(   sep = c(\"_\", \"-\", \":\", \"\"),   seconds = \"yes\",   look_ahead = \"\",   look_behind = \"\" )  create_pattern_dt_sep(   sep = \"T\",   optional = FALSE,   look_ahead = \"\",   look_behind = \"\" )  create_pattern_aru_id(   arus = c(\"BARLT\", \"S\\\\d(A|U)\", \"SM\\\\d\", \"SMM\", \"SMA\"),   n_digits = c(4, 8),   sep = c(\"_\", \"-\", \"\"),   prefix = \"\",   suffix = \"\",   look_ahead = \"\",   look_behind = \"\" )  create_pattern_site_id(   prefix = c(\"P\", \"Q\"),   p_digits = 2,   sep = c(\"_\", \"-\"),   suffix = \"\",   s_digits = 1,   look_ahead = \"\",   look_behind = \"\" )  create_pattern_tz_offset(   direction_from_UTC = \"West\",   n_digits_hrs = 2,   n_digits_min = 2 )  test_pattern(test, pattern)"},{"path":"https://arutools.github.io/ARUtools/dev/reference/create_pattern.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a pattern to match date — create_pattern","text":"order Character vector. Expected orders (y)ear, (m)onth (d)ate. Default \"ymd\" Year-Month-Date order. Can one possible order. sep Character vector. Expected separator(s) pattern parts. Can \"\" separator. yr_digits Numeric vector. Number digits Year, either 2 4. look_ahead Pattern look ahead string Can regular expression text. look_behind Pattern look behind string. Can regular expression text. seconds Character. Whether seconds included. Options \"yes\", \"\", \"maybe\". optional Logical. Whether separator optional . Allows matching different date/time patterns. arus Character vector. Pattern(s) identifying ARU prefix (usually model specific). n_digits Numeric vector. Number digits expected follow arus pattern. Can one two (range). prefix Character vector. Prefix(es) site ids. suffix Character vector. Suffix(es) site ids. p_digits Numeric vector. Number(s) digits following prefix. s_digits Numeric vector. Number(s) digits following suffix. direction_from_UTC Character. Must \"West\", \"East\" \"\" n_digits_hrs Numeric vector. Number(s) digits hours offset. n_digits_min Numeric vector. Number(s) digits minutes offset. test Character vector. Examples text test. pattern Character. Regular expression pattern test.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/create_pattern.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a pattern to match date — create_pattern","text":"Either pattern (create_pattern_xxx()) text extracted pattern (test_pattern())","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/create_pattern.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a pattern to match date — create_pattern","text":"default create_pattern_aru_id() matches many common ARU patterns like BARLT0000, S4A0000, SM40000, SMM0000, SMA0000. test_pattern() helper function see regular expression pattern pick example text. Can used see pattern grabs want. just simple wrapper around stringr::str_extract().","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/create_pattern.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Create a pattern to match date — create_pattern","text":"create_pattern_date(): Create pattern match date create_pattern_time(): Create pattern match time create_pattern_dt_sep(): Create pattern match date/time separator create_pattern_aru_id(): Create pattern match ARU id create_pattern_site_id(): Create pattern match site id create_pattern_tz_offset(): Create pattern match site id test_pattern(): Test patterns","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/create_pattern.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a pattern to match date — create_pattern","text":"","code":"create_pattern_date() # Default matches 2020-01-01 or 2020_01_01 or 20200101 #> [1] \"((((([12]{1}\\\\d{3})))(_|-|)(\\\\d{2})(_|-|)(\\\\d{2})))\" # (\"-\", \"_\" or \"\" as separators) create_pattern_date(sep = \"\") # Matches only 20200101 (no separator allowed) #> [1] \"((((([12]{1}\\\\d{3})))(\\\\d{2})(\\\\d{2})))\"  create_pattern_time() # Default matches 23_59_59 (_, -, :, as optional separators) #> [1] \"([0-2]{1}[0-9]{1})(_|-|:|)([0-5]{1}[0-9]{1})((_|-|:|)([0-5]{1}[0-9]{1}))\" create_pattern_time(sep = \"\", seconds = \"no\") # Matches 2359 (no seconds no separators) #> [1] \"([0-2]{1}[0-9]{1})([0-5]{1}[0-9]{1})\"  create_pattern_dt_sep() # Default matches 'T' as a required separator #> [1] \"(T)\" create_pattern_dt_sep(optional = TRUE) # 'T' as an optional separator #> [1] \"(T)?\" create_pattern_dt_sep(c(\"T\", \"_\", \"-\")) # 'T', '_', or '-' as separators #> [1] \"(T|_|-)\"  create_pattern_aru_id() #> [1] \"((BARLT)|(S\\\\d(A|U))|(SM\\\\d)|(SMM)|(SMA))(_|-|)\\\\d{4,8}\" create_pattern_aru_id(prefix = \"CWS\") #> [1] \"((CWS))((BARLT)|(S\\\\d(A|U))|(SM\\\\d)|(SMM)|(SMA))(_|-|)\\\\d{4,8}\" create_pattern_aru_id(n_digits = 12) #> [1] \"((BARLT)|(S\\\\d(A|U))|(SM\\\\d)|(SMM)|(SMA))(_|-|)\\\\d{12}\"   create_pattern_site_id() # Default matches P00-0 #> [1] \"((Q)|(P))((\\\\d{2}))(_|-)((\\\\d{1}))\" create_pattern_site_id(   prefix = \"site\", p_digits = 3, sep = \"\",   suffix = c(\"a\", \"b\", \"c\"), s_digits = 0 ) # Matches site000a #> [1] \"((site))((\\\\d{3}))((c)|(b)|(a))\"   create_pattern_site_id() # Default matches P00-0 #> [1] \"((Q)|(P))((\\\\d{2}))(_|-)((\\\\d{1}))\" create_pattern_site_id(   prefix = \"site\", p_digits = 3, sep = \"\",   suffix = c(\"a\", \"b\", \"c\"), s_digits = 0 ) # Matches site000a #> [1] \"((site))((\\\\d{3}))((c)|(b)|(a))\"  pat <- create_pattern_aru_id(prefix = \"CWS\") test_pattern(\"CWS_BARLT1012\", pat) # No luck #> [1] NA pat <- create_pattern_aru_id(prefix = \"CWS_\") test_pattern(\"CWS_BARLT1012\", pat) # Ah ha! #> [1] \"CWS_BARLT1012\" pat <- create_pattern_site_id()  pat <- create_pattern_site_id() test_pattern(\"P03\", pat) # Nope #> [1] NA test_pattern(\"P03-1\", pat) # Success! #> [1] \"P03-1\"  pat <- create_pattern_site_id(prefix = \"site\", p_digits = 3, sep = \"\", s_digits = 0) test_pattern(\"site111\", pat) #> [1] \"site111\" pat <- create_pattern_site_id(   prefix = \"site\", p_digits = 3, sep = \"\",   suffix = c(\"a\", \"b\", \"c\"), s_digits = 0 ) test_pattern(c(\"site9\", \"site100a\"), pat) #> [1] NA         \"site100a\""},{"path":"https://arutools.github.io/ARUtools/dev/reference/example_clean.html","id":null,"dir":"Reference","previous_headings":"","what":"Example cleaned recording meta data — example_clean","title":"Example cleaned recording meta data — example_clean","text":"data frame examples correctly formatted metadata added site-level information","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/example_clean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example cleaned recording meta data — example_clean","text":"","code":"example_clean"},{"path":[]},{"path":"https://arutools.github.io/ARUtools/dev/reference/example_clean.html","id":"example-clean","dir":"Reference","previous_headings":"","what":"example_clean","title":"Example cleaned recording meta data — example_clean","text":"data frame 42 rows 10 columns: file_name Name file type File type path Relative file path including file name aru_type ARU model aru_id ARU ids site_id Site ids date_time Recording date/time date Recording date longitude Latitude decimal degrees latitude Longitude decimal degrees","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/example_clean.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example cleaned recording meta data — example_clean","text":"data-raw/data_test.R","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/example_files.html","id":null,"dir":"Reference","previous_headings":"","what":"Example recording files — example_files","title":"Example recording files — example_files","text":"vector examples ARU recording files.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/example_files.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example recording files — example_files","text":"","code":"example_files"},{"path":[]},{"path":"https://arutools.github.io/ARUtools/dev/reference/example_files.html","id":"example-files","dir":"Reference","previous_headings":"","what":"example_files","title":"Example recording files — example_files","text":"vector 42 file paths","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/example_files.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example recording files — example_files","text":"data-raw/data_test.R","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/example_files_long.html","id":null,"dir":"Reference","previous_headings":"","what":"Example long-term deployment recording files — example_files_long","title":"Example long-term deployment recording files — example_files_long","text":"vector examples ARU recording files. Uses example_sites data, deploys longer deployment","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/example_files_long.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example long-term deployment recording files — example_files_long","text":"","code":"example_files_long"},{"path":[]},{"path":"https://arutools.github.io/ARUtools/dev/reference/example_files_long.html","id":"example-files-long","dir":"Reference","previous_headings":"","what":"example_files_long","title":"Example long-term deployment recording files — example_files_long","text":"vector 614 file paths","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/example_files_long.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example long-term deployment recording files — example_files_long","text":"data-raw/data_long_deployment.R","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/example_sites.html","id":null,"dir":"Reference","previous_headings":"","what":"Example site-level meta data — example_sites","title":"Example site-level meta data — example_sites","text":"data frame examples incorrectly formatted site-level data.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/example_sites.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example site-level meta data — example_sites","text":"","code":"example_sites"},{"path":[]},{"path":"https://arutools.github.io/ARUtools/dev/reference/example_sites.html","id":"example-sites","dir":"Reference","previous_headings":"","what":"example_sites","title":"Example site-level meta data — example_sites","text":"data frame 10 rows 8 columns: Sites Site ids Date_set_out Deployment start date Date_removed Deployment end date ARU ARU ids lon Longitude decimal degrees lat Latitude decimal degrees Plots Hypothetical extra plot column Subplot Hypothetical extra subplot column","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/example_sites.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example site-level meta data — example_sites","text":"data-raw/data_test.R","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/example_sites_clean.html","id":null,"dir":"Reference","previous_headings":"","what":"Example cleaned site-level meta data — example_sites_clean","title":"Example cleaned site-level meta data — example_sites_clean","text":"data frame examples correctly formatted site-level data.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/example_sites_clean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example cleaned site-level meta data — example_sites_clean","text":"","code":"example_sites_clean"},{"path":[]},{"path":"https://arutools.github.io/ARUtools/dev/reference/example_sites_clean.html","id":"example-sites-clean","dir":"Reference","previous_headings":"","what":"example_sites_clean","title":"Example cleaned site-level meta data — example_sites_clean","text":"data frame 10 rows 8 columns: site_id Site ids aru_id ARU ids date_time_start Deployment start date/time date_time_end Deployment end date/time date_start Deployment start date date_end Deployment end date longitude Latitude decimal degrees latitude Longitude decimal degrees","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/example_sites_clean.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example cleaned site-level meta data — example_sites_clean","text":"data-raw/data_test.R","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/get_pattern.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns the current vector of ARU types — get_pattern","title":"Returns the current vector of ARU types — get_pattern","text":"Returns current vector ARU types","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/get_pattern.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns the current vector of ARU types — get_pattern","text":"","code":"get_pattern(pattern_name)"},{"path":"https://arutools.github.io/ARUtools/dev/reference/get_pattern.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns the current vector of ARU types — get_pattern","text":"pattern_name String pattern variable return. One \"pattern_aru_type\", \"pattern_check\",\"pattern_data\", \"pattern_date_time\"","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/get_pattern.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Returns the current vector of ARU types — get_pattern","text":"named character vector","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/get_pattern.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Returns the current vector of ARU types — get_pattern","text":"","code":"get_pattern(\"pattern_aru_type\") #>             barlt               SMM           SM(\\\\d)           S(\\\\d)A  #>          \"BAR-LT\" \"Song Meter Mini\"  \"Song Meter \\\\1\"  \"Song Meter \\\\1\""},{"path":"https://arutools.github.io/ARUtools/dev/reference/get_wav_length.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the length of a recording in seconds — get_wav_length","title":"Get the length of a recording in seconds — get_wav_length","text":"Get length recording seconds","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/get_wav_length.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the length of a recording in seconds — get_wav_length","text":"","code":"get_wav_length(path, return_numeric = FALSE)"},{"path":"https://arutools.github.io/ARUtools/dev/reference/get_wav_length.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the length of a recording in seconds — get_wav_length","text":"path Character. Path wave file. return_numeric Logical. Return numeric character?","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/get_wav_length.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the length of a recording in seconds — get_wav_length","text":"Length recording seconds","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/get_wav_length.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the length of a recording in seconds — get_wav_length","text":"","code":"f <- tempfile()   w <- tuneR::sine(440, duration = 100000)   tuneR::writeWave(w, f)   get_wav_length(f) #> 2.27 seconds"},{"path":"https://arutools.github.io/ARUtools/dev/reference/guess_ARU_type.html","id":null,"dir":"Reference","previous_headings":"","what":"Try to guess the ARU type from a file path — guess_ARU_type","title":"Try to guess the ARU type from a file path — guess_ARU_type","text":"Try guess ARU type file path","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/guess_ARU_type.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Try to guess the ARU type from a file path — guess_ARU_type","text":"","code":"guess_ARU_type(path)"},{"path":"https://arutools.github.io/ARUtools/dev/reference/guess_ARU_type.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Try to guess the ARU type from a file path — guess_ARU_type","text":"path Character. Path wave file","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/guess_ARU_type.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Try to guess the ARU type from a file path — guess_ARU_type","text":"Tibble columns 'manufacturer', 'model', 'aru_type'","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/guess_ARU_type.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Try to guess the ARU type from a file path — guess_ARU_type","text":"","code":"get_pattern(\"pattern_aru_type\") #>             barlt               SMM           SM(\\\\d)           S(\\\\d)A  #>          \"BAR-LT\" \"Song Meter Mini\"  \"Song Meter \\\\1\"  \"Song Meter \\\\1\"   guess_ARU_type(\"/path/to/barlt/file.wav\") #> # A tibble: 1 × 3 #>   manufacturer  model  aru_type #>   <chr>         <chr>  <chr>    #> 1 Frontier Labs BAR-LT BARLT     guess_ARU_type(\"/path/to/sm/S4A2342.wav\") #> # A tibble: 1 × 3 #>   manufacturer       model        aru_type  #>   <chr>              <chr>        <chr>     #> 1 Wildlife Acoustics Song Meter 4 SongMeter"},{"path":"https://arutools.github.io/ARUtools/dev/reference/meta_clean_logs.html","id":null,"dir":"Reference","previous_headings":"","what":"Run clean_logs() on the output from clean_metadata() — meta_clean_logs","title":"Run clean_logs() on the output from clean_metadata() — meta_clean_logs","text":"Run clean_logs() output clean_metadata()","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/meta_clean_logs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run clean_logs() on the output from clean_metadata() — meta_clean_logs","text":"","code":"meta_clean_logs(meta)"},{"path":"https://arutools.github.io/ARUtools/dev/reference/meta_clean_logs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run clean_logs() on the output from clean_metadata() — meta_clean_logs","text":"meta Data frame. meta data processed add_sites()","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/meta_clean_logs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run clean_logs() on the output from clean_metadata() — meta_clean_logs","text":"Data frame containing file_names paths log files events date_times lat lon \"gps\" events rec_file, rec_size rec_end \"recording\" events (recording start date_time event) schedule information schedule_date, schedule_name, schedule_lat, schedule_lon, schedule_sr (sunrise), schedule_ss (sunset) metadata information meta_serial meta_firmware columns meta provided","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/meta_clean_logs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run clean_logs() on the output from clean_metadata() — meta_clean_logs","text":"","code":"file_vec <- fs::dir_ls(fs::path_package(\"extdata\", package = \"ARUtools\"), recurse = TRUE,)   m <- clean_metadata(project_files = file_vec, file_type = 'json',pattern_site_id = \"000\\\\d+\" ) #> Extracting ARU info... #> Extracting Dates and Times... #> ! Omitted 1 extra, non-json/GPS files #> ! Detected 2 log files    logs <- meta_clean_logs(m)"},{"path":"https://arutools.github.io/ARUtools/dev/reference/sample_recordings.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample recordings — sample_recordings","title":"Sample recordings — sample_recordings","text":"Sample recordings based selection weights calc_selection_weights() using spsurvey::grts().","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/sample_recordings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample recordings — sample_recordings","text":"","code":"sample_recordings(   meta_weights,   n,   os = NULL,   col_site_id = site_id,   col_sel_weights = psel_std,   seed = NULL,   ... )"},{"path":"https://arutools.github.io/ARUtools/dev/reference/sample_recordings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample recordings — sample_recordings","text":"meta_weights (Spatial) Data frame. Recording meta data selection weights. Output calc_selection_weights(). Must least columns identified col_site_id col_sel_weights, well probability selection columns (starting psel) doy. n Numeric, Data frame, Vector, List. Number base samples choose. stratification site, named vector/list samples per site, data frame columns n samples, n_os oversamples column matching identified col_site_id. os Numeric, Vector, List. sample size (proportional) named vector/list number samples per site Ignored n data frame. col_site_id Column. Unquoted column containing site strata IDs (defaults site_id). col_sel_weights Column. Unquoted name column identifying selection weights (defaults psel_std) seed Numeric. Random seed use random sampling. Seed applies specific sampling events (change seed environment). NULL set seed. ... Extra named arguments passed spsurvey::grts().","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/sample_recordings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample recordings — sample_recordings","text":"sampling run grts. Note included dataset spatial, dummy spatial dataset created using dates times create spatial landscape.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/sample_recordings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample recordings — sample_recordings","text":"","code":"s <- clean_site_index(example_sites_clean,   name_date_time = c(\"date_time_start\", \"date_time_end\") ) m <- clean_metadata(project_files = example_files) |>   add_sites(s) |>   calc_sun() #> Extracting ARU info... #> Extracting Dates and Times... #> Joining by columns `date_time_start` and `date_time_end`  params <- sim_selection_weights()  w <- calc_selection_weights(m, params = params)  # No stratification by site samples <- sample_recordings(w, n = 10, os = 0.1, col_site_id = NULL)  # Stratification by site defined by...  # lists samples <- sample_recordings(w, n = list(P01_1 = 2, P02_1 = 5, P03_1 = 2), os = 0.2)  # vectors samples <- sample_recordings(w, n = c(P01_1 = 2, P02_1 = 5, P03_1 = 2), os = 0.2)  # data frame samples <- sample_recordings(   w,   n = data.frame(     site_id = c(\"P01_1\", \"P02_1\", \"P03_1\"),     n = c(2, 5, 2),     n_os = c(0, 0, 1)   ) )"},{"path":"https://arutools.github.io/ARUtools/dev/reference/set_pattern.html","id":null,"dir":"Reference","previous_headings":"","what":"Set pattern into ARUtools environment — set_pattern","title":"Set pattern into ARUtools environment — set_pattern","text":"Set pattern ARUtools environment","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/set_pattern.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set pattern into ARUtools environment — set_pattern","text":"","code":"set_pattern(pattern_name, pattern)"},{"path":"https://arutools.github.io/ARUtools/dev/reference/set_pattern.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set pattern into ARUtools environment — set_pattern","text":"pattern_name string variable set pattern Pattern add ARUtools environment","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/set_pattern.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set pattern into ARUtools environment — set_pattern","text":"","code":"og_pat <- get_pattern(\"pattern_date_time\")  set_pattern(\"pattern_date_time\", create_pattern_date())  glue::glue(\"Default pattern: {og_pat}\") #> Default pattern: (((((\\d{2})(\\/)(\\d{2})(\\/)((([12]{1}\\d{3}))))))|(((((([12]{1}\\d{3})))(_|-|)(\\d{2})(_|-|)(\\d{2}))))) ([0-2]{1}[0-9]{1})(_|-|:|)([0-5]{1}[0-9]{1})((_|-|:|)([0-5]{1}[0-9]{1})) glue::glue(\"Updated pattern: {get_pattern('pattern_date_time')}\") #> Updated pattern: ((((([12]{1}\\d{3})))(_|-|)(\\d{2})(_|-|)(\\d{2})))  set_pattern(\"pattern_date_time\", og_pat)"},{"path":"https://arutools.github.io/ARUtools/dev/reference/sim_selection_weights.html","id":null,"dir":"Reference","previous_headings":"","what":"Create parameters and simulate selection weights — sim_selection_weights","title":"Create parameters and simulate selection weights — sim_selection_weights","text":"function creates explores parameters generating selections. parameters define selection distribution minutes (min) around sun event (sunrise/sunset), well days (day).","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/sim_selection_weights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create parameters and simulate selection weights — sim_selection_weights","text":"","code":"sim_selection_weights(   min_range = c(-70, 240),   min_mean = 30,   min_sd = 60,   day_range = c(120, 201),   day_mean = 161,   day_sd = 20,   offset = 0,   return_log = TRUE,   selection_fun = \"norm\",   selection_var = \"psel_normalized\",   return_params = TRUE,   plot = TRUE )"},{"path":"https://arutools.github.io/ARUtools/dev/reference/sim_selection_weights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create parameters and simulate selection weights — sim_selection_weights","text":"min_range Numeric vector. Range sampling distribution minutes around sun event. min_mean Numeric. Mean sampling distribution minutes sun event. min_sd Numeric. SD minutes sampling distribution minutes around sun event. day_range Date/Datetime/Numeric vector. Range sampling distribution days. Can Dates, Date-times, DOY (day--year, 1-366). day_mean Date/Datetime/Numeric. Mean date sampling distribution days. Can Date, Date-time, DOY (day--year, 1-366). day_sd Numeric. SD days sampling distribution days. offset Numeric. Offset shift time day minutes. return_log Logical. Log density selection function? selection_fun Character. Selection function use. Options lognorm, norm (default), cauchy. selection_var Character. Selection variable plot (plot = TRUE). Options psel, psel_doy, psel_min, psel_std, psel_scaled, psel_normalized (default). return_params Logical. Return parameter list use calc_selection_weights()? plot Logical. Create plot simulated selection weights? return_param = TRUE plot = TRUE plot created side effect. wise, plot returned directly.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/sim_selection_weights.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create parameters and simulate selection weights — sim_selection_weights","text":"Returns either list selection parameters plot simulated selection weights","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/sim_selection_weights.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create parameters and simulate selection weights — sim_selection_weights","text":"","code":"params <- sim_selection_weights()"},{"path":"https://arutools.github.io/ARUtools/dev/reference/sox_spectro.html","id":null,"dir":"Reference","previous_headings":"","what":"Create spectrogram image from wave file — sox_spectro","title":"Create spectrogram image from wave file — sox_spectro","text":"Using external program SoX (Swiss Army knife sound processing programs), create spectrogram image file. Note must SoX installed use function. Spectrograms silently overwritten.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/sox_spectro.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create spectrogram image from wave file — sox_spectro","text":"","code":"sox_spectro(   path,   dir_out = \"Spectrograms\",   prepend = \"spectro_\",   width = NULL,   height = NULL,   start = NULL,   end = NULL,   rate = \"20k\",   dry_run = FALSE,   quiet = FALSE,   sox_file_path = NULL,   skip_check = FALSE )"},{"path":"https://arutools.github.io/ARUtools/dev/reference/sox_spectro.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create spectrogram image from wave file — sox_spectro","text":"path Character. Path wave file. dir_out Character. Output directory. prepend Character. Text add start output file. Defaults \"spectro_\". width Numeric. Width spectrogram image pixels. height Numeric. Height spectrogram image pixels. start Numeric/Character. Start spectrogram time (seconds HH:MM:SS format). end Numeric/Character. End time spectrogram time (seconds HH:MM:SS format). rate Numeric. Audio sampling rate display (used rate effect sox). effectively limits upper frequency spectrogram rate/2. default (\"20k\"), limits spectrogram 10kHz. Use rate = NULL limiting. dry_run Logical. TRUE show sox command, run (debugging understanding precise details). quiet Logical. Whether suppress progress messages non-essential updates. sox_file_path Path sox file installed system level, otherwise NULL. skip_check Logical. function skip check ensure SoX installed. may allow speed ups running across large numbers files.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/sox_spectro.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create spectrogram image from wave file — sox_spectro","text":"return anything, creates spectrogram image dir_out.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/sox_spectro.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create spectrogram image from wave file — sox_spectro","text":"arguments passed seewave::sox() command. width height correspond -x -y options spectrogram effect. start end used trim effect rate passed rate effect Based code Sam Hache.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/sox_spectro.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create spectrogram image from wave file — sox_spectro","text":"","code":"# Prep sample file w <- tuneR::sine(440, duration = 300000) td <- tempdir() temp_wave <- glue::glue(\"{td}/test_wave.wav\") tuneR::writeWave(w, temp_wave)  # Create spectrograms  try({sox_spectro(temp_wave) sox_spectro(temp_wave, rate = NULL) sox_spectro(temp_wave, start = 2, end = 3) sox_spectro(temp_wave, start = \"0:01\", end = \"0:04\") sox_spectro(temp_wave, prepend = \"\") }) #> Error in check_sox(sox_file_path) : SoX not available  # Clean up unlink(temp_wave) unlink(\"Spectrograms\", recursive = TRUE)"},{"path":"https://arutools.github.io/ARUtools/dev/reference/task_template.html","id":null,"dir":"Reference","previous_headings":"","what":"Example template of tasks for WildTrax — task_template","title":"Example template of tasks for WildTrax — task_template","text":"data frame tasks generated example_clean using wildRtrax::wt_make_aru_tasks() function. Allows updating tasks WildTrax https://wildtrax.ca/.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/task_template.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example template of tasks for WildTrax — task_template","text":"","code":"task_template"},{"path":[]},{"path":"https://arutools.github.io/ARUtools/dev/reference/task_template.html","id":"task-template","dir":"Reference","previous_headings":"","what":"task_template","title":"Example template of tasks for WildTrax — task_template","text":"data frame 14 rows 13 columns: location Site location name recording_date_time Date time recording method Method interpretation (generally '1SPT') taskLength Length recording seconds transcriber Transcriber ID, filled function rain Empty character filling WildTrax wind Empty character filling WildTrax industryNoise Empty character filling WildTrax audioQuality Empty character filling WildTrax taskComments Empty character filling WildTrax internal_task_id Empty character filling WildTrax","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/task_template.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example template of tasks for WildTrax — task_template","text":"data-raw/data_wt_assign_tasks.R","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/temp_wavs.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function to create test wave files — temp_wavs","title":"Helper function to create test wave files — temp_wavs","text":"Creates directory structure example wave files temp folders.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/temp_wavs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function to create test wave files — temp_wavs","text":"","code":"temp_wavs(n = 6)"},{"path":"https://arutools.github.io/ARUtools/dev/reference/temp_wavs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function to create test wave files — temp_wavs","text":"n Numeric. many test files create (six). D","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/temp_wavs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function to create test wave files — temp_wavs","text":"vector paths temporary wave files","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/temp_wavs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Helper function to create test wave files — temp_wavs","text":"","code":"temp_wavs(n=3) #> /tmp/Rtmpw1zXNY/waves/site1/file1.wav /tmp/Rtmpw1zXNY/waves/site2/file2.wav  #> /tmp/Rtmpw1zXNY/waves/site3/file3.wav"},{"path":"https://arutools.github.io/ARUtools/dev/reference/template_observers.html","id":null,"dir":"Reference","previous_headings":"","what":"Example template of tasks for WildTrax — template_observers","title":"Example template of tasks for WildTrax — template_observers","text":"data frame showing example observers effort","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/template_observers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example template of tasks for WildTrax — template_observers","text":"","code":"template_observers"},{"path":[]},{"path":"https://arutools.github.io/ARUtools/dev/reference/template_observers.html","id":"template-observers","dir":"Reference","previous_headings":"","what":"template_observers","title":"Example template of tasks for WildTrax — template_observers","text":"data frame 4 rows 2 columns: transcriber Interpreter name Wildtrax system hrs Number hours assign interpreter","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/template_observers.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example template of tasks for WildTrax — template_observers","text":"data-raw/data_wt_assign_tasks.R","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/wind_detection_pre_processing.html","id":null,"dir":"Reference","previous_headings":"","what":"Pre-processing of files for Wind Detection program — wind_detection_pre_processing","title":"Pre-processing of files for Wind Detection program — wind_detection_pre_processing","text":"function takes vector wave file names returns list three vectors can provided wind detection software written files software can read. Details usable fork wind detection software can found https://github.com/dhope/WindNoiseDetection","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/wind_detection_pre_processing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pre-processing of files for Wind Detection program — wind_detection_pre_processing","text":"","code":"wind_detection_pre_processing(   wav_files,   site_pattern,   output_directory,   write_to_file = FALSE,   chunk_size = NULL )"},{"path":"https://arutools.github.io/ARUtools/dev/reference/wind_detection_pre_processing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pre-processing of files for Wind Detection program — wind_detection_pre_processing","text":"wav_files Vector path wav files site_pattern Pattern extract sites file names output_directory Directory path export files write_to_file Logical function write files output_directory chunk_size Numeric NULL, sets number files include chunk","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/wind_detection_pre_processing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pre-processing of files for Wind Detection program — wind_detection_pre_processing","text":"List including filePath, filenames, sites suitable wind software.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/wind_detection_pre_processing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pre-processing of files for Wind Detection program — wind_detection_pre_processing","text":"","code":"wind_files <-  wind_detection_pre_processing(  wav_files = example_clean$path,    output_directory = td,      site_pattern = create_pattern_site_id(          p_digits = c(2, 3), sep = \"_\",              s_digits = c(1, 2)                ),                  write_to_file = FALSE, chunk_size = NULL                  )"},{"path":"https://arutools.github.io/ARUtools/dev/reference/wind_detection_summarize_json.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize wind detection results — wind_detection_summarize_json","title":"Summarize wind detection results — wind_detection_summarize_json","text":"function takes output command line program summarizes . Details wind detection software can found https://github.com/dhope/WindNoiseDetection.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/wind_detection_summarize_json.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize wind detection results — wind_detection_summarize_json","text":"","code":"wind_detection_summarize_json(f)"},{"path":"https://arutools.github.io/ARUtools/dev/reference/wind_detection_summarize_json.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize wind detection results — wind_detection_summarize_json","text":"f filepath json #'","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/wind_detection_summarize_json.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize wind detection results — wind_detection_summarize_json","text":"tibble summarized data json file","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/wind_detection_summarize_json.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize wind detection results — wind_detection_summarize_json","text":"","code":"# example code   example_json <- system.file(\"extdata\",  \"P71-1__20210606T232500-0400_SS.json\",  package = \"ARUtools\"  )   wind_summary <- wind_detection_summarize_json(example_json)"},{"path":"https://arutools.github.io/ARUtools/dev/reference/wt_assign_tasks.html","id":null,"dir":"Reference","previous_headings":"","what":"Assign tasks for interpretation on Wildtrax — wt_assign_tasks","title":"Assign tasks for interpretation on Wildtrax — wt_assign_tasks","text":"Assign tasks interpretation Wildtrax","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/wt_assign_tasks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assign tasks for interpretation on Wildtrax — wt_assign_tasks","text":"","code":"wt_assign_tasks(   wt_task_template_in,   interp_hours,   wt_task_output_file,   interp_hours_column,   random_seed = NULL )"},{"path":"https://arutools.github.io/ARUtools/dev/reference/wt_assign_tasks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assign tasks for interpretation on Wildtrax — wt_assign_tasks","text":"wt_task_template_in Path csv template downloaded Wildtrax platform https://wildtrax.ca listing tasks. Alternatively, can data.frame correctly formatted using wildRtrax::wt_make_aru_tasks(). See vignette(\"Misc\") details. interp_hours Path number hours interpreter data.table. file, must csv must include columns \"transcriber\" whatever variable interp_hours_column . wt_task_output_file Path csv output file uploading Wildtrax. left NULL write file interp_hours_column LazyEval column name hours interpreters random_seed Integer. Random seed select . left NULL use timestamp","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/wt_assign_tasks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assign tasks for interpretation on Wildtrax — wt_assign_tasks","text":"Returns list tibble assigned tasks summary tibble.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/reference/wt_assign_tasks.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Assign tasks for interpretation on Wildtrax — wt_assign_tasks","text":"","code":"task_output <- wt_assign_tasks(   wt_task_template_in = task_template,   wt_task_output_file = NULL,   interp_hours = template_observers,   interp_hours_column = hrs,   random_seed = 65122   )"},{"path":[]},{"path":"https://arutools.github.io/ARUtools/dev/news/index.html","id":"bugs-development-version","dir":"Changelog","previous_headings":"","what":"Bugs","title":"ARUtools (development version)","text":"Base pipe placeholder calc_sun() causing build fail R version 4.1. Placeholder removed","code":""},{"path":"https://arutools.github.io/ARUtools/dev/news/index.html","id":"arutools-071","dir":"Changelog","previous_headings":"","what":"ARUtools 0.7.1","title":"ARUtools 0.7.1","text":"CRAN release: 2024-10-08","code":""},{"path":"https://arutools.github.io/ARUtools/dev/news/index.html","id":"bugs-0-7-1","dir":"Changelog","previous_headings":"","what":"Bugs","title":"ARUtools 0.7.1","text":"clip_wave() failing due error rlang evaulation nse_names(). (#44)","code":""},{"path":"https://arutools.github.io/ARUtools/dev/news/index.html","id":"arutools-070","dir":"Changelog","previous_headings":"","what":"ARUtools 0.7.0","title":"ARUtools 0.7.0","text":"CRAN release: 2024-09-06","code":""},{"path":"https://arutools.github.io/ARUtools/dev/news/index.html","id":"new-0-7-0","dir":"Changelog","previous_headings":"","what":"New","title":"ARUtools 0.7.0","text":"create_pattern_tz_offset() creates pattern look offset. new function create_lookaround() helps create patterns. Add internal environment global variables get_pattern(), add_pattern_aru_type(), set_pattern() added helper functions. ARU type detection improved now includes manufacturer type. New function guess_ARU_type() can called path guess ARU type.","code":""},{"path":"https://arutools.github.io/ARUtools/dev/news/index.html","id":"update-0-7-0","dir":"Changelog","previous_headings":"","what":"Update","title":"ARUtools 0.7.0","text":"“job” package removed clip_wav() ( #25 ) Updates clean_logs() (#28, #34)","code":""},{"path":"https://arutools.github.io/ARUtools/dev/news/index.html","id":"bugs-0-7-0","dir":"Changelog","previous_headings":"","what":"Bugs","title":"ARUtools 0.7.0","text":"Fix issue oversamples (GRTS fails select_samples() n data frame n_os zero. #40) Fix to_lower() check_names() causes error upper cases used. #41","code":""},{"path":"https://arutools.github.io/ARUtools/dev/news/index.html","id":"arutools-062","dir":"Changelog","previous_headings":"","what":"ARUtools 0.6.2","title":"ARUtools 0.6.2","text":"CRAN release: 2024-04-18 Initial CRAN submission. 1st CRAN version! 🥳 Changes since 0.6.1 relate getting package ready CRAN submission included improved documentation, final coverage tests, removing unnecessary functions. #36 tracks workflow submission Removed play_random_track() (dd3ddb195fe50c37cb83a15110651c4c659014dd) #38 Added examples final functions remove necessary (44879bd3508af743049f0c5528d386d9f56a8475)","code":""},{"path":[]},{"path":"https://arutools.github.io/ARUtools/dev/news/index.html","id":"new-0-6-0","dir":"Changelog","previous_headings":"","what":"New","title":"ARUtools 0.6.0","text":"Cleaned functions recording selection, spectrograms, clipping waves, acoustic indices creating dirs (#8, #11, #12, #13, #23) Added NSE relevant functions, now use col_COLNAME, changed arguments non-NSE functions name_COLNAME (#15) Ensure data order unchanged passing cleaning functions (#19) Added sampling vignette","code":""},{"path":"https://arutools.github.io/ARUtools/dev/news/index.html","id":"bugs-0-6-0","dir":"Changelog","previous_headings":"","what":"Bugs","title":"ARUtools 0.6.0","text":"Fixed bug calc_sun() corrupting date column (#18)","code":""},{"path":[]},{"path":"https://arutools.github.io/ARUtools/dev/news/index.html","id":"new-0-5-1","dir":"Changelog","previous_headings":"","what":"New","title":"ARUtools 0.5.1","text":"add_wildtrax() - New helper function create append WildTrax file names","code":""},{"path":"https://arutools.github.io/ARUtools/dev/news/index.html","id":"bugs-0-5-1","dir":"Changelog","previous_headings":"","what":"Bugs","title":"ARUtools 0.5.1","text":"clean_gps() - Fixed errors processing GPX files","code":""},{"path":"https://arutools.github.io/ARUtools/dev/news/index.html","id":"arutools-050","dir":"Changelog","previous_headings":"","what":"ARUtools 0.5.0","title":"ARUtools 0.5.0","text":"clean_gps() can handle GPX files via sf now distance cutoff results warning (error), returning data max_dist column, users can see site problematic. now checks distance site groups aru_id site_id default pattern matches GPS column headers expanded catches errors continues reporting failed loading (remove skip_bad argument) check_problems() now also checks GPS meta data create_pattern_XXX() Now accept multiple options separators non-optional, provide \"\" pseudo-optional create_pattern_site_id() ids suffix clean_metadata() accepts multiple pattern options clean_site_index() allows date columns (col_date_time = NULL) add_sites() Rename dt_type by_date Take mean multiple sites by_date = \"date\" (instead truncating) Use by_date = NULL skip joining date range Workflow now works sf input (must POINT geometries) clean_site_index() add_sites() calc_sun() Timezones now explicit Expect local time marked UTC Existing non-UTC timezones stripped message Errors returned one relevant date_time column different timezones Vignettes Mini spatial workflow (vignettes/spatial.Rmd) Explaining timezones (vignettes/timezones.Rmd)","code":""},{"path":"https://arutools.github.io/ARUtools/dev/news/index.html","id":"arutools-0409000","dir":"Changelog","previous_headings":"","what":"ARUtools 0.4.0.9000","title":"ARUtools 0.4.0.9000","text":"Major overhaul first half workflow Main functions now clean_metadata() clean_gps() / clean_site_index() add_sites() calc_sun() Helper functions checking, creating regex patterns","code":""}]
