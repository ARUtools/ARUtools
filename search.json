[{"path":"http://arutools.github.io/ARUtools/CODE_DESIGN.html","id":null,"dir":"","previous_headings":"","what":"Code Design","title":"Code Design","text":"file contains notes code design conventions aim making collaboration future modifications easier.","code":""},{"path":"http://arutools.github.io/ARUtools/CODE_DESIGN.html","id":"naming","dir":"","previous_headings":"","what":"Naming","title":"Code Design","text":"Snake case used wherever possible Test files named test-XX_DESCRIPTION.R, XX order run (try test lower order functions first).","code":""},{"path":"http://arutools.github.io/ARUtools/CODE_DESIGN.html","id":"column-names","dir":"","previous_headings":"","what":"Column names","title":"Code Design","text":"initial cleaning functions (clean_metadata(), clean_site_index()) users can specify existing column names, formatted standard names file_name, path date, date_start, date_end, date_time, date_time_start, date_time_end aru_id, aru_type, site_id longitude, latitude tz, t2sr, t2ss add_sites() allow adding keeping extra columns (col_extra = ...)","code":""},{"path":"http://arutools.github.io/ARUtools/CODE_DESIGN.html","id":"regular-expression-patterns","dir":"","previous_headings":"","what":"Regular Expression patterns","title":"Code Design","text":"create_pattern_XXX() e.g., patterns extracting data GPS files","code":""},{"path":"http://arutools.github.io/ARUtools/CODE_DESIGN.html","id":"nitty-gritty-of-patterns-esp-for-datetimes","dir":"","previous_headings":"","what":"Nitty gritty of patterns (esp for date/times)","title":"Code Design","text":"Multiple patterns can created supplying multiple arguments create_pattern_XXX() functions, supplying vector patterns clean_metadata() (example). Date/time patterns order need specified pattern creation, also clean_metadata() (order_date) two steps, extracting pattern parsing pattern. Currently, although seconds can enforced, omitted optional create_pattern_time() function, always optional parsing function (.e. lubridate::parse_date_time(... truncated = 1)). necessary, made optional parsing adding another argument optional_sec similar, may overkill now Right now, users supply date, sep, time patterns, possibly, might worth option supply single date/time pattern take precedence. ’s unclear often necessary, however. possibility matching different numbers numbers (.e. can match 2 year digits 4 year digits), always use rev(sort(digits)), (sort(digits, decreasing = TRUE)) ensure longer patterns can matched comparing shorter patterns","code":""},{"path":"http://arutools.github.io/ARUtools/CODE_DESIGN.html","id":"verbosity","dir":"","previous_headings":"","what":"Verbosity","title":"Code Design","text":"ARUtools pretty chatty result clear weird data handled quiet argument FALSE default. TRUE, non-essential, FYI messages suppressed (warnings, informative problem messages) verbose argument (currently clean_gps()) default FALSE. TRUE, shows even information (generally unnecessary unless troubleshooting specific problem)","code":""},{"path":"http://arutools.github.io/ARUtools/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"http://arutools.github.io/ARUtools/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"http://arutools.github.io/ARUtools/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"http://arutools.github.io/ARUtools/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"http://arutools.github.io/ARUtools/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"http://arutools.github.io/ARUtools/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"http://arutools.github.io/ARUtools/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"http://arutools.github.io/ARUtools/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"http://arutools.github.io/ARUtools/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"http://arutools.github.io/ARUtools/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"http://arutools.github.io/ARUtools/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"http://arutools.github.io/ARUtools/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"http://arutools.github.io/ARUtools/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"http://arutools.github.io/ARUtools/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"http://arutools.github.io/ARUtools/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"http://arutools.github.io/ARUtools/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"http://arutools.github.io/ARUtools/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"http://arutools.github.io/ARUtools/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"http://arutools.github.io/ARUtools/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"http://arutools.github.io/ARUtools/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"http://arutools.github.io/ARUtools/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"http://arutools.github.io/ARUtools/articles/ARUtools.html","id":"read-file-metadata","dir":"Articles","previous_headings":"","what":"Read file metadata","title":"Getting started with ARUtools","text":"Let’s use example data get started. list hypothetical ARU files different sites, using different ARUs. fairly messily organized data clear structure folders appear unneeded characters files. However give standard structure site names, ARU ID codes, datetime stamps, can extract information file structure alone. First things first, ’ll clean meta data associated files. example files follow standard formats Site ID, ARU Id, date/time, can extract information without change default arguments. reading directly files assign base directory clean_metadata read files folder sub-folders.","code":"library(ARUtools) head(example_files) #> [1] \"a_BARLT10962_P01_1/P01_1_20200502T050000_ARU.wav\" #> [2] \"a_BARLT10962_P01_1/P01_1_20200503T052000_ARU.wav\" #> [3] \"a_S4A01234_P02_1/P02_1_20200504T052500_ARU.wav\"   #> [4] \"a_S4A01234_P02_1/P02_1_20200505T073000_ARU.wav\"   #> [5] \"a_BARLT10962_P03_1/P03_1_20200506T100000_ARU.wav\" #> [6] \"a_BARLT11111_P04_1/P04_1_20200506T050000_ARU.wav\" m <- clean_metadata(project_files = example_files) #> Extracting ARU info... #> Extracting Dates and Times... m #> # A tibble: 42 × 8 #>   file_name   type  path  aru_type aru_id site_id date_time           date       #>   <chr>       <chr> <chr> <chr>    <chr>  <chr>   <dttm>              <date>     #> 1 P01_1_2020… wav   a_BA… BarLT    BARLT… P01_1   2020-05-02 05:00:00 2020-05-02 #> 2 P01_1_2020… wav   a_BA… BarLT    BARLT… P01_1   2020-05-03 05:20:00 2020-05-03 #> 3 P03_1_2020… wav   a_BA… BarLT    BARLT… P03_1   2020-05-06 10:00:00 2020-05-06 #> 4 P05_1_2020… wav   a_BA… BarLT    BARLT… P05_1   2020-05-07 05:00:00 2020-05-07 #> # ℹ 38 more rows base_directory <- \"/path/to/project/files/\" m <- clean_metadata(project_dir = base_directory)"},{"path":"http://arutools.github.io/ARUtools/articles/ARUtools.html","id":"add-coordinates","dir":"Articles","previous_headings":"","what":"Add coordinates","title":"Getting started with ARUtools","text":"Next, want add coordinates data. data GPS logs included, detected step now use g <- clean_gps(m) create list GPS coordinates. However, many models ARUs internal GPS , may accurately record location ARU deployed . Therefore recommend create site index file manually record deployment locations, like one. can simply specify single date, recommended use start date end date best matching. critical moving ARUs season. Now let’s clean list can add sites metadata. Ooops! can see right away clean_site_index() expects data particular format. Luckily can let know ’ve used different format. Hmm, ’s interesting message! means deployment dates overlap. ARUtools assumes set ARU specific day, probably didn’t set midnight (.e. start day). Since assume likely using ARUs recording early morning late night, shift dates start/end times noon estimate ARU likely deployed. ARU deployed midnight, use resolve_ovelaps = FALSE. , know exact time ARU deployed, use date/time rather just date site index. Note ’ve lost couple non-standard columns: Plots Subplot. can retain specifying cols_extra. can even fancy rename consistency using named vectors. Now let’s add site-related information metadata.","code":"example_sites #>    Sites Date_set_out Date_removed        ARU    lon    lat Plots Subplot #> 1  P01_1   2020-05-01   2020-05-03 BARLT10962 -85.03 50.010 Plot1       a #> 2  P02_1   2020-05-03   2020-05-05   S4A01234 -87.45 52.680 Plot1       a #> 3  P03_1   2020-05-05   2020-05-06 BARLT10962 -90.38 48.990 Plot2       a #> 4  P04_1   2020-05-05   2020-05-07 BARLT11111 -85.53 45.000 Plot2       a #> 5  P05_1   2020-05-06   2020-05-07 BARLT10962 -88.45 51.050 Plot3       b #> 6  P06_1   2020-05-08   2020-05-09 BARLT10962 -90.08 52.000 Plot1       a #> 7  P07_1   2020-05-08   2020-05-10   S4A01234 -86.03 50.450 Plot1       a #> 8  P08_1   2020-05-10   2020-05-11 BARLT10962 -84.45 48.999 Plot2       a #> 9  P09_1   2020-05-10   2020-05-11   S4A02222 -91.38 45.000 Plot2       a #> 10 P10_1   2020-05-10   2020-05-11   S4A03333 -90.00 50.010 Plot3       b sites <- clean_site_index(example_sites) #> Error: #> ! Problems with data `site_index`: #> • Column 'site_id' does not exist #> • Column 'date' does not exist #> • Column 'aru_id' does not exist #> • Column 'longitude' does not exist #> • Column 'latitude' does not exist #> • See ?clean_site_index sites <- clean_site_index(example_sites,                            col_aru_id = \"ARU\",                            col_site_id = \"Sites\",                            col_date_time = c(\"Date_set_out\", \"Date_removed\"),                           col_coords = c(\"lon\", \"lat\")) #> There are overlapping date ranges #> • Shifting start/end times to 'noon' #> • Skip this with `resolve_overlaps = FALSE` sites #> # A tibble: 10 × 8 #>   site_id aru_id   date_time_start     date_time_end       date_start date_end   #>   <chr>   <chr>    <dttm>              <dttm>              <date>     <date>     #> 1 P01_1   BARLT10… 2020-05-01 12:00:00 2020-05-03 12:00:00 2020-05-01 2020-05-03 #> 2 P02_1   S4A01234 2020-05-03 12:00:00 2020-05-05 12:00:00 2020-05-03 2020-05-05 #> 3 P03_1   BARLT10… 2020-05-05 12:00:00 2020-05-06 12:00:00 2020-05-05 2020-05-06 #> 4 P04_1   BARLT11… 2020-05-05 12:00:00 2020-05-07 12:00:00 2020-05-05 2020-05-07 #> # ℹ 6 more rows #> # ℹ 2 more variables: longitude <dbl>, latitude <dbl> sites <- clean_site_index(example_sites,                            col_aru_id = \"ARU\",                            col_site_id = \"Sites\",                            col_date_time = c(\"Date_set_out\", \"Date_removed\"),                           col_coords = c(\"lon\", \"lat\"),                           col_extra = c(\"Plots\", \"Subplot\")) #> There are overlapping date ranges #> • Shifting start/end times to 'noon' #> • Skip this with `resolve_overlaps = FALSE` sites #> # A tibble: 10 × 10 #>   site_id aru_id   date_time_start     date_time_end       date_start date_end   #>   <chr>   <chr>    <dttm>              <dttm>              <date>     <date>     #> 1 P01_1   BARLT10… 2020-05-01 12:00:00 2020-05-03 12:00:00 2020-05-01 2020-05-03 #> 2 P02_1   S4A01234 2020-05-03 12:00:00 2020-05-05 12:00:00 2020-05-03 2020-05-05 #> 3 P03_1   BARLT10… 2020-05-05 12:00:00 2020-05-06 12:00:00 2020-05-05 2020-05-06 #> 4 P04_1   BARLT11… 2020-05-05 12:00:00 2020-05-07 12:00:00 2020-05-05 2020-05-07 #> # ℹ 6 more rows #> # ℹ 4 more variables: longitude <dbl>, latitude <dbl>, Plots <chr>, #> #   Subplot <chr> sites <- clean_site_index(example_sites,                            col_aru_id = \"ARU\",                            col_site_id = \"Sites\",                            col_date_time = c(\"Date_set_out\", \"Date_removed\"),                           col_coords = c(\"lon\", \"lat\"),                           col_extra = c(\"plot\" = \"Plots\", \"subplot\" = \"Subplot\")) #> There are overlapping date ranges #> • Shifting start/end times to 'noon' #> • Skip this with `resolve_overlaps = FALSE` sites #> # A tibble: 10 × 10 #>   site_id aru_id   date_time_start     date_time_end       date_start date_end   #>   <chr>   <chr>    <dttm>              <dttm>              <date>     <date>     #> 1 P01_1   BARLT10… 2020-05-01 12:00:00 2020-05-03 12:00:00 2020-05-01 2020-05-03 #> 2 P02_1   S4A01234 2020-05-03 12:00:00 2020-05-05 12:00:00 2020-05-03 2020-05-05 #> 3 P03_1   BARLT10… 2020-05-05 12:00:00 2020-05-06 12:00:00 2020-05-05 2020-05-06 #> 4 P04_1   BARLT11… 2020-05-05 12:00:00 2020-05-07 12:00:00 2020-05-05 2020-05-07 #> # ℹ 6 more rows #> # ℹ 4 more variables: longitude <dbl>, latitude <dbl>, plot <chr>, #> #   subplot <chr> m <- add_sites(m, sites) #> Joining by columns `date_time_start` and `date_time_end` m #> # A tibble: 42 × 12 #>   file_name   type  path  aru_type aru_id site_id date_time           date       #>   <chr>       <chr> <chr> <chr>    <chr>  <chr>   <dttm>              <date>     #> 1 P01_1_2020… wav   a_BA… BarLT    BARLT… P01_1   2020-05-02 05:00:00 2020-05-02 #> 2 P01_1_2020… wav   a_BA… BarLT    BARLT… P01_1   2020-05-03 05:20:00 2020-05-03 #> 3 P01_1_2020… wav   j_BA… BarLT    BARLT… P01_1   2020-05-02 05:00:00 2020-05-02 #> 4 P01_1_2020… wav   j_BA… BarLT    BARLT… P01_1   2020-05-03 05:20:00 2020-05-03 #> # ℹ 38 more rows #> # ℹ 4 more variables: longitude <dbl>, latitude <dbl>, plot <chr>, #> #   subplot <chr>"},{"path":"http://arutools.github.io/ARUtools/articles/ARUtools.html","id":"calculate-times-to-sunrise-and-sunset","dir":"Articles","previous_headings":"","what":"Calculate times to sunrise and sunset","title":"Getting started with ARUtools","text":"Great! site-related information describe recording. Now prepare selection procedure, last thing need calculate time sunrise sunset. need clear timezone ARU unit recording times . two options. first option ARUs set home base deployment. case ’s possible deployed location different timezone recording . doesn’t matter, long specify programmed timezone . case, use tz = \"America/Toronto\", whichever time zone used. Note timezones must one OlsonNames(). second option ARU unit set record local timezone placed. case, specify tz = \"local\" calc_sun() function use coordinates determine local timezones. (See Dealing Timezones vignette details). example, let’s assume ARUs set location deployed. ’ll use tz = \"local\", default setting. Tada! Now complete set cleaned metadata associated recording. simple example much pain large projects comes complications, sure check vignette(\"customizing\") vignette(\"spatial\") dig issues.","code":"m <- calc_sun(m) dplyr::glimpse(m) #> Rows: 42 #> Columns: 15 #> $ file_name <chr> \"P01_1_20200502T050000_ARU.wav\", \"P01_1_20200503T052000_ARU.… #> $ type      <chr> \"wav\", \"wav\", \"wav\", \"wav\", \"wav\", \"wav\", \"wav\", \"wav\", \"wav… #> $ path      <chr> \"a_BARLT10962_P01_1/P01_1_20200502T050000_ARU.wav\", \"a_BARLT… #> $ aru_type  <chr> \"BarLT\", \"BarLT\", \"BarLT\", \"BarLT\", \"BarLT\", \"BarLT\", \"SongM… #> $ aru_id    <chr> \"BARLT10962\", \"BARLT10962\", \"BARLT10962\", \"BARLT10962\", \"BAR… #> $ site_id   <chr> \"P01_1\", \"P01_1\", \"P01_1\", \"P01_1\", \"P01_1\", \"P01_1\", \"P02_1… #> $ date_time <dttm> 2020-05-02 05:00:00, 2020-05-03 05:20:00, 2020-05-02 05:00:… #> $ date      <date> 2020-05-02, 2020-05-03, 2020-05-02, 2020-05-03, 2020-05-02,… #> $ longitude <dbl> -85.03, -85.03, -85.03, -85.03, -85.03, -85.03, -87.45, -87.… #> $ latitude  <dbl> 50.01, 50.01, 50.01, 50.01, 50.01, 50.01, 52.68, 52.68, 52.6… #> $ plot      <chr> \"Plot1\", \"Plot1\", \"Plot1\", \"Plot1\", \"Plot1\", \"Plot1\", \"Plot1… #> $ subplot   <chr> \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", … #> $ tz        <chr> \"America/Toronto\", \"America/Toronto\", \"America/Toronto\", \"Am… #> $ t2sr      <dbl> -74.933333, -53.216667, -74.933333, -53.216667, -74.933333, … #> $ t2ss      <dbl> 479.9500, 498.4167, 479.9500, 498.4167, 479.9500, 498.4167, …"},{"path":"http://arutools.github.io/ARUtools/articles/ARUtools.html","id":"next-steps","dir":"Articles","previous_headings":"","what":"Next steps","title":"Getting started with ARUtools","text":"Now set cleaned metadata next step select recordings. using random sampling approach check subsampling article vignette(\"SubSample\").","code":""},{"path":"http://arutools.github.io/ARUtools/articles/Misc.html","id":"setting-up-your-folder-structure","dir":"Articles","previous_headings":"","what":"Setting up your folder structure","title":"Other useful functions","text":"ARUtools focuses processing recordings transferred ARUs, setting folder structure can greatly increase efficiency transferring files. set folder structure need hierarchical structure wish use list sites/arus processing. create series folders plot main level site subdirectory . Note work project structures think carefully want set file names, folder structure spatial information deploy ARUs.","code":"site_list <-  example_sites |>    tidyr::separate(Sites, into = c(\"plot\", \"site\"), sep = \"_\", remove = F) |>    dplyr::select(site_id=Sites, plot, site)       tmp_dir <- tempdir(check = T) |> paste0(\"/ARUtools/\") dir.create(tmp_dir)  create_directory_structure(hexagons = site_list$plot,                            units = site_list$site_id,                             base_dir = tmp_dir) list.dirs(tmp_dir, full.names = F)"},{"path":"http://arutools.github.io/ARUtools/articles/Misc.html","id":"wind-processing","dir":"Articles","previous_headings":"","what":"Wind processing","title":"Other useful functions","text":"One issue can cause difficulty interpretation acoustic recordings wind. Wind can mask bird songs even potential danger interpreters’ ears. University Salford Acoustics Research Centre developed softare program WindNoiseDetection detects wind wave files. developed fork software added ability run multiple files using parallel processing provide list files process. Running program requires fairly complex setup Windows uses C C++ requires Cygwin run. However get running, ARUtools includes couple helper functions process metadata set running WindNoiseDetection. output list vectors include path wave files (filePaths), input wave filenames (filenames), list sites append output results (sites). run WindNoiseDetection can read results using wind_detection_summarize_json().","code":"wind_files <-    prep_for_wind_detection(wav_files = example_clean$path,                                      output_directory = \"./wind_files/\",                                       site_pattern = create_pattern_site_id( p_digits = c(2,3), sep = \"_\",                                                                              s_digits = c(1,2)),                                      write_to_file = F, chunk_size = NULL) example_json <- system.file(\"extdata\", \"P71-1__20210606T232500-0400_SS.json\", package = \"ARUtools\")  wind_summary <- wind_detection_summarize_json(example_json) #> Warning: Function in development. Use at own risk dplyr::glimpse(wind_summary) #> Rows: 1 #> Columns: 7 #> $ totalwindless <dbl> 268.58 #> $ pwindless     <dbl> 0.8966715 #> $ n             <int> 5 #> $ length        <dbl> 299.53 #> $ mean_windless <dbl> 53.716 #> $ name          <chr> \"/cygdrive/P/Path/To/WaveFile/NL/P71/P71-1/20210606_Napk… #> $ jsonF         <chr> \"P71-1__20210606T232500-0400_SS.json\""},{"path":"http://arutools.github.io/ARUtools/articles/Misc.html","id":"assign-tasks","dir":"Articles","previous_headings":"","what":"Assign tasks","title":"Other useful functions","text":"assign tasks need either download task template WildTrax alternatively can use new wildRtrax::wt_make_aru_tasks() function. also need template observers number hours interpreting. doesn’t match exactly time project relative amounts used. files need, can run wt_assign_tasks() randomly assign tasks interpreters based amount effort can put . can alternatively use Shiny app Shiny_select running following:","code":"in_tasks <- fs::file_temp(\"Input_task_file\", ext = \".csv\") task_template <- wildRtrax::wt_make_aru_tasks(example_clean |>                                 dplyr::mutate(                                  recording_date_time = date_time,                                  file_path = path, location = site_id,                                  length_seconds = 300),                               output = in_tasks,                                task_method = '1SPT', task_length = 300) template_observers <-    \"https://raw.githubusercontent.com/dhope/Shiny_select/main/data/InterpreterHours_Template.csv\" task_output <- wt_assign_tasks(wt_task_template_in = task_template,                  wt_task_output_file = NULL,                 interp_hours_file = template_observers,                 interp_hours_column = hrs,                  random_seed = 65416                 ) #> Rows: 4 Columns: 2 #> ── Column specification ──────────────────────────────────────────────────────── #> Delimiter: \",\" #> chr (1): transcriber #> dbl (1): hrs #>  #> ℹ Use `spec()` to retrieve the full column specification for this data. #> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.  task_output$task_summary #> # A tibble: 3 × 5 #>   transcriber                   hrs_assigned   hrs  phrs updated_hrs_remain #>   <chr>                                <dbl> <dbl> <dbl>              <dbl> #> 1 John Yossarian                       0.333   6.5 0.439               6.17 #> 2 Rodion Romanovich Raskolnikov        0.5     2.3 0.155               1.8  #> 3 Charles Dickens                      0.333   5   0.338               4.67 shiny::runGitHub(\"dhope/Shiny_select\")"},{"path":"http://arutools.github.io/ARUtools/articles/SubSample.html","id":"create-data","dir":"Articles","previous_headings":"","what":"Create data","title":"Subsampling recordings","text":"generate data sites example_sites. Click triangle see details method. simulate file names generate series recordings site. schedule every 30 minutes 5:30 8:00 every second day 1 May 10 July. Normally want schedule based around local sunrise targeting dawn chorus, work purposes. site info used example_sites.","code":"library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(stringr) library(lubridate) #>  #> Attaching package: 'lubridate' #> The following objects are masked from 'package:base': #>  #>     date, intersect, setdiff, union  simple_deploy <-  tidyr::expand_grid(site_id = unique(example_sites$Sites),                                        doy = seq(121,191, by = 2),                    times = seq(-30, 120, by = 30)) |>    tidyr::separate(site_id, into = c(\"plot\", \"site\"), sep = \"_\", remove = F) |>    left_join(example_sites, join_by(site_id == Sites)) |>    mutate(     # aru_id = glue::glue(\"BARLT-000{as.numeric(as.factor(site_id))}\"),     date = ymd(\"2028-01-01\")+doy,          date_time = ymd_hm(glue::glue(\"{date} 06:00\"))+minutes(times),          date_time_chr = str_replace(as.character(date_time), \"\\\\s\", \"T\"),          file_name = glue::glue(\"{plot}/{site_id}/{ARU}_{date_time_chr}.wav\") )    simple_deploy #> # A tibble: 2,160 × 16 #>   site_id plot  site    doy times Date_set_out Date_removed ARU        lon   lat #>   <chr>   <chr> <chr> <dbl> <dbl> <chr>        <chr>        <chr>    <dbl> <dbl> #> 1 P01_1   P01   1       121   -30 2020-05-01   2020-05-03   BARLT10… -85.0  50.0 #> 2 P01_1   P01   1       121     0 2020-05-01   2020-05-03   BARLT10… -85.0  50.0 #> 3 P01_1   P01   1       121    30 2020-05-01   2020-05-03   BARLT10… -85.0  50.0 #> 4 P01_1   P01   1       121    60 2020-05-01   2020-05-03   BARLT10… -85.0  50.0 #> # ℹ 2,156 more rows #> # ℹ 6 more variables: Plots <chr>, Subplot <chr>, date <date>, #> #   date_time <dttm>, date_time_chr <chr>, file_name <glue> site_info <- simple_deploy |>    slice_min(order_by = date_time, n=1, by = site_id) |>    dplyr::select(site_id, ARU, lon, lat, date_time)"},{"path":"http://arutools.github.io/ARUtools/articles/SubSample.html","id":"clean-metadata","dir":"Articles","previous_headings":"","what":"Clean metadata","title":"Subsampling recordings","text":"clean metadata can use code found Getting Started vignette. used pipe save space , can see details linked article (vignette(\"ARUtools\")).","code":"sites <- clean_site_index(site_info,                           col_aru_id = \"ARU\",                            col_site_id = \"site_id\",                            col_date_time = c(\"date_time\"),                           col_coords = c(\"lon\", \"lat\") ) metadata <- clean_metadata(project_files = simple_deploy$file_name) |>    add_sites( sites) |>    calc_sun() |>    dplyr::mutate( doy = lubridate::yday(date)) #> Extracting ARU info... #> Extracting Dates and Times... #> Joining by column `date_time` using buffers dplyr::glimpse(metadata) #> Rows: 2,160 #> Columns: 14 #> $ file_name <chr> \"BARLT10962_2028-05-01T05:30:00.wav\", \"BARLT10962_2028-05-01… #> $ type      <chr> \"wav\", \"wav\", \"wav\", \"wav\", \"wav\", \"wav\", \"wav\", \"wav\", \"wav… #> $ path      <chr> \"P01/P01_1/BARLT10962_2028-05-01T05:30:00.wav\", \"P01/P01_1/B… #> $ aru_type  <chr> \"BarLT\", \"BarLT\", \"BarLT\", \"BarLT\", \"BarLT\", \"BarLT\", \"BarLT… #> $ aru_id    <chr> \"BARLT10962\", \"BARLT10962\", \"BARLT10962\", \"BARLT10962\", \"BAR… #> $ site_id   <chr> \"P01_1\", \"P01_1\", \"P01_1\", \"P01_1\", \"P01_1\", \"P01_1\", \"P01_1… #> $ date_time <dttm> 2028-05-01 05:30:00, 2028-05-01 06:00:00, 2028-05-01 06:30:… #> $ date      <date> 2028-05-01, 2028-05-01, 2028-05-01, 2028-05-01, 2028-05-01,… #> $ longitude <dbl> -85.03, -85.03, -85.03, -85.03, -85.03, -85.03, -85.03, -85.… #> $ latitude  <dbl> 50.01, 50.01, 50.01, 50.01, 50.01, 50.01, 50.01, 50.01, 50.0… #> $ tz        <chr> \"America/Toronto\", \"America/Toronto\", \"America/Toronto\", \"Am… #> $ t2sr      <dbl> -46.80, -16.80, 13.20, 43.20, 73.20, 103.20, -43.35, -13.35,… #> $ t2ss      <dbl> 511.6167, 541.6167, 571.6167, 601.6167, 631.6167, 661.6167, … #> $ doy       <dbl> 122, 122, 122, 122, 122, 122, 124, 124, 124, 124, 124, 124, …"},{"path":"http://arutools.github.io/ARUtools/articles/SubSample.html","id":"parameters","dir":"Articles","previous_headings":"","what":"Parameters","title":"Subsampling recordings","text":"Generally random sampling may want recordings selected equal weight across time dates. example sampling songbirds breeding season, species active couple hours around sunrise. also want limit dates ensure picking breeding birds migrants. deal issue allow user specify selection weights based time sunrise (sunset) well day year. Note: active area development can expect process assigning variables much simpler next update. visualize selection parameters use gen_dens_sel_simulation. show sample weights change time time sunrise/sunset.","code":"params <- list(min_range = c(-70, 240),                           doy_range = c(120, lubridate::yday(lubridate::ymd(\"2021-07-20\"))),                           mean_min = 30, sd_min = 60,                           mean_doy = lubridate::yday(lubridate::ymd(\"2021-06-10\")),                           sd_doy = 20,off=0,                           log_ = TRUE, fun = \"norm\") gen_dens_sel_simulation(parms = params)"},{"path":"http://arutools.github.io/ARUtools/articles/SubSample.html","id":"calculate-selection-weights","dir":"Articles","previous_headings":"","what":"Calculate selection weights","title":"Subsampling recordings","text":"parameters set , can use calculate sampling weights metadata. can see selection weights psel_normalized. highest selection weights match output gen_dens_sel_simulation(). schedule set start based time, time sunrise recordings occur differ sites.","code":"full_selection_probs <-    metadata |>    calc_sel_pr(     ARU_ID_col = site_id,      min_col = t2sr,      day_col = doy,     parms = params)"},{"path":"http://arutools.github.io/ARUtools/articles/SubSample.html","id":"assign-sample-size","dir":"Articles","previous_headings":"","what":"Assign sample size","title":"Subsampling recordings","text":"next step assign sample sizes. can done per site basis across board. use 2% sampling rate, subsampling intensity depend project goals. can also set oversample draw extra samples case samples unusable (e.g. due wind). figure can provide coarse rule thumb many minutes recordings might need number samples. course many assumptions including knowledge probability observing per minute, probability change date, time day, conspecific behaviour, weather, etc.","code":"sample_size <- count(full_selection_probs,  site_id) |>    transmute(site_id,             N = floor(n*.02),          n_os  = ceiling(N*.3)          )"},{"path":[]},{"path":"http://arutools.github.io/ARUtools/articles/SubSample.html","id":"grts","dir":"Articles","previous_headings":"Draw subsample","what":"GRTS","title":"Subsampling recordings","text":"ways subsample recordings. ARUtools imported grts() (Generalized Random Tessellation Stratified algorithm) function spsurvey package. developed wrapper around function simplify ’s usage particular use case. GRTS allows us sample using dispersed samples, maintaining stochastic element sampling. case selecting samples dispersed across dates time dates.","code":"grts_res <- fun_aru_samp(full_selection_probs,                           N = sample_size,                          strat_ = \"site_id\",                          seed = 2024,                           selprob_id = \"psel_normalized\",                          x = 'doy',y = 't2sr') #> Warning: Since version 0.4 default selection parameter in gen_dens_sel_simulation is psel_normalize, #>          which ranges from 0 to 1. If you wish to base decisions here off the simulation, #>          you can adjust the `selection_variable` paramter, which is an unquoted variable name of which #>          options are psel, psel_doy, psel_tod, psel_std, psel_scaled, or psel_normalized #> [1] \"10\"     \"Sample\"  dplyr::glimpse(grts_res$sites_base) #> Rows: 40 #> Columns: 29 #> $ siteID          <chr> \"Sample-01\", \"Sample-02\", \"Sample-03\", \"Sample-04\", \"S… #> $ siteuse         <chr> \"Base\", \"Base\", \"Base\", \"Base\", \"Base\", \"Base\", \"Base\"… #> $ replsite        <chr> \"None\", \"None\", \"None\", \"None\", \"None\", \"None\", \"None\"… #> $ lon_WGS84       <dbl> 0.001365439, 0.001545102, 0.001203742, 0.001563069, 0.… #> $ lat_WGS84       <dbl> 4.723823e-04, 5.254387e-04, -2.502089e-04, -2.125268e-… #> $ stratum         <chr> \"P01_1\", \"P01_1\", \"P01_1\", \"P01_1\", \"P02_1\", \"P02_1\", … #> $ wgt             <dbl> 35.29300, 36.72486, 72.07435, 38.37921, 33.54426, 76.4… #> $ ip              <dbl> 0.028334233, 0.027229512, 0.013874562, 0.026055777, 0.… #> $ caty            <chr> \"None\", \"None\", \"None\", \"None\", \"None\", \"None\", \"None\"… #> $ aux             <dbl> 0.9307375, 0.8944490, 0.4557587, 0.8558936, 0.9678483,… #> $ file_name       <chr> \"BARLT10962_2028-05-31T06:30:00.wav\", \"BARLT10962_2028… #> $ type            <chr> \"wav\", \"wav\", \"wav\", \"wav\", \"wav\", \"wav\", \"wav\", \"wav\"… #> $ path            <chr> \"P01/P01_1/BARLT10962_2028-05-31T06:30:00.wav\", \"P01/P… #> $ aru_type        <chr> \"BarLT\", \"BarLT\", \"BarLT\", \"BarLT\", \"SongMeter\", \"Song… #> $ aru_id          <chr> \"BARLT10962\", \"BARLT10962\", \"BARLT10962\", \"BARLT10962\"… #> $ site_id         <chr> \"P01_1\", \"P01_1\", \"P01_1\", \"P01_1\", \"P02_1\", \"P02_1\", … #> $ date_time       <dttm> 2028-05-31 06:30:00, 2028-06-20 06:30:00, 2028-05-13 … #> $ date            <date> 2028-05-31, 2028-06-20, 2028-05-13, 2028-06-22, 2028-… #> $ longitude       <dbl> -85.03, -85.03, -85.03, -85.03, -87.45, -87.45, -87.45… #> $ latitude        <dbl> 50.01, 50.01, 50.01, 50.01, 52.68, 52.68, 52.68, 52.68… #> $ tz              <chr> \"America/Toronto\", \"America/Toronto\", \"America/Toronto… #> $ t2ss            <dbl> 530.1500, 516.0667, 493.4667, 455.6000, 438.7000, 551.… #> $ psel_tod        <dbl> -0.4561300, -0.4598709, -0.4920422, -0.4628636, -0.460… #> $ psel_doy        <dbl> -0.6675488, -0.6758601, -0.8021915, -0.6858336, -0.650… #> $ psel            <dbl> 0.3250817, 0.3211873, 0.2741078, 0.3170496, 0.3290624,… #> $ psel_scaled     <dbl> 0.9775970, 0.9658855, 0.8243066, 0.9534425, 0.9895679,… #> $ psel_std        <dbl> 0.9776457, 0.9659337, 0.8243477, 0.9534901, 0.9895803,… #> $ psel_normalized <dbl> 0.9307375, 0.8944490, 0.4557587, 0.8558936, 0.9678483,… #> $ geometry        <POINT [m]> POINT (152 52.23333), POINT (172 58.1), POINT (1…"},{"path":"http://arutools.github.io/ARUtools/articles/SubSample.html","id":"slice_sample","dir":"Articles","previous_headings":"Draw subsample","what":"slice_sample","title":"Subsampling recordings","text":"don’t want sample using grts() can just use dplyr::slice_sample(). Oversamples random sampling, just involves dropping recordings ’ve selected drawing .","code":"withr::with_seed(2024,{ random_sample <-    full_selection_probs |>    dplyr::slice_sample( n = 4,by = site_id,                        weight_by = psel_normalized,                       replace = F)    } ) withr::with_seed(2024,{ random_sample_stratified <-    full_selection_probs |>    left_join(sample_size,by = join_by(site_id)) |>    nest_by(site_id, N) |>    rowwise() |>    mutate(sample = list(dplyr::slice_sample(.data =data,                                       n = .data$N,                                       weight_by = psel_normalized,                       replace = F)) ) |>    dplyr::select(site_id, sample) |>    tidyr::unnest(sample)    } ) oversample <- filter(full_selection_probs,                       !path %in% random_sample$path) |>    dplyr::slice_sample( n = 2,by = site_id,                        weight_by = psel_normalized,                       replace = F)"},{"path":"http://arutools.github.io/ARUtools/articles/SubSample.html","id":"compare-methods","dir":"Articles","previous_headings":"Draw subsample","what":"Compare methods","title":"Subsampling recordings","text":"Looking draws, may notice grts results spaced , random sample, contains clumping, characteristic random sampling.","code":""},{"path":"http://arutools.github.io/ARUtools/articles/SubSample.html","id":"assigning-recording-lengths","dir":"Articles","previous_headings":"","what":"Assigning recording lengths","title":"Subsampling recordings","text":"surveys may include full recordings, others may interpret portion recordings, allowing recordings least partially interpreted. assign lengths, can repeat process sequentially assigning lengths simply just assign . however creates issue sites less length. Sampling site length creates equal sample length site.","code":"withr::with_seed(6546,{ random_sample$length <- sample(x = c(\"5min\", \"3min\", \"1min\"),                                size =  nrow(random_sample), replace = T) } ) #> # A tibble: 3 × 11 #>   length P02_1 P03_1 P04_1 P05_1 P07_1 P08_1 P09_1 P10_1 P01_1 P06_1 #>   <chr>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1 1min       1     3     1     1     3     2     1     1     0     0 #> 2 3min       1     1     1     2     0     1     3     2     3     3 #> 3 5min       2     0     2     1     1     1     0     1     1     1 withr::with_seed(569,{    sample5min <- slice_sample(random_sample,                            n=1, by = site_id, weight_by = psel_normalized)   sample3min <- slice_sample(random_sample |>                               filter(!path %in% sample5min$path),                            n=1, by = site_id, weight_by = psel_normalized)   random_sample_with_lengths <- random_sample |>    mutate(Length_group =            case_when(path %in% sample5min$path ~ \"5min\",                      path %in% sample3min$path ~ \"3min\",                      TRUE~\"1min\"            ),          length_clip = as.numeric(str_extract(Length_group, \"^\\\\d\"))*60)  }) #> # A tibble: 3 × 11 #>   Length_group P01_1 P02_1 P03_1 P04_1 P05_1 P06_1 P07_1 P08_1 P09_1 P10_1 #>   <chr>        <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1 1min             2     2     2     2     2     2     2     2     2     2 #> 2 3min             1     1     1     1     1     1     1     1     1     1 #> 3 5min             1     1     1     1     1     1     1     1     1     1"},{"path":"http://arutools.github.io/ARUtools/articles/SubSample.html","id":"assign-start-times","dir":"Articles","previous_headings":"","what":"Assign start times","title":"Subsampling recordings","text":"ARUtools includes function get_wav_length, return length ‘wav’ file seconds. can used safely add random start time recordings don’t want start zero. document assume recordings 5 minutes.","code":"random_sample_with_lengths$length_clip <-   map(1:nrow(random_sample_with_lengths),       ~get_wav_length(         file = random_sample_with_lengths$path[[.x]],          return_numeric = T)) random_sample_with_lengths$length <- 5*60 random_sample_with_lengths <-    random_sample_with_lengths |>    rowwise() |>    mutate(StartTime = case_when(Length_group == \"5min\"~0,                                  TRUE~runif(1, 0,                                           pmax(0,                                                length - length_clip)))   ) |> ungroup()"},{"path":"http://arutools.github.io/ARUtools/articles/SubSample.html","id":"format-output-filename","dir":"Articles","previous_headings":"Assign start times","what":"Format output filename","title":"Subsampling recordings","text":"Finally can format filenames Wildtrax, processes sites, dates, times based file name.","code":"final_selection <- random_sample_with_lengths |>    add_wildtrax()  final_selection |>    head() |>    dplyr::select(path, wildtrax_file_name) #> # A tibble: 6 × 2 #>   path                                         wildtrax_file_name    #>   <chr>                                        <glue>                #> 1 P01/P01_1/BARLT10962_2028-07-06T07:00:00.wav P01_1_20280706_070000 #> 2 P01/P01_1/BARLT10962_2028-06-02T07:00:00.wav P01_1_20280602_070000 #> 3 P01/P01_1/BARLT10962_2028-05-15T06:30:00.wav P01_1_20280515_063000 #> 4 P01/P01_1/BARLT10962_2028-07-04T06:30:00.wav P01_1_20280704_063000 #> # ℹ 2 more rows"},{"path":"http://arutools.github.io/ARUtools/articles/SubSample.html","id":"clip-and-copy-files-for-upload","dir":"Articles","previous_headings":"Assign start times","what":"Clip and copy files for upload","title":"Subsampling recordings","text":"format_clip_wave rename, clip copy file location can used uploading Wildtrax Setting subset folders allow copy files organized folder structure can help checking errors prior uploading. large number files, may want run separately files require clipping run much quicker files need clipped. can use option use_job=T allow use job package, launch background job copying take long time. ’s , output folder now selected files, properly named Wildtrax ready upload.","code":"out_directory <- \"/path/to/upload/directory/\" dir.create(out_directory, recursive = T) ul_tab <- expand_grid(period =c('Dawn'), # Add 'Dusk' if using more than one time period                       length = unique(selected_recordings$Length_group)) purrr::map(glue::glue(\"{out_directory}/{ul_tab$period}/{ul_tab$length}\"),             dir.create,recursive = T) log_output <-    format_clip_wave(     segment_df = final_selection,     in_base_directory = \"\",out_base_directory =  out_directory,      length_clip_col = \"length_clip\",      sub_dir_out_col = c(\"Time_period\", \"Length_group\"),      filepath_in_col = \"path\",     out_filename_col =\"wildtrax_file_name\",       use_job = F, filewarn = F)"},{"path":"http://arutools.github.io/ARUtools/articles/customizing.html","id":"regular-expressions","dir":"Articles","previous_headings":"","what":"Regular expressions","title":"Customizing `clean_metadata()`","text":"First let’s talk bit clean_metadata() extracts information. function uses regular expressions match specific text patterns file path recording. Regular expressions really powerful, also reasonably complicated can confusing. example, default, clean_metadata() matches site ids expression ((Q)|(P))(())(_|-)(()). Yikes! Broken , means look “Q” “P” (((Q)|(P))) followed two digits (\\\\d{2}) followed separator, either _ - (_|-) followed single digit (\\\\d{1}). clearly doesn’t define sites example . can supply regular expression, instead. However, sites follow reasonable pattern prefix, followed digits optionally suffix digits, might easier use helper function create regular expression . example, create site id pattern can use create_pattern_site_id(). specify prefix text well many digits might expect, separator, suffix text many suffix digits might . can useful look default patterns functions see might different data. See ?create_pattern_date create_pattern function pull documentation explore defaults well examples. can also useful test pattern running files. can use test_pattern() function see pattern successfully extracts site id first file list. Let’s continue customizing metadata patterns specifying ARU ids, dates times.","code":"m <- clean_metadata(project_files = f, pattern_site_id = \"site\\\\d{3}-(a|b)\\\\d{2}\") #> Extracting ARU info... #> Extracting Dates and Times... #> Identified possible problems with metadata extraction: #> ✖ No times were successfully detected (2/2) #> ✖ No ARU ids were successfully detected (2/2) m #> # A tibble: 2 × 8 #>   file_name   type  path  aru_type aru_id site_id date_time date       #>   <chr>       <chr> <chr> <chr>    <chr>  <chr>   <dttm>    <date>     #> 1 2020_05_04… wav   site… SongMet… NA     site10… NA        2020-05-04 #> 2 2020_05_04… wav   site… SongMet… NA     site10… NA        2020-05-04 m$site_id #> [1] \"site100-a45\" \"site102-b56\" pat_site <- create_pattern_site_id(prefix = \"site\", p_digits = 3,                                     sep = \"-\",                                     suffix = c(\"a\", \"b\"), s_digits = 2) pat_site #> [1] \"((site))((\\\\d{3}))(-)((b)|(a))((\\\\d{2}))\" m <- clean_metadata(project_files = f, pattern_site_id = pat_site) #> Extracting ARU info... #> Extracting Dates and Times... #> Identified possible problems with metadata extraction: #> ✖ No times were successfully detected (2/2) #> ✖ No ARU ids were successfully detected (2/2) m$site_id #> [1] \"site100-a45\" \"site102-b56\" test_pattern(f[1], pat_site) #> [1] \"site100-a45\" pat_aru <- create_pattern_aru_id(arus = \"s4a\", n_digits = 4)  m <- clean_metadata(project_files = f,                     pattern_site_id = pat_site,                     pattern_aru_id = pat_aru,                     pattern_dt_sep = \"_\") #> Extracting ARU info... #> Extracting Dates and Times... m #> # A tibble: 2 × 8 #>   file_name   type  path  aru_type aru_id site_id date_time           date       #>   <chr>       <chr> <chr> <chr>    <chr>  <chr>   <dttm>              <date>     #> 1 2020_05_04… wav   site… SongMet… s4a12… site10… 2020-05-04 05:25:00 2020-05-04 #> 2 2020_05_04… wav   site… SongMet… s4a11… site10… 2020-05-04 05:40:00 2020-05-04"},{"path":[]},{"path":"http://arutools.github.io/ARUtools/articles/customizing.html","id":"date-order","dir":"Articles","previous_headings":"Other options","what":"Date order","title":"Customizing `clean_metadata()`","text":"Depending date formatting, may also need specify order year, month day, addition changing pattern. Note need specify making pattern, telling function turn extracted text date. can specify one order c(\"mdy\", \"ymd\"), know multiple orders file names. particular, try avoid using mdy dmy. dates can ambiguous (example, order 05/05/2020?) may parsed correctly situations.","code":"f <- c(\"P01-1/05042020_052500_S4A1234.wav\",        \"P01-1/05042020_054000_S4A1111.wav\") clean_metadata(project_files = f,                pattern_dt_sep = \"_\",                pattern_date = create_pattern_date(order = \"mdy\"),                order_date = \"mdy\") #> Extracting ARU info... #> Extracting Dates and Times... #> # A tibble: 2 × 8 #>   file_name   type  path  aru_type aru_id site_id date_time           date       #>   <chr>       <chr> <chr> <chr>    <chr>  <chr>   <dttm>              <date>     #> 1 05042020_0… wav   P01-… SongMet… S4A12… P01-1   2020-05-04 05:25:00 2020-05-04 #> 2 05042020_0… wav   P01-… SongMet… S4A11… P01-1   2020-05-04 05:40:00 2020-05-04"},{"path":"http://arutools.github.io/ARUtools/articles/customizing.html","id":"matching-multiple-patterns","dir":"Articles","previous_headings":"Other options","what":"Matching multiple patterns","title":"Customizing `clean_metadata()`","text":"Sometimes files may use one pattern. can address problem one two ways. One option run clean_metadata() twice join outputs approach check number files end matches number expect. Another option supply multiple patterns clean_metadata() create_pattern_XXX() functions approach use depends situation. first approach means patterns matched rigid. less chance accidentally matching incorrect pattern. However, chance omitting files don’t match either pattern. second approach flexible matching patterns allows one step, convenient. However, flexible pattern , opportunities get incorrect matches date parsing. approaches, important double check results make sure ids date/times make sense.","code":"f <- c(\"P01-1/05042020_052500_S4A1234.wav\",        \"P01-1/05042020_054000_S4A1111.wav\",        \"Site10/2020-01-01T09:00:00_BARLT100.wav\",        \"Site10/2020-01-02T09:00:00_BARLT100.wav\") m1 <- clean_metadata(project_files = f,                       pattern_dt_sep = \"_\",                      pattern_date = create_pattern_date(order = \"mdy\"),                      order_date = \"mdy\") #> Extracting ARU info... #> Extracting Dates and Times... #> Identified possible problems with metadata extraction: #> ✖ Not all dates were successfully detected (2/4) #> ✖ Not all times were successfully detected (2/4) #> ✖ Not all ARU ids were successfully detected (2/4) #> ✖ Not all sites were successfully detected (2/4) m1 <- filter(m1, !is.na(date_time)) # omit ones that didn't work m1 #> # A tibble: 2 × 8 #>   file_name   type  path  aru_type aru_id site_id date_time           date       #>   <chr>       <chr> <chr> <chr>    <chr>  <chr>   <dttm>              <date>     #> 1 05042020_0… wav   P01-… SongMet… S4A12… P01-1   2020-05-04 05:25:00 2020-05-04 #> 2 05042020_0… wav   P01-… SongMet… S4A11… P01-1   2020-05-04 05:40:00 2020-05-04  m2 <- clean_metadata(   project_files = f,   pattern_site_id = create_pattern_site_id(prefix = \"Site\", s_digits = 0),   pattern_aru_id = create_pattern_aru_id(n_digits = 3)) #> Extracting ARU info... #> Extracting Dates and Times... #> Identified possible problems with metadata extraction: #> ✖ Not all dates were successfully detected (1/4) #> ✖ Not all times were successfully detected (2/4) #> ✖ Not all sites were successfully detected (2/4) m2 <- filter(m2, !is.na(date_time)) # omit ones that didn't work m2 #> # A tibble: 2 × 8 #>   file_name   type  path  aru_type aru_id site_id date_time           date       #>   <chr>       <chr> <chr> <chr>    <chr>  <chr>   <dttm>              <date>     #> 1 2020-01-01… wav   Site… BarLT    BARLT… Site10  2020-01-01 09:00:00 2020-01-01 #> 2 2020-01-02… wav   Site… BarLT    BARLT… Site10  2020-01-02 09:00:00 2020-01-02  m <- bind_rows(m1, m2) m #> # A tibble: 4 × 8 #>   file_name   type  path  aru_type aru_id site_id date_time           date       #>   <chr>       <chr> <chr> <chr>    <chr>  <chr>   <dttm>              <date>     #> 1 05042020_0… wav   P01-… SongMet… S4A12… P01-1   2020-05-04 05:25:00 2020-05-04 #> 2 05042020_0… wav   P01-… SongMet… S4A11… P01-1   2020-05-04 05:40:00 2020-05-04 #> 3 2020-01-01… wav   Site… BarLT    BARLT… Site10  2020-01-01 09:00:00 2020-01-01 #> 4 2020-01-02… wav   Site… BarLT    BARLT… Site10  2020-01-02 09:00:00 2020-01-02 nrow(m) #> [1] 4 m <- clean_metadata(project_files = f,                      pattern_dt_sep = c(\"_\", \"T\"),                     pattern_date = create_pattern_date(order = c(\"ymd\", \"mdy\")),                     order_date = c(\"ymd\", \"mdy\"),                     pattern_aru_id = create_pattern_aru_id(n_digits = c(3, 4)),                     pattern_site_id = create_pattern_site_id(prefix = c(\"P\", \"Site\"),                                                              sep = c(\"-\", \"\"),                                                              s_digits = c(1, 0))) #> Extracting ARU info... #> Extracting Dates and Times... m #> # A tibble: 4 × 8 #>   file_name   type  path  aru_type aru_id site_id date_time           date       #>   <chr>       <chr> <chr> <chr>    <chr>  <chr>   <dttm>              <date>     #> 1 05042020_0… wav   P01-… SongMet… S4A12… P01-1   2020-05-04 05:25:00 2020-05-04 #> 2 05042020_0… wav   P01-… SongMet… S4A11… P01-1   2020-05-04 05:40:00 2020-05-04 #> 3 2020-01-01… wav   Site… BarLT    BARLT… Site10  2020-01-01 09:00:00 2020-01-01 #> 4 2020-01-02… wav   Site… BarLT    BARLT… Site10  2020-01-02 09:00:00 2020-01-02 check_meta(m) #> # A tibble: 3 × 11 #>   site_id aru_type  aru_id   type  n_files n_dirs n_days min_date            #>   <chr>   <chr>     <chr>    <chr>   <int>  <int>  <int> <dttm>              #> 1 P01-1   SongMeter S4A1111  wav         1      1      1 2020-05-04 05:40:00 #> 2 P01-1   SongMeter S4A1234  wav         1      1      1 2020-05-04 05:25:00 #> 3 Site10  BarLT     BARLT100 wav         2      1      2 2020-01-01 09:00:00 #> # ℹ 3 more variables: max_date <dttm>, min_time <time>, max_time <time> check_meta(m, date = TRUE) #> # A tibble: 4 × 10 #>   site_id aru_type  aru_id   type  date       n_files n_dirs n_days min_time #>   <chr>   <chr>     <chr>    <chr> <date>       <int>  <int>  <int> <time>   #> 1 P01-1   SongMeter S4A1111  wav   2020-05-04       1      1      1 05:40    #> 2 P01-1   SongMeter S4A1234  wav   2020-05-04       1      1      1 05:25    #> 3 Site10  BarLT     BARLT100 wav   2020-01-01       1      1      1 09:00    #> 4 Site10  BarLT     BARLT100 wav   2020-01-02       1      1      1 09:00    #> # ℹ 1 more variable: max_time <time> check_problems(m) #> # A tibble: 0 × 5 #> # ℹ 5 variables: path <chr>, aru_id <chr>, site_id <chr>, date_time <dttm>, #> #   date <date>  unique(m$site_id) #> [1] \"P01-1\"  \"Site10\" unique(m$aru_id) #> [1] \"S4A1234\"  \"S4A1111\"  \"BARLT100\""},{"path":"http://arutools.github.io/ARUtools/articles/customizing.html","id":"subsetting-files","dir":"Articles","previous_headings":"Other options","what":"Subsetting files","title":"Customizing `clean_metadata()`","text":"may want extract meta data every file list directory. Possibly ’re relevant recordings, formatting issues make easier split separate groups first. can omit files using subset subset_type arguments. keep certain files, use default subset_type = \"keep\". omit certain files, use subset_type = \"omit\". keep files “” prefix (note ^ means ‘start’) omit files “” prefix","code":"clean_metadata(project_files = example_files, subset = \"^a\") #> Extracting ARU info... #> Extracting Dates and Times... #> # A tibble: 14 × 8 #>    file_name  type  path  aru_type aru_id site_id date_time           date       #>    <chr>      <chr> <chr> <chr>    <chr>  <chr>   <dttm>              <date>     #>  1 P01_1_202… wav   a_BA… BarLT    BARLT… P01_1   2020-05-02 05:00:00 2020-05-02 #>  2 P01_1_202… wav   a_BA… BarLT    BARLT… P01_1   2020-05-03 05:20:00 2020-05-03 #>  3 P03_1_202… wav   a_BA… BarLT    BARLT… P03_1   2020-05-06 10:00:00 2020-05-06 #>  4 P05_1_202… wav   a_BA… BarLT    BARLT… P05_1   2020-05-07 05:00:00 2020-05-07 #>  5 P06_1_202… wav   a_BA… BarLT    BARLT… P06_1   2020-05-09 05:20:00 2020-05-09 #>  6 P08_1_202… wav   a_BA… BarLT    BARLT… P08_1   2020-05-11 10:00:00 2020-05-11 #>  7 P04_1_202… wav   a_BA… BarLT    BARLT… P04_1   2020-05-06 05:00:00 2020-05-06 #>  8 P04_1_202… wav   a_BA… BarLT    BARLT… P04_1   2020-05-07 03:25:00 2020-05-07 #>  9 P02_1_202… wav   a_S4… SongMet… S4A01… P02_1   2020-05-04 05:25:00 2020-05-04 #> 10 P02_1_202… wav   a_S4… SongMet… S4A01… P02_1   2020-05-05 07:30:00 2020-05-05 #> 11 P07_1_202… wav   a_S4… SongMet… S4A01… P07_1   2020-05-09 05:25:00 2020-05-09 #> 12 P07_1_202… wav   a_S4… SongMet… S4A01… P07_1   2020-05-10 07:30:00 2020-05-10 #> 13 P09_1_202… wav   a_S4… SongMet… S4A02… P09_1   2020-05-11 05:00:00 2020-05-11 #> 14 P10_1_202… wav   a_S4… SongMet… S4A03… P10_1   2020-05-11 03:25:00 2020-05-11 clean_metadata(project_files = example_files, subset = \"^a\", subset_type = \"omit\") #> Extracting ARU info... #> Extracting Dates and Times... #> # A tibble: 28 × 8 #>    file_name  type  path  aru_type aru_id site_id date_time           date       #>    <chr>      <chr> <chr> <chr>    <chr>  <chr>   <dttm>              <date>     #>  1 P01_1_202… wav   j_BA… BarLT    BARLT… P01_1   2020-05-02 05:00:00 2020-05-02 #>  2 P01_1_202… wav   j_BA… BarLT    BARLT… P01_1   2020-05-03 05:20:00 2020-05-03 #>  3 P03_1_202… wav   j_BA… BarLT    BARLT… P03_1   2020-05-06 10:00:00 2020-05-06 #>  4 P05_1_202… wav   j_BA… BarLT    BARLT… P05_1   2020-05-07 05:00:00 2020-05-07 #>  5 P06_1_202… wav   j_BA… BarLT    BARLT… P06_1   2020-05-09 05:20:00 2020-05-09 #>  6 P08_1_202… wav   j_BA… BarLT    BARLT… P08_1   2020-05-11 10:00:00 2020-05-11 #>  7 P04_1_202… wav   j_BA… BarLT    BARLT… P04_1   2020-05-06 05:00:00 2020-05-06 #>  8 P04_1_202… wav   j_BA… BarLT    BARLT… P04_1   2020-05-07 03:25:00 2020-05-07 #>  9 P02_1_202… wav   j_S4… SongMet… S4A01… P02_1   2020-05-04 05:25:00 2020-05-04 #> 10 P02_1_202… wav   j_S4… SongMet… S4A01… P02_1   2020-05-05 07:30:00 2020-05-05 #> # ℹ 18 more rows"},{"path":"http://arutools.github.io/ARUtools/articles/customizing.html","id":"matching-non-wave-files","dir":"Articles","previous_headings":"Other options","what":"Matching non-wave files","title":"Customizing `clean_metadata()`","text":"default clean_metadata() looks .wav files. want match something else, adjust file_type argument. wise ’ll run problems…","code":"f <- c(\"a_BARLT10962_P01_1/P01_1_20200502T050000_ARU.mp4\",        \"a_BARLT10962_P01_1/P01_1_20200503T052000_ARU.mp4\") clean_metadata(project_files = f) #> Error in `clean_metadata()`: #> ! Did not find any 'wav' files. #> ℹ Use `file_type` to change file extension for sound files #> ℹ Check `project_dir`/`project_files` are correct clean_metadata(project_files = f, file_type = \"mp4\") #> Extracting ARU info... #> Extracting Dates and Times... #> # A tibble: 2 × 8 #>   file_name   type  path  aru_type aru_id site_id date_time           date       #>   <chr>       <chr> <chr> <chr>    <chr>  <chr>   <dttm>              <date>     #> 1 P01_1_2020… mp4   a_BA… BarLT    BARLT… P01_1   2020-05-02 05:00:00 2020-05-02 #> 2 P01_1_2020… mp4   a_BA… BarLT    BARLT… P01_1   2020-05-03 05:20:00 2020-05-03"},{"path":"http://arutools.github.io/ARUtools/articles/spatial.html","id":"problems","dir":"Articles","previous_headings":"","what":"Problems","title":"Working with spatial data","text":"However, sometimes spatial data sets might trickier use. example, sf spatial data sets missing coordinates, meaning using add_sites() function, ’ll get warning data frame back try add incomplete list sites. resolve , either add missing site information, omit files joining. Fixed!","code":"m <- clean_metadata(project_files = example_files) #> Extracting ARU info... #> Extracting Dates and Times...  sites <- st_as_sf(example_sites, coords = c(\"lon\", \"lat\"), crs = 4326) |>   clean_site_index(col_aru_id = \"ARU\",                     col_site_id = \"Sites\",                     col_date_time = c(\"Date_set_out\", \"Date_removed\")) #> There are overlapping date ranges #> • Shifting start/end times to 'noon' #> • Skip this with `resolve_overlaps = FALSE`  sites <- sites[-1, ] # Omit that first site  m <- add_sites(m, sites) #> Joining by columns `date_time_start` and `date_time_end` #> Identified possible problems with metadata extraction: #> ✖ Not all files were matched to a site reference (6/42) #> • Consider adjusting the `by` argument #> Warning: Cannot have missing coordinates in spatial data frames #> • Returning non-spatial data frame m #> # A tibble: 42 × 10 #>    file_name  type  path  aru_type aru_id site_id date_time           date       #>    <chr>      <chr> <chr> <chr>    <chr>  <chr>   <dttm>              <date>     #>  1 P01_1_202… wav   a_BA… BarLT    BARLT… P01_1   2020-05-02 05:00:00 2020-05-02 #>  2 P01_1_202… wav   a_BA… BarLT    BARLT… P01_1   2020-05-03 05:20:00 2020-05-03 #>  3 P01_1_202… wav   j_BA… BarLT    BARLT… P01_1   2020-05-02 05:00:00 2020-05-02 #>  4 P01_1_202… wav   j_BA… BarLT    BARLT… P01_1   2020-05-03 05:20:00 2020-05-03 #>  5 P01_1_202… wav   o_BA… BarLT    BARLT… P01_1   2020-05-02 05:00:00 2020-05-02 #>  6 P01_1_202… wav   o_BA… BarLT    BARLT… P01_1   2020-05-03 05:20:00 2020-05-03 #>  7 P02_1_202… wav   a_S4… SongMet… S4A01… P02_1   2020-05-04 05:25:00 2020-05-04 #>  8 P02_1_202… wav   a_S4… SongMet… S4A01… P02_1   2020-05-05 07:30:00 2020-05-05 #>  9 P02_1_202… wav   j_S4… SongMet… S4A01… P02_1   2020-05-04 05:25:00 2020-05-04 #> 10 P02_1_202… wav   j_S4… SongMet… S4A01… P02_1   2020-05-05 07:30:00 2020-05-05 #> # ℹ 32 more rows #> # ℹ 2 more variables: longitude <dbl>, latitude <dbl> m <- clean_metadata(project_files = example_files) |>   filter(date > \"2020-05-03\") # Filter out recordings that don't match a site #> Extracting ARU info... #> Extracting Dates and Times...  m <- add_sites(m, sites) #> Joining by columns `date_time_start` and `date_time_end` m #> Simple feature collection with 36 features and 8 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: -91.38 ymin: 45 xmax: -84.45 ymax: 52.68 #> Geodetic CRS:  WGS 84 #> # A tibble: 36 × 9 #>    file_name  type  path  aru_type aru_id site_id date_time           date       #>    <chr>      <chr> <chr> <chr>    <chr>  <chr>   <dttm>              <date>     #>  1 P02_1_202… wav   a_S4… SongMet… S4A01… P02_1   2020-05-04 05:25:00 2020-05-04 #>  2 P02_1_202… wav   a_S4… SongMet… S4A01… P02_1   2020-05-05 07:30:00 2020-05-05 #>  3 P02_1_202… wav   j_S4… SongMet… S4A01… P02_1   2020-05-04 05:25:00 2020-05-04 #>  4 P02_1_202… wav   j_S4… SongMet… S4A01… P02_1   2020-05-05 07:30:00 2020-05-05 #>  5 P02_1_202… wav   o_S4… SongMet… S4A01… P02_1   2020-05-04 05:25:00 2020-05-04 #>  6 P02_1_202… wav   o_S4… SongMet… S4A01… P02_1   2020-05-05 07:30:00 2020-05-05 #>  7 P03_1_202… wav   a_BA… BarLT    BARLT… P03_1   2020-05-06 10:00:00 2020-05-06 #>  8 P03_1_202… wav   j_BA… BarLT    BARLT… P03_1   2020-05-06 10:00:00 2020-05-06 #>  9 P03_1_202… wav   o_BA… BarLT    BARLT… P03_1   2020-05-06 10:00:00 2020-05-06 #> 10 P04_1_202… wav   a_BA… BarLT    BARLT… P04_1   2020-05-06 05:00:00 2020-05-06 #> # ℹ 26 more rows #> # ℹ 1 more variable: geometry <POINT [°]>"},{"path":"http://arutools.github.io/ARUtools/articles/timezones.html","id":"what-timezone-are-my-data-in","dir":"Articles","previous_headings":"","what":"What timezone are my data in?","title":"Dealing with Timezones","text":"ask R timezone data , R say “UTC” ’s probably really case. three possible options timezones might look like: times timezone programmed ARUs set . likely either timezone region deployed, timezone lab home base (doesn’t really matter , long ’re know one ). several different timezones among recordings, correspond deployed. likely happen ARUs set use GPS get timezone study area straddled timezone boundary. several different timezones among recordings, correspond deployed. might happen timezones set ARUs different projects corrected deployment. ARUtools, options deal withe first two scenarios. However, find third scenario, best thing split files timezone run workflow individually batch.","code":"tz(m$date_time) #> [1] \"UTC\""},{"path":"http://arutools.github.io/ARUtools/articles/timezones.html","id":"calculating-time-to-sunrisesunset","dir":"Articles","previous_headings":"","what":"Calculating time to sunrise/sunset","title":"Dealing with Timezones","text":"simplicity, don’t need worry ‘real’ timezone except calculate time sunrise/sunset. ’s important know timezone patterns data. first scenario, know recordings timezone know timezone . can specify timezone specifically: Alternatively, second scenario, know timezones may different, importantly, correspond location unit deployed. can use aru_tz = \"local\" calc_sun() use recording coordinates figure timezone . Finally, final scenario, know timezones , correspond location unit deployed. case ’ll split data use specific timezones. Let’s assume know timezones sites P06_1 P09_1 Central, rest Eastern. actually use timezone sites located , compare m_joint m_local ’ll see exception timezone called results (“America/Detroit” timezone “America/Toronto”). ’ll also note Eastern timezone (America/Toronto America/Detroit), match m_est.","code":"m_est <- calc_sun(m, aru_tz = \"America/Toronto\") m_local <- calc_sun(m, aru_tz = \"local\") # Split by timezone m1 <- filter(m, site_id %in% c(\"P06_1\", \"P09_1\"))  # Get P06_1 and P09_1 m2 <- filter(m, !site_id %in% c(\"P06_1\", \"P09_1\")) # Get all except the above  # Calculate time to sunrise/sunset individually  m1_cst <- calc_sun(m1, aru_tz = \"America/Winnipeg\") m2_est <- calc_sun(m2, aru_tz = \"America/Toronto\")  # Join them back in m_joint <- bind_rows(m1_cst, m2_est)"},{"path":"http://arutools.github.io/ARUtools/articles/timezones.html","id":"important-things-to-note","dir":"Articles","previous_headings":"","what":"Important things to note","title":"Dealing with Timezones","text":"timezone recordings, must site index, won’t join properly add_sites() Unless know timezones match deployment location, must know timezone recordings made . calc_sun() returns relative time sunrise sunset, ’s important know timezone recording , ’s important timezone matches ’s deployment area.","code":""},{"path":"http://arutools.github.io/ARUtools/articles/timezones.html","id":"an-example","dir":"Articles","previous_headings":"","what":"An example","title":"Dealing with Timezones","text":"Let’s assume two sites, one Eastern timezone, one Western. However, programmed record 4am, 5am 6am Eastern. ’ll first use example data create mini meta data set. now calculate time sunrise/sunset (t2sr t2ss) find difference sites 15min, accounting fact site P06_1 farther west P01_1 recording 6am occurs 28.8min sunrise, whereas P01_1’s 6am recording occurs 14.9 min sunrise. However, incorrectly assume ARU unit central timezone recording timezone, get different results. times sunrise/sunset site P06_1 offset hour, ’re assuming wrong timezone (hour different correct one). Therefore take home need two things: make sure timezones match recordings site index know timezones (least can derived coordinates).","code":"m_mini <- filter(m, site_id %in% c(\"P01_1\", \"P06_1\")) |>   select(aru_id, site_id, longitude, latitude) |>   distinct() |>   cross_join(data.frame(date_time = c(\"2020-05-02 05:00:00\",                                        \"2020-05-02 06:00:00\",                                       \"2020-05-02 07:00:00\"))) |>   mutate(date = as_date(date_time)) calc_sun(m_mini, aru_tz = \"America/Toronto\") #> # A tibble: 6 × 9 #>   aru_id   site_id longitude latitude date_time           date       tz     t2sr #>   <chr>    <chr>       <dbl>    <dbl> <dttm>              <date>     <chr> <dbl> #> 1 BARLT10… P01_1       -85.0     50.0 2020-05-02 05:00:00 2020-05-02 Amer… -74.9 #> 2 BARLT10… P01_1       -85.0     50.0 2020-05-02 06:00:00 2020-05-02 Amer… -14.9 #> 3 BARLT10… P01_1       -85.0     50.0 2020-05-02 07:00:00 2020-05-02 Amer…  45.1 #> 4 BARLT10… P06_1       -90.1     52   2020-05-02 05:00:00 2020-05-02 Amer… -88.8 #> 5 BARLT10… P06_1       -90.1     52   2020-05-02 06:00:00 2020-05-02 Amer… -28.8 #> 6 BARLT10… P06_1       -90.1     52   2020-05-02 07:00:00 2020-05-02 Amer…  31.2 #> # ℹ 1 more variable: t2ss <dbl> calc_sun(m_mini, aru_tz = \"local\") #> # A tibble: 6 × 9 #>   aru_id   site_id longitude latitude date_time           date       tz     t2sr #>   <chr>    <chr>       <dbl>    <dbl> <dttm>              <date>     <chr> <dbl> #> 1 BARLT10… P01_1       -85.0     50.0 2020-05-02 05:00:00 2020-05-02 Amer… -74.9 #> 2 BARLT10… P01_1       -85.0     50.0 2020-05-02 06:00:00 2020-05-02 Amer… -14.9 #> 3 BARLT10… P01_1       -85.0     50.0 2020-05-02 07:00:00 2020-05-02 Amer…  45.1 #> 4 BARLT10… P06_1       -90.1     52   2020-05-02 05:00:00 2020-05-02 Amer… -28.8 #> 5 BARLT10… P06_1       -90.1     52   2020-05-02 06:00:00 2020-05-02 Amer…  31.2 #> 6 BARLT10… P06_1       -90.1     52   2020-05-02 07:00:00 2020-05-02 Amer…  91.2 #> # ℹ 1 more variable: t2ss <dbl>"},{"path":"http://arutools.github.io/ARUtools/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"David Hope. Author, maintainer. Steffi LaZerte. Author.","code":""},{"path":"http://arutools.github.io/ARUtools/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Hope, David Steffi LaZerte. ARUtools: package ARU data. www.github.com/arutools/ARUtools","code":"@Manual{,   title = {ARUtools: a package for ARU data},   author = {David Hope and Steffi LaZerte},   year = {2023},   url = {www.github.com/arutools/ARUtools}, }"},{"path":"http://arutools.github.io/ARUtools/index.html","id":"arutools-","dir":"","previous_headings":"","what":"Tools for management of Acoustic Recording Unit (ARU) data","title":"Tools for management of Acoustic Recording Unit (ARU) data","text":"goal ARUtools facilitate processing ARU data subsampling recordings. remains development version now. means user function names variable names may change versions functions may become defunct.","code":""},{"path":"http://arutools.github.io/ARUtools/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Tools for management of Acoustic Recording Unit (ARU) data","text":"can install current version ARUtools R-universe repository. Alternatively can install package GitHub code . need Rtools installed first:","code":"install.packages(\"ARUtools\",                  repos = c(\"https://arutools.r-universe.dev\",                            \"https://cran.r-project.org\") ) # install.packages(\"pak\") # Uncomment if you don't have remotes installed. pak::pak(\"arutools/ARUtools\")"},{"path":"http://arutools.github.io/ARUtools/index.html","id":"learn-to-use","dir":"","previous_headings":"","what":"Learn to use","title":"Tools for management of Acoustic Recording Unit (ARU) data","text":"easiest way dig using ARUtools package using documentation webpage currently six vignettes help get running cleaning ARU metadata Getting started ARUtools (vignette(\"ARUtools\")) Customizing clean_metadata() (vignette(\"customizing\")) Dealing timezones (vignette(\"timezones\")) Working spatial data (vignette(\"spatial\")) Subsampling recordings (vignette(\"SubSample\")) useful functions (vignette(\"Misc\") )","code":""},{"path":"http://arutools.github.io/ARUtools/index.html","id":"provide-feedback","dir":"","previous_headings":"","what":"Provide feedback","title":"Tools for management of Acoustic Recording Unit (ARU) data","text":"run problems ideas extensions, please don’t hesitate submit issue.","code":""},{"path":"http://arutools.github.io/ARUtools/index.html","id":"motivation-and-limitations","dir":"","previous_headings":"","what":"Motivation and limitations","title":"Tools for management of Acoustic Recording Unit (ARU) data","text":"package initially started life series scripts process recordings multiple large projects around monitoring migratory bird populations Ontario’s North. Moving scripts package stemmed following wise advice Hadley Wickham: good rule thumb consider writing function whenever ’ve copied pasted block code twice (.e. now three copies code). multiple projects, data issues, became clear either require copy/pasting lot code likely break something developing series functions shared across projects (.e. package). initial version code usable , ’re using package, fantastic work Steffi LaZerte translated mess user-friendly functions see today. However, due variable nature data management, possible ARUtools may work well project. run issues, please submit issue. also good packages may use : wildRtrax (R)  warbleR (R) emu (command line) SoX (command line) Sound-Extraction (python)","code":""},{"path":"http://arutools.github.io/ARUtools/reference/ARUtools.html","id":null,"dir":"Reference","previous_headings":"","what":"ARUtools: CWS Ontario Tools for working with ARU files — ARUtools","title":"ARUtools: CWS Ontario Tools for working with ARU files — ARUtools","text":"ARU tools might find useful working ARU files.","code":""},{"path":[]},{"path":"http://arutools.github.io/ARUtools/reference/ARUtools.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"ARUtools: CWS Ontario Tools for working with ARU files — ARUtools","text":"Maintainer: David Hope david.hope@ec.gc.ca (ORCID) Authors: Steffi LaZerte sel@steffilazerte.ca (ORCID)","code":""},{"path":"http://arutools.github.io/ARUtools/reference/add_sites.html","id":null,"dir":"Reference","previous_headings":"","what":"Add site-level data to the metadata — add_sites","title":"Add site-level data to the metadata — add_sites","text":"Uses dates join site-level data (coordinates site ids) meta data. site data single dates, buffer used determine recordings belong site observation. Can join site ids alone set `by_date = NULL`.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/add_sites.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add site-level data to the metadata — add_sites","text":"","code":"add_sites(   meta,   sites,   buffer_before = 0,   buffer_after = NULL,   by = c(\"site_id\", \"aru_id\"),   by_date = \"date_time\",   quiet = FALSE )"},{"path":"http://arutools.github.io/ARUtools/reference/add_sites.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add site-level data to the metadata — add_sites","text":"meta Data frame. Recording metadata. Output `clean_metadata()`. sites Data frame. Site-level data `clean_site_index()`. buffer_before Numeric. Number hours deployment include recordings. `NULL` means include time last deployment. Coupled `buffer_after`, creates window around date/time join recordings site-level data. Ignored `sites` start end column date/times. Default 0. buffer_after Numeric. Number hours deployment include recordings. `NULL` means include time next deployment. Coupled `buffer_before`, creates window around date/time join recordings site-level data. Ignored `sites` start end column date/times. Default `NULL`. Character. Columns identify deployment `sites` well `meta`, besides date/time, used join data. Default `site_id` `aru_id`. by_date Character. Date/time type join data . `date` faster `date_time` precise. Default `date_time`. `NULL` means ignore dates join `` columns (`dplyr::left_join()`). quiet Logical. Whether suppress progress messages non-essential updates.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/add_sites.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add site-level data to the metadata — add_sites","text":"data frame metadata site-level data joined .","code":""},{"path":"http://arutools.github.io/ARUtools/reference/add_sites.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add site-level data to the metadata — add_sites","text":"","code":"m <- clean_metadata(project_files = example_files) #> Extracting ARU info... #> Extracting Dates and Times... s <- clean_site_index(example_sites_clean,                       col_date = c(\"date_time_start\", \"date_time_end\")) m <- add_sites(m, s) #> Joining by columns `date_time_start` and `date_time_end`  # Without dates (by site only) m <- clean_metadata(project_files = example_files) #> Extracting ARU info... #> Extracting Dates and Times... eg <- dplyr::select(example_sites_clean, -date_time_start, -date_time_end) s <- clean_site_index(eg, col_date_time = NULL) m <- add_sites(m, s, by_date = NULL) #> Ignoring dates - Joining with `by` columns only (`by_date == NULL`)"},{"path":"http://arutools.github.io/ARUtools/reference/add_wildtrax.html","id":null,"dir":"Reference","previous_headings":"","what":"Add Wildtrax file name to metadata — add_wildtrax","title":"Add Wildtrax file name to metadata — add_wildtrax","text":"Create append file name appropriate uploading data Wildtrax system.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/add_wildtrax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add Wildtrax file name to metadata — add_wildtrax","text":"","code":"add_wildtrax(meta)"},{"path":"http://arutools.github.io/ARUtools/reference/add_wildtrax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add Wildtrax file name to metadata — add_wildtrax","text":"meta Data frame. Recording metadata. Output `clean_metadata()`.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/add_wildtrax.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add Wildtrax file name to metadata — add_wildtrax","text":"Data frame metadata appended column wildtrax appropriate   file names.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/add_wildtrax.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add Wildtrax file name to metadata — add_wildtrax","text":"","code":"m <- clean_metadata(project_files = example_files) #> Extracting ARU info... #> Extracting Dates and Times... m <- add_wildtrax(m) m #> # A tibble: 42 × 9 #>    file_name  type  path  aru_type aru_id site_id date_time           date       #>    <chr>      <chr> <chr> <chr>    <chr>  <chr>   <dttm>              <date>     #>  1 P01_1_202… wav   a_BA… BarLT    BARLT… P01_1   2020-05-02 05:00:00 2020-05-02 #>  2 P01_1_202… wav   a_BA… BarLT    BARLT… P01_1   2020-05-03 05:20:00 2020-05-03 #>  3 P03_1_202… wav   a_BA… BarLT    BARLT… P03_1   2020-05-06 10:00:00 2020-05-06 #>  4 P05_1_202… wav   a_BA… BarLT    BARLT… P05_1   2020-05-07 05:00:00 2020-05-07 #>  5 P06_1_202… wav   a_BA… BarLT    BARLT… P06_1   2020-05-09 05:20:00 2020-05-09 #>  6 P08_1_202… wav   a_BA… BarLT    BARLT… P08_1   2020-05-11 10:00:00 2020-05-11 #>  7 P04_1_202… wav   a_BA… BarLT    BARLT… P04_1   2020-05-06 05:00:00 2020-05-06 #>  8 P04_1_202… wav   a_BA… BarLT    BARLT… P04_1   2020-05-07 03:25:00 2020-05-07 #>  9 P02_1_202… wav   a_S4… SongMet… S4A01… P02_1   2020-05-04 05:25:00 2020-05-04 #> 10 P02_1_202… wav   a_S4… SongMet… S4A01… P02_1   2020-05-05 07:30:00 2020-05-05 #> # ℹ 32 more rows #> # ℹ 1 more variable: wildtrax_file_name <glue>"},{"path":"http://arutools.github.io/ARUtools/reference/calc_sel_pr.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Inclusion Probabilities — calc_sel_pr","title":"Calculate Inclusion Probabilities — calc_sel_pr","text":"Calculate Inclusion Probabilities","code":""},{"path":"http://arutools.github.io/ARUtools/reference/calc_sel_pr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Inclusion Probabilities — calc_sel_pr","text":"","code":"calc_sel_pr(   .data,   ARU_ID_col,   min_col,   day_col,   parms = list(min_range = c(-60, 300), doy_range = c(150, 180), mean_min = 30, sd_min =     30, mean_doy = 0, sd_doy = 10, off = 0, log_ = FALSE, fun = \"norm\") )"},{"path":"http://arutools.github.io/ARUtools/reference/calc_sel_pr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Inclusion Probabilities — calc_sel_pr","text":".data Data frame Date, times, ARU IDs ARU_ID_col ARU id column. quoted. min_col Minutes column. quoted. day_col Day column. quoted. parms list parameters. See defaults examples.  include min_range, doy_range, mean_min, sd_min, mean_doy, sd_doy, , log_, fun.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/calc_sel_pr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Inclusion Probabilities — calc_sel_pr","text":"Returns .data selection probability columns","code":""},{"path":"http://arutools.github.io/ARUtools/reference/calc_sun.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate time to sunrise/sunset — calc_sun","title":"Calculate time to sunrise/sunset — calc_sun","text":"Calculate sunrise/sunset sound file day , day day get nearest sunrise recording.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/calc_sun.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate time to sunrise/sunset — calc_sun","text":"","code":"calc_sun(meta_sites, aru_tz = \"local\")"},{"path":"http://arutools.github.io/ARUtools/reference/calc_sun.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate time to sunrise/sunset — calc_sun","text":"meta_sites (Spatial) Data frame. Recording metadata added coordinates. Output `clean_metadata()` `add_sites()` (either `clean_gps()` `clean_site_index()`). aru_tz Character. Must either \"local\" timezone listed `OlsonNames()`. See Details.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/calc_sun.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate time to sunrise/sunset — calc_sun","text":"Data frame metadata added timezone recording time (`tz`),  time sunrise/sunset (`t2sr`, `t2ss`).","code":""},{"path":"http://arutools.github.io/ARUtools/reference/calc_sun.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate time to sunrise/sunset — calc_sun","text":"Timezones. ensure sunrise/sunset times calculated   correctly relative time recording, need know   timezone date/time recording. ARUs calibrated   specific timezone going field, can specified   using, example, `aru_tz = \"America/Toronto\"`. hand   ARU calibrated whichever timezone local deployed use   `aru_tz = \"local\"`. specific timezone calculated individually   based longitude latitude recording.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/calc_sun.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate time to sunrise/sunset — calc_sun","text":"","code":"m <- clean_metadata(project_files = example_files) #> Extracting ARU info... #> Extracting Dates and Times... s <- clean_site_index(example_sites_clean,                       col_date = c(\"date_time_start\", \"date_time_end\")) m <- add_sites(m, s) #> Joining by columns `date_time_start` and `date_time_end` m <- calc_sun(m)"},{"path":"http://arutools.github.io/ARUtools/reference/check_file.html","id":null,"dir":"Reference","previous_headings":"","what":"Explore a file — check_file","title":"Explore a file — check_file","text":"Shows first lines text file. Useful trying understand problems GPS files.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/check_file.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Explore a file — check_file","text":"","code":"check_file(file_name, n_max = 10, ...)"},{"path":"http://arutools.github.io/ARUtools/reference/check_file.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Explore a file — check_file","text":"file_name Character. File path check. n_max Numeric. Number lines file show. Default 10. ... Arguments passed `readr::read_lines()`","code":""},{"path":"http://arutools.github.io/ARUtools/reference/check_file.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Explore a file — check_file","text":"Wrapper around `readr::read_lines(n_max)`.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/check_meta.html","id":null,"dir":"Reference","previous_headings":"","what":"Check output of `clean_metadata()` — check_meta","title":"Check output of `clean_metadata()` — check_meta","text":"Cleaning metadata can take series tries. function helps summarize explore metadata possible patterns may help find problems.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/check_meta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check output of `clean_metadata()` — check_meta","text":"","code":"check_meta(meta, date = FALSE)"},{"path":"http://arutools.github.io/ARUtools/reference/check_meta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check output of `clean_metadata()` — check_meta","text":"meta Data frame. Recording metadata. Output `clean_metadata()`. date Logical. Whether summarize output date (well `site_id` `aru_id`. Default `FALSE`.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/check_meta.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check output of `clean_metadata()` — check_meta","text":"data frame summarizing metadata site_id, aru_type, aru_id, (optionally) date. Presents number files, directories, days worth recordings, well minimum maximum recording times.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/check_meta.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check output of `clean_metadata()` — check_meta","text":"","code":"m <- clean_metadata(project_files = example_files) #> Extracting ARU info... #> Extracting Dates and Times...  check_meta(m) #> # A tibble: 10 × 11 #>    site_id aru_type  aru_id     type  n_files n_dirs n_days min_date            #>    <chr>   <chr>     <chr>      <chr>   <int>  <int>  <int> <dttm>              #>  1 P01_1   BarLT     BARLT10962 wav         6      3      2 2020-05-02 05:00:00 #>  2 P02_1   SongMeter S4A01234   wav         6      3      2 2020-05-04 05:25:00 #>  3 P03_1   BarLT     BARLT10962 wav         3      3      1 2020-05-06 10:00:00 #>  4 P04_1   BarLT     BARLT11111 wav         6      3      2 2020-05-06 05:00:00 #>  5 P05_1   BarLT     BARLT10962 wav         3      3      1 2020-05-07 05:00:00 #>  6 P06_1   BarLT     BARLT10962 wav         3      3      1 2020-05-09 05:20:00 #>  7 P07_1   SongMeter S4A01234   wav         6      3      2 2020-05-09 05:25:00 #>  8 P08_1   BarLT     BARLT10962 wav         3      3      1 2020-05-11 10:00:00 #>  9 P09_1   SongMeter S4A02222   wav         3      3      1 2020-05-11 05:00:00 #> 10 P10_1   SongMeter S4A03333   wav         3      3      1 2020-05-11 03:25:00 #> # ℹ 3 more variables: max_date <dttm>, min_time <time>, max_time <time> check_meta(m, date = TRUE) #> # A tibble: 14 × 10 #>    site_id aru_type  aru_id     type  date       n_files n_dirs n_days min_time #>    <chr>   <chr>     <chr>      <chr> <date>       <int>  <int>  <int> <time>   #>  1 P01_1   BarLT     BARLT10962 wav   2020-05-02       3      3      1 05:00    #>  2 P01_1   BarLT     BARLT10962 wav   2020-05-03       3      3      1 05:20    #>  3 P02_1   SongMeter S4A01234   wav   2020-05-04       3      3      1 05:25    #>  4 P02_1   SongMeter S4A01234   wav   2020-05-05       3      3      1 07:30    #>  5 P03_1   BarLT     BARLT10962 wav   2020-05-06       3      3      1 10:00    #>  6 P04_1   BarLT     BARLT11111 wav   2020-05-06       3      3      1 05:00    #>  7 P04_1   BarLT     BARLT11111 wav   2020-05-07       3      3      1 03:25    #>  8 P05_1   BarLT     BARLT10962 wav   2020-05-07       3      3      1 05:00    #>  9 P06_1   BarLT     BARLT10962 wav   2020-05-09       3      3      1 05:20    #> 10 P07_1   SongMeter S4A01234   wav   2020-05-09       3      3      1 05:25    #> 11 P07_1   SongMeter S4A01234   wav   2020-05-10       3      3      1 07:30    #> 12 P08_1   BarLT     BARLT10962 wav   2020-05-11       3      3      1 10:00    #> 13 P09_1   SongMeter S4A02222   wav   2020-05-11       3      3      1 05:00    #> 14 P10_1   SongMeter S4A03333   wav   2020-05-11       3      3      1 03:25    #> # ℹ 1 more variable: max_time <time>"},{"path":"http://arutools.github.io/ARUtools/reference/check_problems.html","id":null,"dir":"Reference","previous_headings":"","what":"Check problems in output of `clean_metadata()` — check_problems","title":"Check problems in output of `clean_metadata()` — check_problems","text":"Cleaning metadata can take series tries. function helps summarize explore missing metadata (problems).","code":""},{"path":"http://arutools.github.io/ARUtools/reference/check_problems.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check problems in output of `clean_metadata()` — check_problems","text":"","code":"check_problems(   df,   check = c(\"site_id\", \"aru_id\", \"date\", \"date_time\", \"longitude\", \"latitude\"),   path = FALSE,   date = FALSE )"},{"path":"http://arutools.github.io/ARUtools/reference/check_problems.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check problems in output of `clean_metadata()` — check_problems","text":"df Data frame. Either meta data (`clean_metadata()`) GPS coordinates (`clean_gps()`) check Character. Character vector columns check missing values. Default `site_id`, `aru_id`, `date`, `date_time`, `longitude` `latitude`. path Logical. Whether return just file paths missing attributes. Default `FALSE` date Logical. Whether summarize output date (well `site_id` `aru_id`. Default `FALSE`.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/check_problems.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check problems in output of `clean_metadata()` — check_problems","text":"data frame summarizing metadata site_id, aru_type, aru_id, (optionally) date. Presents number files, directories, days worth recordings, well minimum maximum recording times.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/check_problems.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check problems in output of `clean_metadata()` — check_problems","text":"","code":"m <- clean_metadata(project_files = example_files, pattern_aru_id = \"test\") #> Extracting ARU info... #> Extracting Dates and Times... #> Identified possible problems with metadata extraction: #> ✖ No ARU ids were successfully detected (42/42)  check_problems(m) #> # A tibble: 42 × 5 #>    path                            aru_id site_id date_time           date       #>    <chr>                           <chr>  <chr>   <dttm>              <date>     #>  1 a_BARLT10962_P01_1/P01_1_20200… NA     P01_1   2020-05-02 05:00:00 2020-05-02 #>  2 a_BARLT10962_P01_1/P01_1_20200… NA     P01_1   2020-05-03 05:20:00 2020-05-03 #>  3 a_BARLT10962_P03_1/P03_1_20200… NA     P03_1   2020-05-06 10:00:00 2020-05-06 #>  4 a_BARLT10962_P05_1/P05_1_20200… NA     P05_1   2020-05-07 05:00:00 2020-05-07 #>  5 a_BARLT10962_P06_1/P06_1_20200… NA     P06_1   2020-05-09 05:20:00 2020-05-09 #>  6 a_BARLT10962_P08_1/P08_1_20200… NA     P08_1   2020-05-11 10:00:00 2020-05-11 #>  7 a_BARLT11111_P04_1/P04_1_20200… NA     P04_1   2020-05-06 05:00:00 2020-05-06 #>  8 a_BARLT11111_P04_1/P04_1_20200… NA     P04_1   2020-05-07 03:25:00 2020-05-07 #>  9 a_S4A01234_P02_1/P02_1_2020050… NA     P02_1   2020-05-04 05:25:00 2020-05-04 #> 10 a_S4A01234_P02_1/P02_1_2020050… NA     P02_1   2020-05-05 07:30:00 2020-05-05 #> # ℹ 32 more rows check_problems(m, date = TRUE) #> # A tibble: 14 × 7 #>    site_id aru_id date       date_time_min       date_time_max       date_time_n #>    <chr>   <chr>  <date>     <dttm>              <dttm>                    <int> #>  1 P01_1   NA     2020-05-02 2020-05-02 05:00:00 2020-05-02 05:00:00           3 #>  2 P01_1   NA     2020-05-03 2020-05-03 05:20:00 2020-05-03 05:20:00           3 #>  3 P02_1   NA     2020-05-04 2020-05-04 05:25:00 2020-05-04 05:25:00           3 #>  4 P02_1   NA     2020-05-05 2020-05-05 07:30:00 2020-05-05 07:30:00           3 #>  5 P03_1   NA     2020-05-06 2020-05-06 10:00:00 2020-05-06 10:00:00           3 #>  6 P04_1   NA     2020-05-06 2020-05-06 05:00:00 2020-05-06 05:00:00           3 #>  7 P04_1   NA     2020-05-07 2020-05-07 03:25:00 2020-05-07 03:25:00           3 #>  8 P05_1   NA     2020-05-07 2020-05-07 05:00:00 2020-05-07 05:00:00           3 #>  9 P06_1   NA     2020-05-09 2020-05-09 05:20:00 2020-05-09 05:20:00           3 #> 10 P07_1   NA     2020-05-09 2020-05-09 05:25:00 2020-05-09 05:25:00           3 #> 11 P07_1   NA     2020-05-10 2020-05-10 07:30:00 2020-05-10 07:30:00           3 #> 12 P08_1   NA     2020-05-11 2020-05-11 10:00:00 2020-05-11 10:00:00           3 #> 13 P09_1   NA     2020-05-11 2020-05-11 05:00:00 2020-05-11 05:00:00           3 #> 14 P10_1   NA     2020-05-11 2020-05-11 03:25:00 2020-05-11 03:25:00           3 #> # ℹ 1 more variable: date_time_n_na <int> check_problems(m, path = TRUE) #>  [1] \"a_BARLT10962_P01_1/P01_1_20200502T050000_ARU.wav\" #>  [2] \"a_BARLT10962_P01_1/P01_1_20200503T052000_ARU.wav\" #>  [3] \"a_BARLT10962_P03_1/P03_1_20200506T100000_ARU.wav\" #>  [4] \"a_BARLT10962_P05_1/P05_1_20200507T050000_ARU.wav\" #>  [5] \"a_BARLT10962_P06_1/P06_1_20200509T052000_ARU.wav\" #>  [6] \"a_BARLT10962_P08_1/P08_1_20200511T100000_ARU.wav\" #>  [7] \"a_BARLT11111_P04_1/P04_1_20200506T050000_ARU.wav\" #>  [8] \"a_BARLT11111_P04_1/P04_1_20200507T032500_ARU.wav\" #>  [9] \"a_S4A01234_P02_1/P02_1_20200504T052500_ARU.wav\"   #> [10] \"a_S4A01234_P02_1/P02_1_20200505T073000_ARU.wav\"   #> [11] \"a_S4A01234_P07_1/P07_1_20200509T052500_ARU.wav\"   #> [12] \"a_S4A01234_P07_1/P07_1_20200510T073000_ARU.wav\"   #> [13] \"a_S4A02222_P09_1/P09_1_20200511T050000_ARU.wav\"   #> [14] \"a_S4A03333_P10_1/P10_1_20200511T032500_ARU.wav\"   #> [15] \"j_BARLT10962_P01_1/P01_1_20200502T050000_ARU.wav\" #> [16] \"j_BARLT10962_P01_1/P01_1_20200503T052000_ARU.wav\" #> [17] \"j_BARLT10962_P03_1/P03_1_20200506T100000_ARU.wav\" #> [18] \"j_BARLT10962_P05_1/P05_1_20200507T050000_ARU.wav\" #> [19] \"j_BARLT10962_P06_1/P06_1_20200509T052000_ARU.wav\" #> [20] \"j_BARLT10962_P08_1/P08_1_20200511T100000_ARU.wav\" #> [21] \"j_BARLT11111_P04_1/P04_1_20200506T050000_ARU.wav\" #> [22] \"j_BARLT11111_P04_1/P04_1_20200507T032500_ARU.wav\" #> [23] \"j_S4A01234_P02_1/P02_1_20200504T052500_ARU.wav\"   #> [24] \"j_S4A01234_P02_1/P02_1_20200505T073000_ARU.wav\"   #> [25] \"j_S4A01234_P07_1/P07_1_20200509T052500_ARU.wav\"   #> [26] \"j_S4A01234_P07_1/P07_1_20200510T073000_ARU.wav\"   #> [27] \"j_S4A02222_P09_1/P09_1_20200511T050000_ARU.wav\"   #> [28] \"j_S4A03333_P10_1/P10_1_20200511T032500_ARU.wav\"   #> [29] \"o_BARLT10962_P01_1/P01_1_20200502T050000_ARU.wav\" #> [30] \"o_BARLT10962_P01_1/P01_1_20200503T052000_ARU.wav\" #> [31] \"o_BARLT10962_P03_1/P03_1_20200506T100000_ARU.wav\" #> [32] \"o_BARLT10962_P05_1/P05_1_20200507T050000_ARU.wav\" #> [33] \"o_BARLT10962_P06_1/P06_1_20200509T052000_ARU.wav\" #> [34] \"o_BARLT10962_P08_1/P08_1_20200511T100000_ARU.wav\" #> [35] \"o_BARLT11111_P04_1/P04_1_20200506T050000_ARU.wav\" #> [36] \"o_BARLT11111_P04_1/P04_1_20200507T032500_ARU.wav\" #> [37] \"o_S4A01234_P02_1/P02_1_20200504T052500_ARU.wav\"   #> [38] \"o_S4A01234_P02_1/P02_1_20200505T073000_ARU.wav\"   #> [39] \"o_S4A01234_P07_1/P07_1_20200509T052500_ARU.wav\"   #> [40] \"o_S4A01234_P07_1/P07_1_20200510T073000_ARU.wav\"   #> [41] \"o_S4A02222_P09_1/P09_1_20200511T050000_ARU.wav\"   #> [42] \"o_S4A03333_P10_1/P10_1_20200511T032500_ARU.wav\""},{"path":"http://arutools.github.io/ARUtools/reference/clean_gps.html","id":null,"dir":"Reference","previous_headings":"","what":"Check and clean GPS data — clean_gps","title":"Check and clean GPS data — clean_gps","text":"Check clean GPS data ARU logs. GPS points checked obvious problems (expected range, distance cutoffs timing) attached meta data frame. Note often safer reliable create Site Index file including site ids, GPS coordinates. file can cleaned prepared `clean_site_index()` instead.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/clean_gps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check and clean GPS data — clean_gps","text":"","code":"clean_gps(   meta = NULL,   dist_cutoff = 100,   dist_crs = 3161,   dist_by = c(\"site_id\", \"aru_id\"),   quiet = FALSE,   verbose = FALSE )"},{"path":"http://arutools.github.io/ARUtools/reference/clean_gps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check and clean GPS data — clean_gps","text":"meta Data frame. Output `clean_metadata()`. dist_cutoff Numeric. Maximum distance (m) GPS points within site. Default 100m can set `Inf` skip. dist_crs Numeric. Coordinate Reference System use calculating distance (one m). dist_by Character. Column identifies sites within compare distance among GPS points. valid `dist_cutoff` `Inf`. quiet Logical. Whether suppress progress messages non-essential updates. verbose Logical. Show extra loading information. Default `FALSE`.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/clean_gps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check and clean GPS data — clean_gps","text":"Data frame site-level metadata.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/clean_gps.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check and clean GPS data — clean_gps","text":"checking maximum distance (`dist_cutoff`) among GPS points within group (`dist_by`), returned data frame include column `max_dist`, represents largest distance among points within group.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/clean_gps.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check and clean GPS data — clean_gps","text":"","code":"if (FALSE) {   m <- clean_metadata(project_dir = \"my_project\")   g <- clean_gps(meta = m) }"},{"path":"http://arutools.github.io/ARUtools/reference/clean_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract and clean ARU metadata from file names — clean_metadata","title":"Extract and clean ARU metadata from file names — clean_metadata","text":"Using regular expressions, metadata extracted file names directory structure, checked cleaned.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/clean_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract and clean ARU metadata from file names — clean_metadata","text":"","code":"clean_metadata(   project_dir = NULL,   project_files = NULL,   file_type = \"wav\",   subset = NULL,   subset_type = \"keep\",   pattern_site_id = create_pattern_site_id(),   pattern_aru_id = create_pattern_aru_id(),   pattern_date = create_pattern_date(),   pattern_time = create_pattern_time(),   pattern_dt_sep = create_pattern_dt_sep(),   order_date = \"ymd\",   quiet = FALSE )"},{"path":"http://arutools.github.io/ARUtools/reference/clean_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract and clean ARU metadata from file names — clean_metadata","text":"project_dir Character. Directory project files stored. File paths used extract information must actually exist. project_files Character. Vector project file paths. paths can absolute relative working directory, actually need point existing files unless plan use `clean_gps()` sampling steps line. Must provided `project_dir` `NULL`. file_type Character. Type file (extension) summarize. Default wav. subset Character. Text pattern mark subset files/directories either `keep` `omit` (see `subset_type`) subset_type Character. Either `keep` (default) `omit` files/directories match pattern `subset`. pattern_site_id Character. Regular expression extract site ids. See `create_pattern_site_id()`. Can vector multiple patterns match. pattern_aru_id Character. Regular expression extract ARU ids. See `create_pattern_aru_id()`. Can vector multiple patterns match. pattern_date Character. Regular expression extract dates. See `create_pattern_date()`. Can vector multiple patterns match. pattern_time Character. Regular expression extract times. See `create_pattern_time()`. Can vector multiple patterns match. pattern_dt_sep Character. Regular expression mark separators dates times. See `create_pattern_dt_sep()`. order_date Character. Order date appears . \"ymd\" (default), \"mdy\", \"dmy\". Can vector multiple patterns match. quiet Logical. Whether suppress progress messages non-essential updates.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/clean_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract and clean ARU metadata from file names — clean_metadata","text":"Data frame extracted metadata","code":""},{"path":"http://arutools.github.io/ARUtools/reference/clean_metadata.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract and clean ARU metadata from file names — clean_metadata","text":"Note times extracted first combining date, date/time separator time patterns. means problem combination, dates might extracted date/times . mismatch can used determine part pattern needs tweaked. See `vignette(\"customizing\", package = \"ARUtools\")` details customizing `clean_metadata()` project.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/clean_metadata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract and clean ARU metadata from file names — clean_metadata","text":"","code":"clean_metadata(project_files = example_files) #> Extracting ARU info... #> Extracting Dates and Times... #> # A tibble: 42 × 8 #>    file_name  type  path  aru_type aru_id site_id date_time           date       #>    <chr>      <chr> <chr> <chr>    <chr>  <chr>   <dttm>              <date>     #>  1 P01_1_202… wav   a_BA… BarLT    BARLT… P01_1   2020-05-02 05:00:00 2020-05-02 #>  2 P01_1_202… wav   a_BA… BarLT    BARLT… P01_1   2020-05-03 05:20:00 2020-05-03 #>  3 P03_1_202… wav   a_BA… BarLT    BARLT… P03_1   2020-05-06 10:00:00 2020-05-06 #>  4 P05_1_202… wav   a_BA… BarLT    BARLT… P05_1   2020-05-07 05:00:00 2020-05-07 #>  5 P06_1_202… wav   a_BA… BarLT    BARLT… P06_1   2020-05-09 05:20:00 2020-05-09 #>  6 P08_1_202… wav   a_BA… BarLT    BARLT… P08_1   2020-05-11 10:00:00 2020-05-11 #>  7 P04_1_202… wav   a_BA… BarLT    BARLT… P04_1   2020-05-06 05:00:00 2020-05-06 #>  8 P04_1_202… wav   a_BA… BarLT    BARLT… P04_1   2020-05-07 03:25:00 2020-05-07 #>  9 P02_1_202… wav   a_S4… SongMet… S4A01… P02_1   2020-05-04 05:25:00 2020-05-04 #> 10 P02_1_202… wav   a_S4… SongMet… S4A01… P02_1   2020-05-05 07:30:00 2020-05-05 #> # ℹ 32 more rows clean_metadata(project_files = example_files, subset = \"P02\") #> Extracting ARU info... #> Extracting Dates and Times... #> # A tibble: 6 × 8 #>   file_name   type  path  aru_type aru_id site_id date_time           date       #>   <chr>       <chr> <chr> <chr>    <chr>  <chr>   <dttm>              <date>     #> 1 P02_1_2020… wav   a_S4… SongMet… S4A01… P02_1   2020-05-04 05:25:00 2020-05-04 #> 2 P02_1_2020… wav   a_S4… SongMet… S4A01… P02_1   2020-05-05 07:30:00 2020-05-05 #> 3 P02_1_2020… wav   j_S4… SongMet… S4A01… P02_1   2020-05-04 05:25:00 2020-05-04 #> 4 P02_1_2020… wav   j_S4… SongMet… S4A01… P02_1   2020-05-05 07:30:00 2020-05-05 #> 5 P02_1_2020… wav   o_S4… SongMet… S4A01… P02_1   2020-05-04 05:25:00 2020-05-04 #> 6 P02_1_2020… wav   o_S4… SongMet… S4A01… P02_1   2020-05-05 07:30:00 2020-05-05"},{"path":"http://arutools.github.io/ARUtools/reference/clean_site_index.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare and clean site index file — clean_site_index","title":"Prepare and clean site index file — clean_site_index","text":"site index file contains information specific ARUs deployed . function cleans file (csv, xlsx) data frame preparation adding details output `clean_metadata()`. can used specify missing information according date, GPS lon/lats site ids.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/clean_site_index.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare and clean site index file — clean_site_index","text":"","code":"clean_site_index(   site_index,   col_aru_id = \"aru_id\",   col_site_id = \"site_id\",   col_date_time = \"date\",   col_coords = c(\"longitude\", \"latitude\"),   col_extra = NULL,   resolve_overlaps = TRUE,   quiet = FALSE )"},{"path":"http://arutools.github.io/ARUtools/reference/clean_site_index.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare and clean site index file — clean_site_index","text":"site_index Data frame (can spatial) file path. Site index data clean. file path, must local csv xlsx file. col_aru_id Character. Column name contains ARU ids. Default `aru_id`. col_site_id Character. Column name contains site ids. col_date_time Character. Column name contains dates date/times. Can vector two names 'start' 'end' columns. Can `NULL` ignore dates. col_coords Character. Column names contain longitude latitude (order). Ignored `site_index` spatial. col_extra Character. Column names extra data include. named vector, rename columns (see examples). resolve_overlaps Logical. Whether resolve date overlaps shifting start/end dates noon (default `TRUE`). assumes ARUs generally ** deployed/removed midnight (official start/end day) noon used approximation ARU deployed removed. possible, use specific deployment times avoid issue. quiet Logical. Whether suppress progress messages non-essential updates.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/clean_site_index.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare and clean site index file — clean_site_index","text":"Standardized site index data frame","code":""},{"path":"http://arutools.github.io/ARUtools/reference/clean_site_index.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Prepare and clean site index file — clean_site_index","text":"Note times assumed 'local' time timezone used (removed present, replaced UTC). allows sites different timezones processed time.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/clean_site_index.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prepare and clean site index file — clean_site_index","text":"","code":"s <- clean_site_index(example_sites,                       col_aru_id = \"ARU\",                       col_site_id = \"Sites\",                       col_date_time = c(\"Date_set_out\", \"Date_removed\"),                       col_coords = c(\"lon\", \"lat\")) #> There are overlapping date ranges #> • Shifting start/end times to 'noon' #> • Skip this with `resolve_overlaps = FALSE`  s <- clean_site_index(example_sites,                       col_aru_id = \"ARU\",                       col_site_id = \"Sites\",                       col_date_time = c(\"Date_set_out\", \"Date_removed\"),                       col_coords = c(\"lon\", \"lat\"),                       col_extra = c(\"plot\" = \"Plots\")) #> There are overlapping date ranges #> • Shifting start/end times to 'noon' #> • Skip this with `resolve_overlaps = FALSE`  # Without dates eg <- dplyr::select(example_sites, -Date_set_out, -Date_removed) s <- clean_site_index(eg,                       col_aru_id = \"ARU\",                       col_site_id = \"Sites\",                       col_date_time = NULL,                       col_coords = c(\"lon\", \"lat\"),                       col_extra = c(\"plot\" = \"Plots\"))"},{"path":"http://arutools.github.io/ARUtools/reference/common_docs.html","id":null,"dir":"Reference","previous_headings":"","what":"Common arguments and documentation for various functions — common_docs","title":"Common arguments and documentation for various functions — common_docs","text":"Common arguments documentation various functions","code":""},{"path":"http://arutools.github.io/ARUtools/reference/common_docs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Common arguments and documentation for various functions — common_docs","text":"project_dir Character. Directory project files stored. File paths used extract information must actually exist. project_files Character. Vector project file paths. paths can absolute relative working directory, actually need point existing files unless plan use `clean_gps()` sampling steps line. Must provided `project_dir` `NULL`. subset Character. Text pattern mark subset files/directories either `keep` `omit` (see `subset_type`) subset_type Character. Either `keep` (default) `omit` files/directories match pattern `subset`. meta Data frame. Recording metadata. Output `clean_metadata()`. meta_sites (Spatial) Data frame. Recording metadata added coordinates. Output `clean_metadata()` `add_sites()` (either `clean_gps()` `clean_site_index()`). date Logical. Whether summarize output date (well `site_id` `aru_id`. Default `FALSE`. quiet Logical. Whether suppress progress messages non-essential updates.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/common_docs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Common arguments and documentation for various functions — common_docs","text":"Use `@inheritParams common_docs` include function documentation matching argument (include matching args)","code":""},{"path":"http://arutools.github.io/ARUtools/reference/count_files.html","id":null,"dir":"Reference","previous_headings":"","what":"Count files in a project directory — count_files","title":"Count files in a project directory — count_files","text":"Helper function explore number files directory, recursively.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/count_files.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Count files in a project directory — count_files","text":"","code":"count_files(project_dir, subset = NULL, subset_type = \"keep\")"},{"path":"http://arutools.github.io/ARUtools/reference/count_files.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Count files in a project directory — count_files","text":"project_dir Character. Directory project files stored. File paths used extract information must actually exist. subset Character. Text pattern mark subset files/directories either `keep` `omit` (see `subset_type`) subset_type Character. Either `keep` (default) `omit` files/directories match pattern `subset`.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/create_directory_structure.html","id":null,"dir":"Reference","previous_headings":"","what":"Create directory structure for ARU folders — create_directory_structure","title":"Create directory structure for ARU folders — create_directory_structure","text":"Create directory structure ARU folders","code":""},{"path":"http://arutools.github.io/ARUtools/reference/create_directory_structure.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create directory structure for ARU folders — create_directory_structure","text":"","code":"create_directory_structure(hexagons, units, base_dir)"},{"path":"http://arutools.github.io/ARUtools/reference/create_directory_structure.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create directory structure for ARU folders — create_directory_structure","text":"hexagons Character vector hexagons clusters units Character vector ARU unit ids. include hexagon name base_dir Base directory build directory structure .","code":""},{"path":"http://arutools.github.io/ARUtools/reference/create_directory_structure.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create directory structure for ARU folders — create_directory_structure","text":"return anything run. cancelled returns string notification.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/create_pattern.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a pattern to match date — create_pattern","title":"Create a pattern to match date — create_pattern","text":"Helper functions create regular expression patterns match different metadata file paths.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/create_pattern.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a pattern to match date — create_pattern","text":"","code":"create_pattern_date(order = \"ymd\", sep = c(\"_\", \"-\", \"\"), yr_digits = 4)  create_pattern_time(sep = c(\"_\", \"-\", \":\", \"\"), seconds = \"yes\")  create_pattern_dt_sep(sep = \"T\", optional = FALSE)  create_pattern_aru_id(   arus = c(\"BARLT\", \"S\\\\d(A|U)\", \"SM\\\\d\", \"SMM\", \"SMA\"),   n_digits = c(4, 8),   sep = c(\"_\", \"-\", \"\"),   prefix = \"\",   suffix = \"\" )  create_pattern_site_id(   prefix = c(\"P\", \"Q\"),   p_digits = 2,   sep = c(\"_\", \"-\"),   suffix = \"\",   s_digits = 1 )  test_pattern(test, pattern)"},{"path":"http://arutools.github.io/ARUtools/reference/create_pattern.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a pattern to match date — create_pattern","text":"order Character vector. Expected orders (y)ear, (m)onth (d)ate. Default \"ymd\" Year-Month-Date order. Can one possible order. sep Character vector. Expected separator(s) pattern parts. Can \"\" separator. yr_digits Numeric vector. Number digits Year, either 2 4. seconds Character. Whether seconds included. Options \"yes\", \"\", \"maybe\". optional Logical. Whether separator optional . Allows matching different date/time patterns. arus Character vector. Pattern(s) identifying ARU prefix (usually model specific). n_digits Numeric vector. Number digits expected follow `arus` pattern. Can one two (range). prefix Character vector. Prefix(es) site ids. suffix Character vector. Suffix(es) site ids. p_digits Numeric vector. Number(s) digits following `prefix`. s_digits Numeric vector. Number(s) digits following `suffix`. test Character vector. Examples text test. pattern Character. Regular expression pattern test.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/create_pattern.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a pattern to match date — create_pattern","text":"Either pattern (`create_pattern_xxx()`) text extracted   pattern (`test_pattern()`)","code":""},{"path":"http://arutools.github.io/ARUtools/reference/create_pattern.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a pattern to match date — create_pattern","text":"default `create_pattern_aru_id()` matches many common ARU patterns like `BARLT0000`, `S4A0000`, `SM40000`, `SMM0000`, `SMA0000`. `test_pattern()` helper function see regular expression pattern pick example text. Can used see pattern grabs want. just simple wrapper around `stringr::str_extract()`.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/create_pattern.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Create a pattern to match date — create_pattern","text":"create_pattern_date(): Create pattern match date create_pattern_time(): Create pattern match time create_pattern_dt_sep(): Create pattern match date/time separator create_pattern_aru_id(): Create pattern match ARU id create_pattern_site_id(): Create pattern match site id test_pattern(): Test patterns","code":""},{"path":"http://arutools.github.io/ARUtools/reference/create_pattern.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a pattern to match date — create_pattern","text":"","code":"create_pattern_date()  # Default matches 2020-01-01 or 2020_01_01 or 20200101 #> [1] \"((((([12]{1}\\\\d{3})))(_|-|)(\\\\d{2})(_|-|)(\\\\d{2})))\"                        # (\"-\", \"_\" or \"\" as separators) create_pattern_date(sep = \"\") # Matches only 20200101 (no separator allowed) #> [1] \"((((([12]{1}\\\\d{3})))(\\\\d{2})(\\\\d{2})))\"  create_pattern_time()  # Default matches 23_59_59 (_, -, :, as optional separators) #> [1] \"([0-2]{1}[0-9]{1})(_|-|:|)([0-5]{1}[0-9]{1})((_|-|:|)([0-5]{1}[0-9]{1}))\" create_pattern_time(sep = \"\", seconds = \"no\") # Matches 2359 (no seconds no separators) #> [1] \"([0-2]{1}[0-9]{1})([0-5]{1}[0-9]{1})\"  create_pattern_dt_sep()  # Default matches 'T' as a required separator #> [1] \"(T)\" create_pattern_dt_sep(optional = TRUE) # 'T' as an optional separator #> [1] \"(T)?\" create_pattern_dt_sep(c(\"T\", \"_\", \"-\")) # 'T', '_', or '-' as separators #> [1] \"(T|_|-)\"  create_pattern_aru_id() #> [1] \"((BARLT)|(S\\\\d(A|U))|(SM\\\\d)|(SMM)|(SMA))(_|-|)\\\\d{4,8}\" create_pattern_aru_id(prefix = \"CWS\") #> [1] \"((CWS))((BARLT)|(S\\\\d(A|U))|(SM\\\\d)|(SMM)|(SMA))(_|-|)\\\\d{4,8}\" create_pattern_aru_id(n_digits = 12) #> [1] \"((BARLT)|(S\\\\d(A|U))|(SM\\\\d)|(SMM)|(SMA))(_|-|)\\\\d{12}\"   create_pattern_site_id() # Default matches P00-0 #> [1] \"((Q)|(P))((\\\\d{2}))(_|-)((\\\\d{1}))\" create_pattern_site_id(prefix = \"site\", p_digits = 3, sep = \"\",                        suffix = c(\"a\", \"b\", \"c\"), s_digits = 0) # Matches site000a #> [1] \"((site))((\\\\d{3}))((c)|(b)|(a))\"  pat <- create_pattern_aru_id(prefix = \"CWS\") test_pattern(\"CWS_BARLT1012\", pat)            # No luck #> [1] NA pat <- create_pattern_aru_id(prefix = \"CWS_\") test_pattern(\"CWS_BARLT1012\", pat)            # Ah ha! #> [1] \"CWS_BARLT1012\" pat <- create_pattern_site_id()  pat <- create_pattern_site_id() test_pattern(\"P03\", pat)   # Nope #> [1] NA test_pattern(\"P03-1\", pat) # Success! #> [1] \"P03-1\"  pat <- create_pattern_site_id(prefix = \"site\", p_digits = 3, sep = \"\", s_digits = 0) test_pattern(\"site111\", pat) #> [1] \"site111\" pat <- create_pattern_site_id(prefix = \"site\", p_digits = 3, sep = \"\",                              suffix = c(\"a\", \"b\", \"c\"), s_digits = 0) test_pattern(c(\"site9\", \"site100a\"), pat) #> [1] NA         \"site100a\""},{"path":"http://arutools.github.io/ARUtools/reference/default_selection_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Default parameters for use in `gen_dens_sel_simulation` and `calc_sel_pr` — default_selection_parameters","title":"Default parameters for use in `gen_dens_sel_simulation` and `calc_sel_pr` — default_selection_parameters","text":"generated list defaults use selection parameters selecting ARU recordings time day day year. See gen_dens_sel_simulation calc_sel_pr examples use.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/default_selection_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Default parameters for use in `gen_dens_sel_simulation` and `calc_sel_pr` — default_selection_parameters","text":"","code":"default_selection_parameters"},{"path":"http://arutools.github.io/ARUtools/reference/default_selection_parameters.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Default parameters for use in `gen_dens_sel_simulation` and `calc_sel_pr` — default_selection_parameters","text":"## `default_selection_parameters` list 9 objects: min_range Range minutes relative sun event doy_range Range day year mean_min Average minutes sun event selection sd_min Standard deviation distribution selection distrution minutes sun event mean_doy Average day year selection sd_doy Standard deviation day year selection Offset shift time day. log_ Log density selection function? fun Selection function. Options 'lognorm','norm', 'cauchy'.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/default_selection_parameters.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Default parameters for use in `gen_dens_sel_simulation` and `calc_sel_pr` — default_selection_parameters","text":"data-raw/default_selection_parameters.R","code":""},{"path":"http://arutools.github.io/ARUtools/reference/example_clean.html","id":null,"dir":"Reference","previous_headings":"","what":"Example cleaned recording meta data — example_clean","title":"Example cleaned recording meta data — example_clean","text":"data frame examples correctly formatted metadata added site-level information data frame tasks generated `example_clean` using wildRtrax::wt_make_aru_tasks() function","code":""},{"path":"http://arutools.github.io/ARUtools/reference/example_clean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example cleaned recording meta data — example_clean","text":"","code":"example_clean  example_clean"},{"path":"http://arutools.github.io/ARUtools/reference/example_clean.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example cleaned recording meta data — example_clean","text":"## `example_clean` data frame 42 rows 10 columns: file_name Name file type File type path Relative file path including file name aru_type ARU model aru_id ARU ids site_id Site ids date_time Recording date/time date Recording date longitude Latitude decimal degrees latitude Longitude decimal degrees ## `task_template` data frame 14 rows 13 columns: location Site location name recording_date_time Date time recording method Method interpretation (generally '1SPT') taskLength Length recording seconds transcriber Transcriber ID, filled function rain Empty character filling WildTrax wind Empty character filling WildTrax industryNoise Empty character filling WildTrax audioQuality Empty character filling WildTrax taskComments Empty character filling WildTrax internal_task_id Empty character filling WildTrax","code":""},{"path":"http://arutools.github.io/ARUtools/reference/example_clean.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example cleaned recording meta data — example_clean","text":"data-raw/data_test.R data-raw/task_template.R","code":""},{"path":"http://arutools.github.io/ARUtools/reference/example_files.html","id":null,"dir":"Reference","previous_headings":"","what":"Example recording files — example_files","title":"Example recording files — example_files","text":"vector examples ARU recording files.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/example_files.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example recording files — example_files","text":"","code":"example_files"},{"path":"http://arutools.github.io/ARUtools/reference/example_files.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example recording files — example_files","text":"## `example_files` vector 42 file paths","code":""},{"path":"http://arutools.github.io/ARUtools/reference/example_files.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example recording files — example_files","text":"data-raw/data_test.R","code":""},{"path":"http://arutools.github.io/ARUtools/reference/example_sites.html","id":null,"dir":"Reference","previous_headings":"","what":"Example site-level meta data — example_sites","title":"Example site-level meta data — example_sites","text":"data frame examples incorrectly formatted site-level data.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/example_sites.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example site-level meta data — example_sites","text":"","code":"example_sites"},{"path":"http://arutools.github.io/ARUtools/reference/example_sites.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example site-level meta data — example_sites","text":"## `example_sites` data frame 10 rows 8 columns: Sites Site ids Date_set_out Deployment start date Date_removed Deployment end date ARU ARU ids lon Longitude decimal degrees lat Latitude decimal degrees Plots Hypothetical extra plot column Subplot Hypothetical extra subplot column","code":""},{"path":"http://arutools.github.io/ARUtools/reference/example_sites.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example site-level meta data — example_sites","text":"data-raw/data_test.R","code":""},{"path":"http://arutools.github.io/ARUtools/reference/example_sites_clean.html","id":null,"dir":"Reference","previous_headings":"","what":"Example cleaned site-level meta data — example_sites_clean","title":"Example cleaned site-level meta data — example_sites_clean","text":"data frame examples correctly formatted site-level data.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/example_sites_clean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example cleaned site-level meta data — example_sites_clean","text":"","code":"example_sites_clean"},{"path":"http://arutools.github.io/ARUtools/reference/example_sites_clean.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example cleaned site-level meta data — example_sites_clean","text":"## `example_sites_clean` data frame 10 rows 8 columns: site_id Site ids aru_id ARU ids date_time_start Deployment start date/time date_time_end Deployment end date/time date_start Deployment start date date_end Deployment end date longitude Latitude decimal degrees latitude Longitude decimal degrees","code":""},{"path":"http://arutools.github.io/ARUtools/reference/example_sites_clean.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example cleaned site-level meta data — example_sites_clean","text":"data-raw/data_test.R","code":""},{"path":"http://arutools.github.io/ARUtools/reference/format_clip_wave.html","id":null,"dir":"Reference","previous_headings":"","what":"Process multiple wav files by copying them with a new filename or clipping\nto a given length. — format_clip_wave","title":"Process multiple wav files by copying them with a new filename or clipping\nto a given length. — format_clip_wave","text":"Process multiple wav files copying new filename clipping given length.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/format_clip_wave.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process multiple wav files by copying them with a new filename or clipping\nto a given length. — format_clip_wave","text":"","code":"format_clip_wave(   segment_df,   in_base_directory,   out_base_directory,   length_clip_col,   sub_dir_out_col,   filepath_in_col,   out_filename_col,   filewarn = T,   use_job = F,   ... )"},{"path":"http://arutools.github.io/ARUtools/reference/format_clip_wave.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process multiple wav files by copying them with a new filename or clipping\nto a given length. — format_clip_wave","text":"segment_df Data frame details file locations. in_base_directory String. Directory wav files read . out_base_directory String. Directory output files length_clip_col String column name length clip seconds sub_dir_out_col String vector strings column name directories output , nested out_base_directory filepath_in_col String column name path file, either nested base directory absolute out_filename_col String column name output filename filewarn Logical. Default TRUE. function provide warnings file movements use_job Logical. Default FALSE. Use job package copy files.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/format_clip_wave.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process multiple wav files by copying them with a new filename or clipping\nto a given length. — format_clip_wave","text":"logical logical vector status file copy.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/format_clip_wave_single.html","id":null,"dir":"Reference","previous_headings":"","what":"Clip single wave file to length from given start time in recording — format_clip_wave_single","title":"Clip single wave file to length from given start time in recording — format_clip_wave_single","text":"Clip single wave file length given start time recording","code":""},{"path":"http://arutools.github.io/ARUtools/reference/format_clip_wave_single.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clip single wave file to length from given start time in recording — format_clip_wave_single","text":"","code":"format_clip_wave_single(   in_file,   out_file,   length_clip,   StartTime,   warn = T,   l = NULL )"},{"path":"http://arutools.github.io/ARUtools/reference/format_clip_wave_single.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clip single wave file to length from given start time in recording — format_clip_wave_single","text":"l","code":""},{"path":"http://arutools.github.io/ARUtools/reference/fun_aru_samp.html","id":null,"dir":"Reference","previous_headings":"","what":"Run the model function — fun_aru_samp","title":"Run the model function — fun_aru_samp","text":"Run model function","code":""},{"path":"http://arutools.github.io/ARUtools/reference/fun_aru_samp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run the model function — fun_aru_samp","text":"","code":"fun_aru_samp(df, N, os, seed, strat_, selprob_id, x, y, ...)"},{"path":"http://arutools.github.io/ARUtools/reference/fun_aru_samp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run the model function — fun_aru_samp","text":"df Data frame use ARU information selection probabilities N Number samples per stratum os Oversample proportion seed random number seed strat_ Stratum ID. column grts runs selprob_id Selection probability column x Column df x (using doy) y Column df y -time day time sunrise/sunset","code":""},{"path":"http://arutools.github.io/ARUtools/reference/fun_aru_samp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run the model function — fun_aru_samp","text":"sampling run grts","code":""},{"path":"http://arutools.github.io/ARUtools/reference/gen_dens_sel_simulation.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate selection probabilities for GRTS — gen_dens_sel_simulation","title":"Simulate selection probabilities for GRTS — gen_dens_sel_simulation","text":"Simulate selection probabilities GRTS","code":""},{"path":"http://arutools.github.io/ARUtools/reference/gen_dens_sel_simulation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate selection probabilities for GRTS — gen_dens_sel_simulation","text":"","code":"gen_dens_sel_simulation(   parms = ARUtools::default_selection_parameters,   selection_variable = psel_normalized,   return_dat = F,   ... )"},{"path":"http://arutools.github.io/ARUtools/reference/gen_dens_sel_simulation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate selection probabilities for GRTS — gen_dens_sel_simulation","text":"parms List parameters simulation see ?ARUtools::default_selection_parameters names default values selection_variable unquoted variable name options psel, psel_doy, psel_tod, psel_std, psel_scaled, psel_normalized. Default psel_normalized return_dat Logical - return just data print basic plot","code":""},{"path":"http://arutools.github.io/ARUtools/reference/gen_dens_sel_simulation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate selection probabilities for GRTS — gen_dens_sel_simulation","text":"Returns either data frame selection probabilities plots selection probabiliies.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/gen_dens_sel_simulation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate selection probabilities for GRTS — gen_dens_sel_simulation","text":"","code":"# gen_dens_sel_simulation(min =  -70:240,doy = 121:201, #               parms = ARUtools::default_selection_parameters, #             selection_variable = psel_normalized , return_dat=F)"},{"path":"http://arutools.github.io/ARUtools/reference/get_file_info.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the file info from a recording — get_file_info","title":"Get the file info from a recording — get_file_info","text":"Get file info recording","code":""},{"path":"http://arutools.github.io/ARUtools/reference/get_file_info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the file info from a recording — get_file_info","text":"","code":"get_file_info(file, use_exifr = FALSE)"},{"path":"http://arutools.github.io/ARUtools/reference/get_file_info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the file info from a recording — get_file_info","text":"file Path  file use_exfir Logical use exifr package, slower, returns information allows use flac files.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/get_file_info.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the file info from a recording — get_file_info","text":"tibble file information. use_exifr creates data, takes longer.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/get_file_info.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the file info from a recording — get_file_info","text":"","code":"f <- tempfile() wav <- download.file(\"https://www2.cs.uic.edu/~i101/SoundFiles/StarWars3.wav\", destfile = f) get_file_info(f) #> # A tibble: 1 × 6 #>   sample.rate channels  bits samples path                       duration_seconds #>         <int>    <int> <int>   <dbl> <chr>                                 <dbl> #> 1       22050        1    16   66150 /tmp/RtmppuvqtH/file1f8e7…                3 get_file_info(f, use_exifr = TRUE) #> Warning: File /tmp/RtmppuvqtH/file1f8e7b4e2f15 failed to load. #> # A tibble: 1 × 1 #>   path                             #>   <chr>                            #> 1 /tmp/RtmppuvqtH/file1f8e7b4e2f15"},{"path":"http://arutools.github.io/ARUtools/reference/get_wav_length.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the length of a recording in seconds — get_wav_length","title":"Get the length of a recording in seconds — get_wav_length","text":"Get length recording seconds","code":""},{"path":"http://arutools.github.io/ARUtools/reference/get_wav_length.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the length of a recording in seconds — get_wav_length","text":"","code":"get_wav_length(file, return_numeric = F)"},{"path":"http://arutools.github.io/ARUtools/reference/get_wav_length.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the length of a recording in seconds — get_wav_length","text":"file Path wave file","code":""},{"path":"http://arutools.github.io/ARUtools/reference/get_wav_length.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the length of a recording in seconds — get_wav_length","text":"length recording seconds","code":""},{"path":"http://arutools.github.io/ARUtools/reference/get_wav_length.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the length of a recording in seconds — get_wav_length","text":"","code":"f <- tempfile() wav <- download.file(\"https://www2.cs.uic.edu/~i101/SoundFiles/StarWars3.wav\", destfile = f) get_wav_length(f) #> 3 seconds"},{"path":"http://arutools.github.io/ARUtools/reference/getvals.html","id":null,"dir":"Reference","previous_headings":"","what":"Get accoustic complexity values — getvals","title":"Get accoustic complexity values — getvals","text":"Wrapper soundecology package","code":""},{"path":"http://arutools.github.io/ARUtools/reference/getvals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get accoustic complexity values — getvals","text":"","code":"getvals(filename, fl, mf = NA, maxf = NA, units_ = \"samples\")"},{"path":"http://arutools.github.io/ARUtools/reference/getvals.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get accoustic complexity values — getvals","text":"filename File name fl file location mf minimum frequency complexity maxf max freqency complexity units_ Units tuneR read wave file. Defaults \"samples\"","code":""},{"path":"http://arutools.github.io/ARUtools/reference/getvals.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get accoustic complexity values — getvals","text":"Returns data frame accoustic indices.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/play_random_track.html","id":null,"dir":"Reference","previous_headings":"","what":"Play random track — play_random_track","title":"Play random track — play_random_track","text":"play random track wave file given folder.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/play_random_track.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Play random track — play_random_track","text":"","code":"play_random_track(base_folder, file_list = NULL, random_seed = NULL)"},{"path":"http://arutools.github.io/ARUtools/reference/play_random_track.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Play random track — play_random_track","text":"base_folder Base folder path search . file_list Vector strings file locations. null, search manually. relative base_folder","code":""},{"path":"http://arutools.github.io/ARUtools/reference/play_random_track.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Play random track — play_random_track","text":"return anything. open media player","code":""},{"path":"http://arutools.github.io/ARUtools/reference/prep_for_wind_detection.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare files for WindNoiseDetection — prep_for_wind_detection","title":"Prepare files for WindNoiseDetection — prep_for_wind_detection","text":"function prepares set files can used fork WindNoiseDetection found https://github.com/dhope/WindNoiseDetection","code":""},{"path":"http://arutools.github.io/ARUtools/reference/prep_for_wind_detection.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare files for WindNoiseDetection — prep_for_wind_detection","text":"","code":"prep_for_wind_detection(   wav_files,   site_pattern,   output_directory,   write_to_file = FALSE,   chunk_size = NULL )"},{"path":"http://arutools.github.io/ARUtools/reference/prep_for_wind_detection.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare files for WindNoiseDetection — prep_for_wind_detection","text":"wav_files Vector path wav files site_pattern Pattern extract sites file names output_directory Directory path export files write_to_file Logical function write files output_directory chunk_size Numeric NULL, sets number files include chunk","code":""},{"path":"http://arutools.github.io/ARUtools/reference/prep_for_wind_detection.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare files for WindNoiseDetection — prep_for_wind_detection","text":"List vectors sites, filenames, filePaths","code":""},{"path":"http://arutools.github.io/ARUtools/reference/process_gps_SM.html","id":null,"dir":"Reference","previous_headings":"","what":"Process GPS locations for SongMeters — process_gps_SM","title":"Process GPS locations for SongMeters — process_gps_SM","text":"Process GPS locations SongMeters","code":""},{"path":"http://arutools.github.io/ARUtools/reference/process_gps_SM.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process GPS locations for SongMeters — process_gps_SM","text":"","code":"process_gps_SM(folder_base, list_files, site_pattern)"},{"path":"http://arutools.github.io/ARUtools/reference/process_gps_SM.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process GPS locations for SongMeters — process_gps_SM","text":"folder_base Base folder summary folders locationed list_files List files folder_base site_pattern site pattern separate siteid","code":""},{"path":"http://arutools.github.io/ARUtools/reference/process_gps_SM.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process GPS locations for SongMeters — process_gps_SM","text":"Returns data frame lon/lat location date collected","code":""},{"path":"http://arutools.github.io/ARUtools/reference/process_gps_barlt.html","id":null,"dir":"Reference","previous_headings":"","what":"Process GPS log file for BarLT — process_gps_barlt","title":"Process GPS log file for BarLT — process_gps_barlt","text":"Extracts lat/lon locations gps log files   drop locations given date,   drop duplicate locations","code":""},{"path":"http://arutools.github.io/ARUtools/reference/process_gps_barlt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process GPS log file for BarLT — process_gps_barlt","text":"","code":"process_gps_barlt(   base_folder,   file_list,   deploy_start_date,   check_dists,   site_pattern,   ... )"},{"path":"http://arutools.github.io/ARUtools/reference/process_gps_barlt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process GPS log file for BarLT — process_gps_barlt","text":"base_folder base_folder files stored file_list file list relative base_folder deploy_start_date first date deployment","code":""},{"path":"http://arutools.github.io/ARUtools/reference/process_gps_barlt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process GPS log file for BarLT — process_gps_barlt","text":"Returns data frame lat/lon location date collected","code":""},{"path":"http://arutools.github.io/ARUtools/reference/process_log_SM.html","id":null,"dir":"Reference","previous_headings":"","what":"Process log files from SongMeters — process_log_SM","title":"Process log files from SongMeters — process_log_SM","text":"Process log files SongMeters","code":""},{"path":"http://arutools.github.io/ARUtools/reference/process_log_SM.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process log files from SongMeters — process_log_SM","text":"","code":"process_log_SM(folder_base, list_files, site_pattern, return_gps, return_log)"},{"path":"http://arutools.github.io/ARUtools/reference/process_log_SM.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process log files from SongMeters — process_log_SM","text":"folder_base Base folder summary folders locationed list_files List files folder_base site_pattern site pattern separate siteid return_gps Logical. function return GPS locations? return_log Logical. function return full log?","code":""},{"path":"http://arutools.github.io/ARUtools/reference/process_log_SM.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process log files from SongMeters — process_log_SM","text":"Returns data frame lon/lat location date collected","code":""},{"path":"http://arutools.github.io/ARUtools/reference/read_and_check_barlt_gps.html","id":null,"dir":"Reference","previous_headings":"","what":"Read barlt gps and check locations — read_and_check_barlt_gps","title":"Read barlt gps and check locations — read_and_check_barlt_gps","text":"Read barlt gps check locations","code":""},{"path":"http://arutools.github.io/ARUtools/reference/read_and_check_barlt_gps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read barlt gps and check locations — read_and_check_barlt_gps","text":"","code":"read_and_check_barlt_gps(.x, return_all_locs = F)"},{"path":"http://arutools.github.io/ARUtools/reference/read_and_check_barlt_gps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read barlt gps and check locations — read_and_check_barlt_gps","text":".x Path gps file barLT return_all_locs logical. Return gps locations file. Default false","code":""},{"path":"http://arutools.github.io/ARUtools/reference/read_and_check_barlt_gps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read barlt gps and check locations — read_and_check_barlt_gps","text":"Returns paths chosen user","code":""},{"path":"http://arutools.github.io/ARUtools/reference/read_log_barlt.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse the log file for BarLT — read_log_barlt","title":"Parse the log file for BarLT — read_log_barlt","text":"Returns serial number, firware version log file parsed tibble.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/read_log_barlt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse the log file for BarLT — read_log_barlt","text":"","code":"read_log_barlt(filename)"},{"path":"http://arutools.github.io/ARUtools/reference/read_log_barlt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse the log file for BarLT — read_log_barlt","text":"filename Character. File location log file","code":""},{"path":"http://arutools.github.io/ARUtools/reference/read_summary_SM4.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse SM4 logfiles — read_summary_SM4","title":"Parse SM4 logfiles — read_summary_SM4","text":"Parse SM4 logfiles","code":""},{"path":"http://arutools.github.io/ARUtools/reference/read_summary_SM4.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse SM4 logfiles — read_summary_SM4","text":"","code":"read_summary_SM4(filename, SiteID_pattern = \"SM4A\\\\d{5}\")"},{"path":"http://arutools.github.io/ARUtools/reference/read_summary_SM4.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse SM4 logfiles — read_summary_SM4","text":"filename Character string vector character strings file locations. Can single file vector file locations. SiteID_pattern Pattern extracting SiteID filename. Defaults 'SM4A\\d5', SM4, followed 5 digits.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/read_summary_SM4.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parse SM4 logfiles — read_summary_SM4","text":"Returns data frame log files.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/soxSpectrogram.html","id":null,"dir":"Reference","previous_headings":"","what":"Create spectrogram from wave file — soxSpectrogram","title":"Create spectrogram from wave file — soxSpectrogram","text":"Functions Sam Hache create spectrograms","code":""},{"path":"http://arutools.github.io/ARUtools/reference/soxSpectrogram.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create spectrogram from wave file — soxSpectrogram","text":"","code":"soxSpectrogram(   file.path,   out.path = \"Spectrograms\",   out.app = \"test\",   size = list(x = 2000, y = 1000),   duration = list(start = 0, end = 180),   sox.file.path )"},{"path":"http://arutools.github.io/ARUtools/reference/soxSpectrogram.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create spectrogram from wave file — soxSpectrogram","text":"file.path Input must file directory (file.path) .path Default save Spectrogram folder current working directory otherwise specify location (.path) .app Appends start output file. Default 'test' size Size picture pixels duration Duration recording plot sox.file.path Path sox file.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/soxSpectrogram.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create spectrogram from wave file — soxSpectrogram","text":"return anything, create image file .path.","code":""},{"path":"http://arutools.github.io/ARUtools/reference/soxSpectrogram.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create spectrogram from wave file — soxSpectrogram","text":"Create spectrogram save wherever want Input must file directory (file.path) Default save Spectrogram folder current working directory otherwise specify location (.path) Size specifies x y size output pixels must list Duration sets duration spectrogram default 3 min listed seconds","code":""},{"path":"http://arutools.github.io/ARUtools/reference/wind_detection_pre_processing.html","id":null,"dir":"Reference","previous_headings":"","what":"Pre-processing of files for Wind Detection program — wind_detection_pre_processing","title":"Pre-processing of files for Wind Detection program — wind_detection_pre_processing","text":"Pre-processing files Wind Detection program","code":""},{"path":"http://arutools.github.io/ARUtools/reference/wind_detection_pre_processing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pre-processing of files for Wind Detection program — wind_detection_pre_processing","text":"","code":"wind_detection_pre_processing(   wav_vector,   site_pattern,   chunksize,   file_drive,   output_directory = NULL,   write_output = FALSE )"},{"path":"http://arutools.github.io/ARUtools/reference/wind_detection_pre_processing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pre-processing of files for Wind Detection program — wind_detection_pre_processing","text":"write_output","code":""},{"path":"http://arutools.github.io/ARUtools/reference/wind_detection_summarize_json.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize wind detection results — wind_detection_summarize_json","title":"Summarize wind detection results — wind_detection_summarize_json","text":"Summarize wind detection results","code":""},{"path":"http://arutools.github.io/ARUtools/reference/wind_detection_summarize_json.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize wind detection results — wind_detection_summarize_json","text":"","code":"wind_detection_summarize_json(f, json_string_regex = \"/[\\\\w|\\\\d|_|-]+\")"},{"path":"http://arutools.github.io/ARUtools/reference/wind_detection_summarize_json.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize wind detection results — wind_detection_summarize_json","text":"f filepath json json_string_regex string. Regex extract file path","code":""},{"path":"http://arutools.github.io/ARUtools/reference/wt_assign_tasks.html","id":null,"dir":"Reference","previous_headings":"","what":"Assign tasks for wildtrax interpretation — wt_assign_tasks","title":"Assign tasks for wildtrax interpretation — wt_assign_tasks","text":"Assign tasks wildtrax interpretation","code":""},{"path":"http://arutools.github.io/ARUtools/reference/wt_assign_tasks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assign tasks for wildtrax interpretation — wt_assign_tasks","text":"","code":"wt_assign_tasks(   wt_task_template_in,   interp_hours_file,   wt_task_output_file,   interp_hours_column,   random_seed = NULL )"},{"path":"http://arutools.github.io/ARUtools/reference/wt_assign_tasks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assign tasks for wildtrax interpretation — wt_assign_tasks","text":"wt_task_template_in Path csv template downloaded WilldTrax website listing tasks interp_hours_file Path number hours interpreter. Must csv include wt_task_output_file Path csv output file uploading wildtrax. left NULL write file interp_hours_column LazyEval column name hours interpreters random_seed Integer. Random seed select . left NULL use timestamp","code":""},{"path":"http://arutools.github.io/ARUtools/reference/wt_assign_tasks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assign tasks for wildtrax interpretation — wt_assign_tasks","text":"Returns list tibble assigned tasks summary tibble.","code":""},{"path":[]},{"path":"http://arutools.github.io/ARUtools/news/index.html","id":"new-0-5-1","dir":"Changelog","previous_headings":"","what":"New","title":"ARUtools 0.5.1","text":"add_wildtrax() - New helper function create append Wildtrax file names","code":""},{"path":"http://arutools.github.io/ARUtools/news/index.html","id":"bugs-0-5-1","dir":"Changelog","previous_headings":"","what":"Bugs","title":"ARUtools 0.5.1","text":"clean_gps() - Fixed errors processing GPX files","code":""},{"path":"http://arutools.github.io/ARUtools/news/index.html","id":"arutools-050","dir":"Changelog","previous_headings":"","what":"ARUtools 0.5.0","title":"ARUtools 0.5.0","text":"clean_gps() can handle GPX files via sf now distance cutoff results warning (error), returning data max_dist column, users can see site problematic. now checks distance site groups aru_id site_id default pattern matches GPS column headers expanded catches errors continues reporting failed loading (remove skip_bad argument) check_problems() now also checks GPS meta data create_pattern_XXX() Now accept multiple options separators non-optional, provide \"\" pseudo-optional create_pattern_site_id() ids suffix clean_metadata() accepts multiple pattern options clean_site_index() allows date columns (col_date_time = NULL) add_sites() Rename dt_type by_date Take mean multiple sites by_date = \"date\" (instead truncating) Use by_date = NULL skip joining date range Workflow now works sf input (must POINT geometries) clean_site_index() add_sites() calc_sun() Timezones now explicit Expect local time marked UTC Existing non-UTC timezones stripped message Errors returned one relevant date_time column different timezones Vignettes Mini spatial workflow (vignettes/spatial.Rmd) Explaining timezones (vignettes/timezones.Rmd)","code":""},{"path":"http://arutools.github.io/ARUtools/news/index.html","id":"arutools-0409000","dir":"Changelog","previous_headings":"","what":"ARUtools 0.4.0.9000","title":"ARUtools 0.4.0.9000","text":"Major overhaul first half workflow Main functions now clean_metadata() clean_gps() / clean_site_index() add_sites() calc_sun() Helper functions checking, creating regex patterns","code":""}]
